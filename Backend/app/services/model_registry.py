from __future__ import annotations

import os
from dataclasses import dataclass
from pathlib import Path
from shutil import copy2
from threading import Lock
from typing import Dict, Iterable, Optional

import torch
from huggingface_hub import hf_hub_download
from loguru import logger


try:
    from doclayout_yolo import YOLOv10
except ImportError as exc:  # pragma: no cover - í™˜ê²½ ì˜ì¡´
    YOLOv10 = None  # type: ignore[assignment]
    _IMPORT_ERROR = exc
else:
    _IMPORT_ERROR = None


@dataclass(frozen=True)
class ModelSpec:
    name: str
    repo_id: str
    filename: str
    imgsz: int = 1024
    conf: float = 0.25


@dataclass
class ModelHandle:
    name: str
    spec: ModelSpec
    model: "YOLOv10"
    device: str
    weight_path: Path


class ModelRegistry:
    """
    DocLayout-YOLO ê³„ì—´ ëª¨ë¸ì„ ì „ì—­ìœ¼ë¡œ ìºì‹±/ì¬ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë ˆì§€ìŠ¤íŠ¸ë¦¬.
    - ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œëŠ” í•œ ë²ˆë§Œ ìˆ˜í–‰
    - ë””ë°”ì´ìŠ¤(CPU/GPU)ë³„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•„ìš” ì‹œ ë³„ë„ë¡œ ìœ ì§€
    """

    def __init__(self) -> None:
        self._specs: Dict[str, ModelSpec] = {}
        self._models: Dict[str, ModelHandle] = {}
        self._locks: Dict[str, Lock] = {}
        self._default_device = "cuda" if torch.cuda.is_available() else "cpu"

    @staticmethod
    def _make_key(name: str, device: str) -> str:
        return f"{name}:{device}"

    def register(self, spec: ModelSpec) -> None:
        self._specs[spec.name] = spec
        self._locks.setdefault(spec.name, Lock())
        logger.debug(f"ğŸ“˜ ëª¨ë¸ ìŠ¤í™ ë“±ë¡: {spec.name} (imgsz={spec.imgsz}, conf={spec.conf})")

    def list_registered(self) -> Dict[str, ModelSpec]:
        return dict(self._specs)

    def preload(self, targets: Optional[Iterable[str]] = None, *, device: Optional[str] = None) -> None:
        names = list(targets) if targets else list(self._specs.keys())
        for name in names:
            try:
                self.get_model(name, device=device)
            except Exception as exc:  # pragma: no cover - ì´ˆê¸°í™” ë‹¨ê³„
                logger.error(f"âŒ ëª¨ë¸ í”„ë¦¬ë¡œë“œ ì‹¤íŒ¨ ({name}): {exc}")
                raise

    def get_model(self, name: str, *, device: Optional[str] = None) -> ModelHandle:
        if name not in self._specs:
            raise KeyError(f"ë“±ë¡ë˜ì§€ ì•Šì€ ëª¨ë¸ì…ë‹ˆë‹¤: {name}")

        if _IMPORT_ERROR is not None:
            raise RuntimeError(
                "doclayout_yolo íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            ) from _IMPORT_ERROR

        resolved_device = device or self._default_device
        key = self._make_key(name, resolved_device)

        if key in self._models:
            return self._models[key]

        lock = self._locks.setdefault(name, Lock())
        with lock:
            if key in self._models:
                return self._models[key]

            spec = self._specs[name]
            weight_path = self._download_weights(name, spec)
            model = self._load_model(weight_path, resolved_device)

            handle = ModelHandle(
                name=name,
                spec=spec,
                model=model,
                device=resolved_device,
                weight_path=weight_path,
            )
            self._models[key] = handle
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {name} (device={resolved_device})")
            return handle

    @staticmethod
    def _download_weights(name: str, spec: ModelSpec) -> Path:
        override_env = os.getenv(f"{name.upper()}_MODEL_PATH")
        if override_env:
            override_path = Path(override_env)
            if override_path.exists():
                logger.info(f"ğŸ“‚ {name} ê°€ì¤‘ì¹˜ ê²½ë¡œ override ì‚¬ìš©: {override_path}")
                return override_path.resolve()
            logger.warning(
                f"âš ï¸ {name.upper()}_MODEL_PATH ê°€ ì§€ì •ë˜ì—ˆì§€ë§Œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {override_path}"
            )

        cache_root = Path(
            os.getenv("MODEL_CACHE_DIR", Path.home() / ".cache" / "smarteye_models")
        ).resolve()
        target_dir = (cache_root / name).resolve()
        target_dir.mkdir(parents=True, exist_ok=True)
        target_path = target_dir / spec.filename

        if target_path.exists():
            logger.debug(f"ğŸ“¦ ìºì‹œëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©: {target_path}")
            return target_path

        logger.info(f"â¬‡ï¸ {name} ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ ì¤‘ ({spec.repo_id}/{spec.filename})")
        downloaded_path = hf_hub_download(
            repo_id=spec.repo_id,
            filename=spec.filename,
            local_dir=str(target_dir),
            local_dir_use_symlinks=False,
        )

        downloaded_path = Path(downloaded_path).resolve()
        if downloaded_path != target_path:
            copy2(downloaded_path, target_path)
            logger.debug(f"ğŸ“ ê°€ì¤‘ì¹˜ ë³µì‚¬: {downloaded_path.name} -> {target_path}")

        return target_path

    @staticmethod
    def _load_model(weight_path: Path, device: str) -> "YOLOv10":
        if YOLOv10 is None:  # pragma: no cover
            raise RuntimeError("doclayout_yolo íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        logger.info(f"ğŸ§  ëª¨ë¸ ë¡œë”©: {weight_path.name} (device={device})")
        model = YOLOv10(str(weight_path), task="predict")
        model.to(device)
        if hasattr(model, "training"):
            model.training = False
        return model


# ---------------------------------------------------------------------------
# ì „ì—­ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¸ìŠ¤í„´ìŠ¤ ë° ê¸°ë³¸ ëª¨ë¸ ìŠ¤í™ ë“±ë¡
# ---------------------------------------------------------------------------
DEFAULT_MODEL_SPECS = [
    ModelSpec(
        name="SmartEyeSsen",
        repo_id="AkJeond/SmartEye",
        filename="best.pt",
        imgsz=1024,
        conf=0.25,
    ),
    ModelSpec(
        name="docstructbench",
        repo_id="juliozhao/DocLayout-YOLO-DocStructBench",
        filename="doclayout_yolo_docstructbench_imgsz1024.pt",
        imgsz=1024,
        conf=0.25,
    )
]

model_registry = ModelRegistry()
for spec in DEFAULT_MODEL_SPECS:
    model_registry.register(spec)

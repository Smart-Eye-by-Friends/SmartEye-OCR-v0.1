# -*- coding: utf-8 -*-
"""
SmartEyeSsen Analysis Service (v1.1 - Duplicate Detection Filter Added)
========================================================================

í•™ìŠµì§€ ë¶„ì„ ì„œë¹„ìŠ¤ - ë ˆì´ì•„ì›ƒ ë¶„ì„, OCR, AI ì„¤ëª… ìƒì„±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
Refactored from api_server.py WorksheetAnalyzer class.

ì£¼ìš” ë³€ê²½ì‚¬í•­ (DB í†µí•© ë²„ì „):
- analyze_layout: DocLayout-YOLO ê²°ê³¼ë¥¼ layout_elements í…Œì´ë¸”ì— ì €ì¥ í›„ ORM ê°ì²´ ë°˜í™˜
- perform_ocr: text_contents í…Œì´ë¸”ì— OCR ê²°ê³¼ upsert
- call_openai_api / call_openai_api_async: ai_descriptions í…Œì´ë¸”ì— ì„¤ëª… í…ìŠ¤íŠ¸ upsert
- ì¤‘ë³µ íƒì§€ í•„í„°ë§(IoU ê¸°ë°˜) ë¡œì§ ìœ ì§€
"""

import asyncio
import base64
import colorsys
import io
import os
import platform
import random
from dataclasses import dataclass
from typing import Dict, List, Optional

import cv2
import numpy as np
import openai
import pytesseract
import torch
from PIL import Image
from loguru import logger
from openai import AsyncOpenAI
from sqlalchemy.orm import Session

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    logger.warning("âš ï¸ google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Tesseract OCRë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")

from .. import models
from .model_registry import model_registry


class GeminiOCRError(Exception):
    """Gemini OCR ì²˜ë¦¬ ì¤‘ ë°œìƒí•˜ëŠ” ì˜ˆì™¸."""


@dataclass
class GeminiOCRJob:
    element: models.LayoutElement
    cls_name: str
    pil_image: Image.Image
    cropped_img: np.ndarray


@dataclass
class GeminiOCRResult:
    job: GeminiOCRJob
    text: str = ""
    engine: str = "Gemini-2.5-Flash-Lite"
    error: Optional[Exception] = None


def _safe_int(value: Optional[str], default: int) -> int:
    try:
        return int(value) if value is not None else default
    except ValueError:
        logger.warning(
            f"âš ï¸ í™˜ê²½ ë³€ìˆ˜ ê°’ì´ ì •ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤. ê¸°ë³¸ê°’ {default} ì‚¬ìš©: {value}"
        )
        return default


def _safe_float(value: Optional[str], default: float) -> float:
    try:
        return float(value) if value is not None else default
    except ValueError:
        logger.warning(
            f"âš ï¸ í™˜ê²½ ë³€ìˆ˜ ê°’ì´ ì‹¤ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤. ê¸°ë³¸ê°’ {default} ì‚¬ìš©: {value}"
        )
        return default


GEMINI_MAX_CONCURRENCY = _safe_int(os.getenv("GEMINI_MAX_CONCURRENCY"), 30)
GEMINI_MAX_RETRIES = _safe_int(os.getenv("GEMINI_MAX_RETRIES"), 3)
GEMINI_RETRY_BASE_DELAY = _safe_float(os.getenv("GEMINI_RETRY_BASE_DELAY"), 1.5)
GEMINI_SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# --- ì‹ ê·œ: ì´ë¯¸ì§€ ì„¤ëª…ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€ (ê·œì • ê¸°ë°˜ ìµœì í™”) ---
figure_prompt = """
ë‹¹ì‹ ì€ ì‹œê°ì¥ì•  í•™ìƒì„ ìœ„í•œ ì´ë¯¸ì§€ ì„¤ëª… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì—­í• :
- í•œêµ­ ì ì ë„ì„œ ê·œì •(ì œ2ì ˆ ì‹œê° ìë£Œ, p.82-91)ì„ ì •í™•íˆ ë”°ë¦…ë‹ˆë‹¤.
- ì´ˆë“±í•™ìƒ(8-14ì„¸)ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ ë§ì„ ì”ë‹ˆë‹¤.
- ì ì ë…ìê°€ ì´‰ê°ìœ¼ë¡œ ì •ë³´ë¥¼ íŒŒì•…í•˜ë„ë¡ í•©ë‹ˆë‹¤.
- ê°ê´€ì  ì‚¬ì‹¤ë§Œ ì„¤ëª…í•˜ê³  ì£¼ê´€ì  íŒë‹¨ì€ í”¼í•©ë‹ˆë‹¤.

ì„¤ëª… ê·œì¹™ (í•œêµ­ ì ì ê·œì • ì¤€ìˆ˜):
1. ì œëª© í™•ì¸: ì›ë³¸ì— ì œëª©ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ 'ì œëª© ì—†ìŒ'ìœ¼ë¡œ í‘œê¸°
2. ê·¸ë¦¼/ì‚¬ì§„ ìœ í˜•: ì‹¤ì‚¬, ì‚½í™”, ë„í˜•, ì‚¬ì§„ ë“± êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ
3. ì½ê¸° ìˆœì„œ: ì™¼ìª½â†’ì˜¤ë¥¸ìª½, ìœ„â†’ì•„ë˜ ìˆœì„œ ì¤€ìˆ˜
4. êµ¬ì¡° ì„¤ëª…:
   - ë°°ê²½: ì‚¬ì§„/ê·¸ë¦¼ì˜ ë°°ê²½ì´ë‚˜ ì„¤ì •
   - ì¤‘ì‹¬ í”¼ì‚¬ì²´: ê°€ì¥ ì¤‘ìš”í•œ ëŒ€ìƒ
   - ìœ„ì¹˜ ê´€ê³„: ìš”ì†Œë“¤ ê°„ì˜ ê³µê°„ì  ë°°ì¹˜
5. ì„¸ë¶€ ì„¤ëª…:
   - í¬ê¸°, ìƒ‰ìƒ, ì¬ì§ˆ ë“± ë¬¼ë¦¬ì  íŠ¹ì„±
   - í‘œì •, ìì„¸, ë™ì‘(ì¸ë¬¼/ë™ë¬¼ í¬í•¨ ì‹œ)
   - ìˆ«ìë‚˜ ë¬¸ìê°€ ìˆìœ¼ë©´ ëª…í™•í•˜ê²Œ ì „ë‹¬
6. ë¬¸ì¥ ê¸¸ì´: ì´ˆë“±í•™ìƒ ì´í•´ë„ ê¸°ì¤€, 30ì ì´ë‚´ ê¶Œì¥
7. ì¶”ì¸¡ ê¸ˆì§€: ì›ë³¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ì•ŠìŒ

[ì¶œë ¥ í˜•ì‹]
ì´ë¯¸ì§€ ê°œìš”:
- ì œëª©: [ì œëª© ë˜ëŠ” 'ì œëª© ì—†ìŒ']
- ìœ í˜•: [ì‹¤ì‚¬/ì‚½í™”/ë„í˜•/ì‚¬ì§„ ë“±]

êµ¬ì„± ìš”ì†Œ:
- ë°°ê²½: [ë°°ê²½ ì„¤ëª…]
- ì¤‘ì‹¬ ëŒ€ìƒ: [ì£¼ìš” í”¼ì‚¬ì²´ ì„¤ëª…]
- ìœ„ì¹˜ ê´€ê³„: [ê³µê°„ì  ë°°ì¹˜ ì„¤ëª…]

ì„¸ë¶€ ë‚´ìš©:
[ìƒ‰ìƒ, í¬ê¸°, íŠ¹ì§• ë“± êµ¬ì²´ì  ì„¤ëª…]

íŠ¹ì´ ì‚¬í•­:
[ë¬¸ì, ê¸°í˜¸, ì£¼ëª©í•  ë§Œí•œ ìš”ì†Œ ë“±]
"""

table_prompt = """
ë‹¹ì‹ ì€ ì‹œê°ì¥ì•  í•™ìƒì„ ìœ„í•œ í‘œ ì„¤ëª… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì—­í• :
- í•œêµ­ ì ì ë„ì„œ ê·œì •(ì œ3ì¥ ì œ1ì ˆ í‘œ, p.62-81)ì„ ì •í™•íˆ ë”°ë¦…ë‹ˆë‹¤.
- íŠ¹íˆ simple_table ê·œì •(ìˆ˜ì°¨/ëª‡ ê°œ ë‹¨ì–´ í‘œ, p.65-66)ì„ ì ìš©í•©ë‹ˆë‹¤.
- ì´ˆë“±í•™ìƒ(8-14ì„¸)ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ ë§ì„ ì”ë‹ˆë‹¤.
- í‘œì˜ êµ¬ì¡°ë¥¼ ëª…í™•í•˜ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.
- ì ì ë…ìê°€ í–‰ë³„ë¡œ ì •í™•í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

ì„¤ëª… ê·œì¹™ (í•œêµ­ ì ì ê·œì • ì¤€ìˆ˜):
1. ì œëª©ê³¼ ë‹¨ìœ„ ëª…ì‹œ:
   - í‘œì˜ ì œëª©ì´ ìˆìœ¼ë©´ ìš°ì„  í‘œê¸°
   - ì œëª©ì´ ì—†ìœ¼ë©´ 'ì œëª© ì—†ìŒ'ìœ¼ë¡œ í‘œê¸°
   - í‘œì˜ ë‹¨ìœ„ ëª…ì‹œ (ì˜ˆ: %, ëª…, kg ë“±)

2. í‘œì˜ êµ¬ì¡° íŒŒì•… (simple_table ê·œì •):
   - í–‰ ìˆ˜(ëª‡ ì¤„)ì™€ ì—´ ìˆ˜(ëª‡ ì¹¸) ëª…í™•íˆ í‘œê¸°
   - ì—´ ì œëª©(ì»¬ëŸ¼ í—¤ë”) ì°¨ë¡€ëŒ€ë¡œ ë‚˜ì—´
   - í–‰ ì œëª©(ë¡œìš° í—¤ë”) í™•ì¸

3. í–‰ë³„ ìˆœì°¨ ì„¤ëª…:
   - ì²« ë²ˆì§¸ í–‰ë¶€í„° ë§ˆì§€ë§‰ í–‰ê¹Œì§€ ìˆœì„œëŒ€ë¡œ
   - ê° í–‰ ë‚´ì—ì„œëŠ” ì™¼ìª½ ì—´ë¶€í„° ì˜¤ë¥¸ìª½ ì—´ ìˆœì„œë¡œ
   - í–‰ ì œëª©ê³¼ ë°ì´í„°ë¥¼ ëª…í™•íˆ ì—°ê²°

4. ìˆ˜ì¹˜ í‘œí˜„:
   - ìˆ«ìëŠ” ë°˜ë“œì‹œ ë‹¨ìœ„ì™€ í•¨ê»˜ í‘œê¸° (ì˜ˆ: "3ëª…", "50%")
   - í¬ê¸° ë¹„êµ ì¶”ê°€ (ì˜ˆ: "Aê°€ Bë³´ë‹¤ ë†’ìŒ")
   - ì¦ê° ë°©í–¥ ëª…ì‹œ (ì˜ˆ: "ì¦ê°€", "ê°ì†Œ")

5. íŠ¹ì´ ì‚¬í•­ ì²˜ë¦¬:
   - ë¹ˆ ì¹¸ì´ ìˆìœ¼ë©´ ëª…ì‹œ (ì˜ˆ: "í•´ë‹¹ ë°ì´í„° ì—†ìŒ")
   - ë³„í‘œ(*), ì£¼ì„ì´ ìˆìœ¼ë©´ ì„¤ëª…
   - ë³‘í•©ëœ ì…€(merged cell)ì´ ìˆìœ¼ë©´ êµ¬ì¡° ëª…í™•íˆ

6. í•µì‹¬ ë©”ì‹œì§€:
   - í‘œê°€ ë¬´ì—‡ì„ ë³´ì—¬ì£¼ëŠ”ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½

[ì¶œë ¥ í˜•ì‹]
í‘œì˜ ì •ë³´:
- ì œëª©: [ì œëª© ë˜ëŠ” 'ì œëª© ì—†ìŒ']
- í¬ê¸°: [í–‰ ìˆ˜]í–‰ Ã— [ì—´ ìˆ˜]ì—´
- ë‹¨ìœ„: [%, ëª…, kg ë“±]

í‘œì˜ êµ¬ì¡°:
- ì—´ ì œëª©: [ì—´1], [ì—´2], [ì—´3] ... (ìˆœì„œëŒ€ë¡œ)
- í–‰ ì œëª©: [í–‰1], [í–‰2], [í–‰3] ... (ìˆìœ¼ë©´)

í–‰ë³„ ë°ì´í„°:
ì²« ë²ˆì§¸ í–‰ ([í–‰_ì œëª©1]): [ë°ì´í„°1], [ë°ì´í„°2], [ë°ì´í„°3]
ë‘ ë²ˆì§¸ í–‰ ([í–‰_ì œëª©2]): [ë°ì´í„°1], [ë°ì´í„°2], [ë°ì´í„°3]
ì„¸ ë²ˆì§¸ í–‰ ([í–‰_ì œëª©3]): [í•„ìš” ì‹œ ê³„ì†]

íŠ¹ì´ ì‚¬í•­: [ë¹ˆì¹¸, ë³‘í•©, ì£¼ì„ ë“±]

í•µì‹¬: [í‘œê°€ ë³´ì—¬ì£¼ëŠ” í•µì‹¬ ì •ë³´ í•œ ë¬¸ì¥]
"""

flowchart_prompt = """
ë‹¹ì‹ ì€ ì‹œê°ì¥ì•  í•™ìƒì„ ìœ„í•œ ìˆœì„œë„ ì„¤ëª… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì—­í• :
- í•œêµ­ ì ì ë„ì„œ ê·œì •(ì œ2ì ˆ, p.108-112)ì„ ì •í™•íˆ ë”°ë¦…ë‹ˆë‹¤.
- ì´ˆë“±í•™ìƒ(8-14ì„¸)ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ ë§ì„ ì”ë‹ˆë‹¤.
- ìˆœì„œë„ì˜ íë¦„ê³¼ ë…¼ë¦¬ë¥¼ ëª…í™•í•˜ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.
- ì ì ë…ìê°€ ë‹¨ê³„ë³„ ì§„í–‰ì„ ì •í™•í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

ì„¤ëª… ê·œì¹™ (í•œêµ­ ì ì ê·œì • ì¤€ìˆ˜):
1. ì œëª©ê³¼ ì£¼ì œ:
   - ìˆœì„œë„ì˜ ì œëª©ì´ ìˆìœ¼ë©´ ëª…ì‹œ
   - ì´ ìˆœì„œë„ê°€ ë¬´ì—‡ì— ëŒ€í•œ ê²ƒì¸ì§€ ëª…í™•íˆ

2. ì‹œì‘ì ê³¼ ì¢…ë£Œì :
   - ì‹œì‘ì (ì‹œì‘ ë…¸ë“œ) ëª…í™•íˆ í‘œê¸°
   - ì¢…ë£Œì (ë ë…¸ë“œ) ëª…í™•íˆ í‘œê¸°
   - ì „ì²´ ë‹¨ê³„ ìˆ˜ í‘œê¸°

3. ë‹¨ê³„ë³„ ì§„í–‰ ì„¤ëª… (ì™¼ìª½â†’ì˜¤ë¥¸ìª½, ìœ„â†’ì•„ë˜ ìˆœì„œ):
   - ì²« ë²ˆì§¸: [ë‹¨ê³„ ë‚´ìš©]
   - ë‘ ë²ˆì§¸: [ë‹¨ê³„ ë‚´ìš©]
   - ì„¸ ë²ˆì§¸: [í•„ìš” ì‹œ ê³„ì†]
   - ê° ë‹¨ê³„ëŠ” ë²ˆí˜¸ë¥¼ ë¶™ì—¬ì„œ ìˆœì°¨ í‘œê¸°

4. ë¶„ê¸°/ì¡°ê±´ í‘œí˜„:
   - "ë§Œì•½ ~~ë¼ë©´" í˜•ì‹ìœ¼ë¡œ ì¡°ê±´ë¬¸ í’€ì´
   - ê° ì¡°ê±´ë³„ ì§„í–‰ ê²½ë¡œ ëª…í™•íˆ
   - ì˜ˆ/ì•„ë‹ˆì˜¤ ì„ íƒì§€ ìˆìœ¼ë©´ êµ¬ë¶„

5. ë£¨í”„/ë°˜ë³µ í‘œí˜„:
   - "ë‹¤ì‹œ ~~ë¡œ ëŒì•„ê°" í˜•ì‹ìœ¼ë¡œ í‘œí˜„
   - ì™œ ë°˜ë³µë˜ëŠ”ì§€ ì´ìœ  í•¨ê»˜ ëª…ì‹œ

6. ë¬¸ì¥ ê·œì¹™:
   - ì´ˆë“±í•™ìƒ ì´í•´ ìˆ˜ì¤€ ê¸°ì¤€
   - ê°„ë‹¨í•˜ê³  ëª…í™•í•œ í‘œí˜„
   - ì›ë³¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠìŒ

[ì¶œë ¥ í˜•ì‹]
ìˆœì„œë„ ê°œìš”:
- ì œëª©: [ì œëª© ë˜ëŠ” 'ì œëª© ì—†ìŒ']
- ì£¼ì œ: [ë¬´ì—‡ì— ëŒ€í•œ ìˆœì„œë„ì¸ê°€]
- ì‹œì‘ì : [ì‹œì‘]
- ì¢…ë£Œì : [ë]
- ì´ ë‹¨ê³„: [ëŒ€ëµ ëª‡ ë‹¨ê³„]

ë‹¨ê³„ë³„ ì§„í–‰:
1ë‹¨ê³„: [ë‚´ìš©]
   â†“
2ë‹¨ê³„: [ë‚´ìš©]
   â†“
3ë‹¨ê³„: [í•„ìš” ì‹œ ê³„ì†]

ë¶„ê¸°/ì¡°ê±´ (ìˆìœ¼ë©´):
[ì¡°ê±´]: [ê²°ê³¼ ê²½ë¡œ]

í•µì‹¬: [ì´ ìˆœì„œë„ê°€ ì„¤ëª…í•˜ëŠ” ì „ì²´ íë¦„ í•œ ë¬¸ì¥]
"""


# --- ì‹ ê·œ: IoU ê³„ì‚° í•¨ìˆ˜ ì¶”ê°€ ---
def calculate_iou(box1, box2):
    """ë‘ ë°”ìš´ë”© ë°•ìŠ¤ ê°„ì˜ IoU(Intersection over Union) ê³„ì‚°"""
    # box í˜•ì‹: [x1, y1, x2, y2]
    x1_inter = max(box1[0], box2[0])
    y1_inter = max(box1[1], box2[1])
    x2_inter = min(box1[2], box2[2])
    y2_inter = min(box1[3], box2[3])

    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)

    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])

    union_area = box1_area + box2_area - inter_area

    if union_area == 0:
        return 0.0
    return inter_area / union_area


# --- ì‹ ê·œ: ì¤‘ë³µ ì œê±° í›„ì²˜ë¦¬ í•¨ìˆ˜ ì¶”ê°€ ---
def filter_duplicate_detections(boxes, classes, confs, class_names, iou_threshold=0.7):
    """
    ëª¨ë“  í´ë˜ìŠ¤ ìŒì— ëŒ€í•´ IoU ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë³µ íƒì§€ë¥¼ í•„í„°ë§. (ìë™ ë°©ì‹)
    ì‹ ë¢°ë„ê°€ ë‚®ì€ ìª½ì„ ì œê±°.
    """
    num_detections = len(boxes)
    suppressed = [False] * num_detections  # ì œê±°í•  ìš”ì†Œ í‘œì‹œ

    indices = list(range(num_detections))
    # ì‹ ë¢°ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ê²ƒì„ ë‚¨ê¸°ê¸° ìœ„í•¨)
    indices.sort(key=lambda i: confs[i], reverse=True)

    for i in range(num_detections):
        idx1 = indices[i]
        if suppressed[idx1]:
            continue

        box1 = boxes[idx1]
        # cls_id1 = int(classes[idx1]) # í´ë˜ìŠ¤ ì •ë³´ëŠ” ì œê±° ë¡œì§ì— ë¶ˆí•„ìš”
        # cls_name1 = class_names.get(cls_id1, f"unknown_{cls_id1}") # í´ë˜ìŠ¤ ì •ë³´ëŠ” ì œê±° ë¡œì§ì— ë¶ˆí•„ìš”

        for j in range(i + 1, num_detections):
            idx2 = indices[j]
            if suppressed[idx2]:
                continue

            box2 = boxes[idx2]
            # cls_id2 = int(classes[idx2]) # í´ë˜ìŠ¤ ì •ë³´ëŠ” ì œê±° ë¡œì§ì— ë¶ˆí•„ìš”
            # cls_name2 = class_names.get(cls_id2, f"unknown_{cls_id2}") # í´ë˜ìŠ¤ ì •ë³´ëŠ” ì œê±° ë¡œì§ì— ë¶ˆí•„ìš”

            # --- ğŸ‘‡ ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘ ğŸ‘‡ ---
            # íŠ¹ì • í´ë˜ìŠ¤ ìŒ í™•ì¸ ì¡°ê±´ ì œê±°: ëª¨ë“  ìŒì— ëŒ€í•´ IoU ê³„ì‚°
            # if (cls_name1, cls_name2) in problematic_pairs: # ì´ ì¡°ê±´ ì œê±°
            iou = calculate_iou(box1, box2)
            if iou > iou_threshold:
                # ì‹ ë¢°ë„ ë‚®ì€ ìª½(idx2)ì„ ì œê±° ëŒ€ìƒìœ¼ë¡œ í‘œì‹œ
                suppressed[idx2] = True
                # ë¡œê·¸ ë©”ì‹œì§€ì—ì„œ í´ë˜ìŠ¤ ì´ë¦„ ì œê±° (ì„ íƒ ì‚¬í•­)
                logger.debug(
                    f"ì¤‘ë³µ íƒì§€ ì œê±°: Box {idx2}(conf={confs[idx2]:.2f}) - "
                    f"Box {idx1}(conf={confs[idx1]:.2f})ì™€ IoU={iou:.2f} > {iou_threshold}"
                )
            # --- ğŸ‘† ìˆ˜ì •ëœ ë¶€ë¶„ ë ğŸ‘† ---

    # ì œê±°ë˜ì§€ ì•Šì€ ìš”ì†Œë“¤ì˜ ì¸ë±ìŠ¤ ë°˜í™˜
    final_indices = [i for i, s in enumerate(suppressed) if not s]
    logger.info(
        f"ìë™ ì¤‘ë³µ íƒì§€ í•„í„°ë§: {num_detections}ê°œ â†’ {len(final_indices)}ê°œ ìš”ì†Œ (IoU > {iou_threshold})"
    )  # ë¡œê·¸ ë©”ì‹œì§€ ìˆ˜ì •
    return final_indices


# Windowsì—ì„œ Tesseract ê²½ë¡œ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
if platform.system() == "Windows":
    pytesseract.pytesseract.tesseract_cmd = (
        r"C:\Program Files\Tesseract-OCR\tesseract.exe"
    )

# ë””ë°”ì´ìŠ¤ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
device = "cuda:0" if torch.cuda.is_available() else "cpu"

# Google Gemini API ì´ˆê¸°í™”
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
gemini_available = False
if GENAI_AVAILABLE and GEMINI_API_KEY and GEMINI_API_KEY != "your_gemini_api_key_here":
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_available = True
        logger.info("âœ… Gemini API ì´ˆê¸°í™” ì™„ë£Œ (OCR ì—”ì§„ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥)")
    except Exception as e:
        logger.warning(f"âš ï¸ Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {e} - Tesseract OCRë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤")
        gemini_available = False
else:
    if not GENAI_AVAILABLE:
        logger.info("â„¹ï¸ google-generativeai íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜ - Tesseract OCR ì‚¬ìš©")
    else:
        logger.info("â„¹ï¸ GEMINI_API_KEY ë¯¸ì„¤ì • - Tesseract OCR ì‚¬ìš©")


class AnalysisService:
    """í•™ìŠµì§€ ë¶„ì„ ì„œë¹„ìŠ¤ - ìƒíƒœ ì—†ëŠ” í•¨ìˆ˜í˜• ë””ìì¸"""

    def __init__(self, model_choice: str = "SmartEyeSsen", auto_load: bool = False):
        """
        ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            model_choice: ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ (ê¸°ë³¸ê°’: "SmartEyeSsen")
            auto_load: Trueì´ë©´ ì´ˆê¸°í™” ì‹œ ìë™ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ (ê¸°ë³¸ê°’: False, í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
        """
        self.device = device
        self.model_choice = model_choice
        self.model_registry = model_registry
        self._model_handle = None
        self._model_loaded = False
        self.gemini_max_concurrency = max(1, GEMINI_MAX_CONCURRENCY)
        self.gemini_max_retries = max(1, GEMINI_MAX_RETRIES)
        self.gemini_retry_base_delay = max(0.1, GEMINI_RETRY_BASE_DELAY)

        # ìë™ ë¡œë“œ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš° ì¦‰ì‹œ ëª¨ë¸ ë¡œë“œ
        if auto_load:
            self._ensure_model_loaded()

    def _ensure_model_loaded(self, model_choice: Optional[str] = None):
        """
        Lazy Loading: ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìë™ìœ¼ë¡œ ë¡œë“œ
        (ë‹¤ì¤‘ í˜ì´ì§€ ì²˜ë¦¬ ì‹œ ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ ìµœì í™”)
        """
        target_model = model_choice or self.model_choice
        if (
            self._model_loaded
            and self._model_handle is not None
            and self._model_handle.name == target_model
        ):
            return self._model_handle

        handle = self.model_registry.get_model(target_model, device=self.device)
        self._model_handle = handle
        self.model_choice = target_model
        self._model_loaded = True
        return handle

    def analyze_layout(
        self,
        image: np.ndarray,
        *,
        page_id: int,
        db: Session,
        model_choice: Optional[str] = None,
    ) -> List[models.LayoutElement]:
        """
        ë ˆì´ì•„ì›ƒ ë¶„ì„ + ì¤‘ë³µ íƒì§€ í•„í„°ë§ í›„ ê²°ê³¼ë¥¼ DBì— ì €ì¥í•œë‹¤.

        Args:
            image: ë¶„ì„í•  ì´ë¯¸ì§€ (numpy array)
            page_id: ê²°ê³¼ë¥¼ ì €ì¥í•  pages.page_id
            db: SQLAlchemy Session
            model_choice: ì‚¬ìš©í•  ëª¨ë¸ (ë¯¸ì§€ì • ì‹œ ì¸ìŠ¤í„´ìŠ¤ ê¸°ë³¸ê°’ ì‚¬ìš©)

        Returns:
            DBì— ì €ì¥ëœ LayoutElement ORM ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        active_model = model_choice or self.model_choice

        try:
            # ëª¨ë¸ ì„ íƒì´ ë³€ê²½ë˜ì—ˆìœ¼ë©´ ì¬ë¡œë“œ
            if active_model != self.model_choice:
                logger.warning(f"ëª¨ë¸ ë³€ê²½ ê°ì§€: {self.model_choice} -> {active_model}")
                self.model_choice = active_model
                self._model_loaded = False

            # Lazy Loading: ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìë™ ë¡œë“œ
            handle = self._ensure_model_loaded(active_model)
            model = handle.model
            model_spec = handle.spec

            logger.info("ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œì‘...")
            temp_path = "temp_image.jpg"
            cv2.imwrite(temp_path, image)

            imgsz, conf = model_spec.imgsz, model_spec.conf

            results = model.predict(
                temp_path, imgsz=imgsz, conf=conf, iou=0.45, device=self.device
            )

            boxes = results[0].boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]
            classes = results[0].boxes.cls.cpu().numpy()
            confs = results[0].boxes.conf.cpu().numpy()
            class_names = model.names  # í´ë˜ìŠ¤ ID â†’ ì´ë¦„

            detection_records: List[Dict[str, float]] = []

            if not boxes.size:
                logger.warning("ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼, ê°ì§€ëœ ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return self._create_elements_from_layout(
                    detections=detection_records, page_id=page_id, db=db
                )

            final_indices = filter_duplicate_detections(
                boxes, classes, confs, class_names, iou_threshold=0.7
            )

            for i in final_indices:
                box = boxes[i]
                cls_id = int(classes[i])
                conf_val = float(confs[i])
                x1, y1, x2, y2 = map(int, box)

                cls_name = (
                    class_names.get(cls_id, f"unknown_{cls_id}")
                    if isinstance(class_names, dict)
                    else None
                )
                if cls_name is None:
                    try:
                        cls_name = class_names[cls_id]
                    except (IndexError, KeyError):
                        cls_name = f"unknown_{cls_id}"

                width = x2 - x1
                height = y2 - y1
                area = width * height
                if area < 100:
                    continue

                detection_records.append(
                    {
                        "class_name": cls_name,
                        "confidence": conf_val,
                        "bbox_x": x1,
                        "bbox_y": y1,
                        "bbox_width": width,
                        "bbox_height": height,
                    }
                )

            elements = self._create_elements_from_layout(
                detections=detection_records, page_id=page_id, db=db
            )
            logger.info(f"ë ˆì´ì•„ì›ƒ ë¶„ì„ ì™„ë£Œ: ìµœì¢… {len(elements)}ê°œ ìš”ì†Œ ì €ì¥")
            return elements

        except Exception as e:
            logger.error(f"ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
            return []

    def _create_elements_from_layout(
        self, *, detections: List[Dict[str, float]], page_id: int, db: Session
    ) -> List[models.LayoutElement]:
        """
        ê°ì§€ ê²°ê³¼ë¥¼ layout_elements í…Œì´ë¸”ì— ì €ì¥í•˜ê³  ORM ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤.
        """
        logger.debug(f"í˜ì´ì§€ {page_id} ê¸°ì¡´ ë ˆì´ì•„ì›ƒ ìš”ì†Œ ì •ë¦¬")
        existing_elements = (
            db.query(models.LayoutElement)
            .filter(models.LayoutElement.page_id == page_id)
            .all()
        )
        for element in existing_elements:
            db.delete(element)
        db.flush()  # CASCADE ê´€ê³„ ì •ë¦¬

        if not detections:
            db.commit()
            return []

        created_elements: List[models.LayoutElement] = []
        for record in detections:
            element = models.LayoutElement(
                page_id=page_id,
                class_name=record["class_name"],
                confidence=record["confidence"],
                bbox_x=int(record["bbox_x"]),
                bbox_y=int(record["bbox_y"]),
                bbox_width=int(record["bbox_width"]),
                bbox_height=int(record["bbox_height"]),
            )
            db.add(element)
            created_elements.append(element)

        db.flush()
        db.commit()
        for element in created_elements:
            db.refresh(element)

        return created_elements

    def _upsert_text_content(
        self,
        *,
        db: Session,
        element_id: int,
        ocr_text: str,
        ocr_engine: str,
        language: str,
        ocr_confidence: Optional[float] = None,
    ) -> models.TextContent:
        """
        í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•œë‹¤.
        """
        existing = (
            db.query(models.TextContent)
            .filter(models.TextContent.element_id == element_id)
            .one_or_none()
        )

        if existing:
            existing.ocr_text = ocr_text
            existing.ocr_engine = ocr_engine
            existing.language = language
            existing.ocr_confidence = ocr_confidence
            db.flush()
            return existing

        content = models.TextContent(
            element_id=element_id,
            ocr_text=ocr_text,
            ocr_engine=ocr_engine,
            ocr_confidence=ocr_confidence,
            language=language,
        )
        db.add(content)
        db.flush()
        return content

    def _upsert_ai_descriptions(
        self,
        *,
        db: Session,
        descriptions: Dict[int, str],
        model_name: str,
        prompt: Optional[str],
    ) -> List[models.AIDescription]:
        """
        AI ì„¤ëª…ì„ ìƒì„±í•˜ê±°ë‚˜ ê°±ì‹ í•œë‹¤.
        """
        saved_records: List[models.AIDescription] = []
        for element_id, description in descriptions.items():
            existing = (
                db.query(models.AIDescription)
                .filter(models.AIDescription.element_id == element_id)
                .one_or_none()
            )

            if existing:
                existing.description = description
                existing.ai_model = model_name
                existing.prompt_used = prompt
                db.flush()
                saved_records.append(existing)
                continue

            record = models.AIDescription(
                element_id=element_id,
                description=description,
                ai_model=model_name,
                prompt_used=prompt,
            )
            db.add(record)
            saved_records.append(record)

        db.flush()
        db.commit()
        for record in saved_records:
            db.refresh(record)

        return saved_records

    def perform_ocr(
        self,
        image: np.ndarray,
        layout_elements: List[models.LayoutElement],
        *,
        db: Session,
        language: str = "kor",
    ) -> List[models.TextContent]:
        """OCR ì²˜ë¦¬ (ì˜ì—­ë³„ ì „ì²˜ë¦¬ ì¶”ê°€) ë° text_contents í…Œì´ë¸” ì €ì¥"""
        target_classes = [
            "plain text",
            "unit",
            "question type",
            "question text",
            "question number",
            "title",
            "figure_caption",
            "table caption",
            "table footnote",
            "isolate_formula",
            "formula_caption",
            "list",
            "choices",
            "page",
            "second_question_number",
        ]
        ocr_results: List[models.TextContent] = []
        custom_config = r"--oem 1 --psm 4 -c preserve_interword_spaces=1"
        logger.info(
            f"OCR ì²˜ë¦¬ ì‹œì‘... ì´ {len(layout_elements)}ê°œ ë ˆì´ì•„ì›ƒ ìš”ì†Œ ì¤‘ OCR ëŒ€ìƒ í•„í„°ë§"
        )
        logger.info(f"OCR ëŒ€ìƒ í´ë˜ìŠ¤ ëª©ë¡: {target_classes}")
        detected_classes = {elem.class_name for elem in layout_elements}  # Setìœ¼ë¡œ ë³€ê²½
        logger.info(f"ê°ì§€ëœ ëª¨ë“  í´ë˜ìŠ¤: {detected_classes}")

        target_count = 0
        for element in layout_elements:
            cls_name = element.class_name  # Pydantic ëª¨ë¸ì€ ì´ë¯¸ lower() ë¶ˆí•„ìš”
            logger.debug(
                f"ë ˆì´ì•„ì›ƒ ID {element.element_id}: í´ë˜ìŠ¤ '{cls_name}' í™•ì¸ ì¤‘..."
            )  # DEBUG ë ˆë²¨ë¡œ ë³€ê²½
            if cls_name not in target_classes:
                logger.debug(f"  â†’ OCR ëŒ€ìƒ ì•„ë‹˜")
                continue

            target_count += 1
            logger.debug(
                f"  â†’ OCR ëŒ€ìƒ {target_count}: ID {element.element_id} - í´ë˜ìŠ¤ '{cls_name}'"
            )

            # 1. ì˜ì—­ ì´ë¯¸ì§€ ì˜ë¼ë‚´ê¸° (ê¸°ì¡´ ì½”ë“œ)
            x1, y1 = element.bbox_x, element.bbox_y
            x2, y2 = x1 + element.bbox_width, y1 + element.bbox_height
            # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì¢Œí‘œ ì¡°ì •
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(image.shape[1], x2), min(image.shape[0], y2)

            if y2 <= y1 or x2 <= x1:  # í¬ê¸°ê°€ 0ì´ê±°ë‚˜ ìŒìˆ˜ì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
                logger.warning(
                    f"  â†’ ìœ íš¨í•˜ì§€ ì•Šì€ BBox í¬ê¸°: ID {element.element_id}, ê±´ë„ˆëœ€"
                )
                continue
            cropped_img = image[y1:y2, x1:x2]

            try:
                # --- ğŸ‘‡ ì˜ì—­ë³„ ì „ì²˜ë¦¬ ë‹¨ê³„ ì‹œì‘ ğŸ‘‡ ---

                # 2. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜: ìƒ‰ìƒ ì •ë³´ ì œê±°
                gray_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)

                # 3. ì´ì§„í™” (Otsu's Binarization): í…ìŠ¤íŠ¸/ë°°ê²½ ëª…í™•í™”
                # Otsu ë°©ì‹ì€ ì„ê³„ê°’ì„ ìë™ìœ¼ë¡œ ê²°ì •í•´ ì¤ë‹ˆë‹¤.
                # í•„ìš”ì— ë”°ë¼ cv2.adaptiveThreshold ë“± ë‹¤ë¥¸ ë°©ì‹ ì‚¬ìš© ê°€ëŠ¥
                _, binary_img = cv2.threshold(
                    gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
                )

                # 4. (ì„ íƒì ) ë…¸ì´ì¦ˆ ì œê±°: Median í•„í„° ì ìš© (ì‘ì€ ì  ì œê±°ì— íš¨ê³¼ì )
                # ì»¤ë„ í¬ê¸°(ì˜ˆ: 3)ëŠ” ì‹¤í—˜ì„ í†µí•´ ì¡°ì •
                denoised_img = cv2.medianBlur(binary_img, 3)

                # --- ğŸ‘† ì˜ì—­ë³„ ì „ì²˜ë¦¬ ë‹¨ê³„ ë ğŸ‘† ---

                # 5. ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¡œ OCR ìˆ˜í–‰
                # Pillow ì´ë¯¸ì§€ë¡œ ë³€í™˜ (TesseractëŠ” Pillow ì´ë¯¸ì§€ ì…ë ¥ ì„ í˜¸)
                pil_img = Image.fromarray(denoised_img)
                text = pytesseract.image_to_string(
                    pil_img, lang="kor+eng", config=custom_config
                ).strip()

                if len(text) > 1:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                    db_text = self._upsert_text_content(
                        db=db,
                        element_id=element.element_id,
                        ocr_text=text,
                        ocr_engine="Tesseract",
                        language=language,
                    )
                    ocr_results.append(db_text)
                    logger.info(
                        f"âœ… OCR ì„±ê³µ: ID {element.element_id} ({cls_name}) - '{text[:50].replace(chr(10), ' ')}...' ({len(text)}ì)"
                    )  # ê°œí–‰ë¬¸ì ì œê±°
                else:
                    logger.warning(
                        f"âš ï¸ OCR ê²°ê³¼ ì—†ìŒ: ID {element.element_id} ({cls_name})"
                    )
            except Exception as e:
                logger.error(
                    f"OCR ì‹¤íŒ¨: ID {element.element_id} - {e}", exc_info=True
                )  # ìƒì„¸ ì—ëŸ¬

        db.commit()
        for content in ocr_results:
            db.refresh(content)

        logger.info(f"OCR ì²˜ë¦¬ ì™„ë£Œ: {len(ocr_results)}ê°œ í…ìŠ¤íŠ¸ ë¸”ë¡ ì €ì¥")
        return ocr_results

    def call_openai_api(
        self,
        image: np.ndarray,
        layout_elements: List[models.LayoutElement],
        *,
        api_key: Optional[str],
        db: Session,
        model_name: str = "gpt-4-turbo",
    ) -> Dict[int, str]:
        """OpenAI API í˜¸ì¶œ ë° ai_descriptions í…Œì´ë¸” ì €ì¥"""
        if not api_key:
            logger.warning("API í‚¤ê°€ ì—†ì–´ AI ì„¤ëª… ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {}
        target_classes = ["figure", "table", "flowchart"]
        ai_descriptions: Dict[int, str] = {}

        try:
            client = openai.OpenAI(api_key=api_key)
            logger.info("OpenAI API ì²˜ë¦¬ ì‹œì‘...")
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return {}

        prompts = {
            "figure": figure_prompt,
            "table": table_prompt,
            "flowchart": flowchart_prompt,
        }
        system_prompt = (
            "ë‹¹ì‹ ì€ ì‹œê° ì¥ì•  ì•„ë™ í•™ìŠµ AI ë¹„ì„œì…ë‹ˆë‹¤. "
            "ì‹œê° ìë£Œ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”. "
            "ìŒì„± ë³€í™˜ ì‹œ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì§ì ‘ì ì¸ ë¬¸ì¥ì„ ì‚¬ìš©í•˜ì„¸ìš”."
        )

        for element in layout_elements:
            cls_name = element.class_name
            if cls_name not in target_classes:
                continue

            x1, y1 = element.bbox_x, element.bbox_y
            x2, y2 = x1 + element.bbox_width, y1 + element.bbox_height
            if y2 <= y1 or x2 <= x1:
                continue

            cropped_img = image[y1:y2, x1:x2]
            pil_img = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
            buffered = io.BytesIO()
            pil_img.save(buffered, format="PNG")
            img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
            prompt = prompts.get(cls_name, f"ì´ {cls_name} ë‚´ìš© ì„¤ëª…")

            try:
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{img_base64}"
                                    },
                                },
                            ],
                        },
                    ],
                    temperature=0.2,
                    max_tokens=600,
                )
                description = response.choices[0].message.content.strip()
                ai_descriptions[element.element_id] = description
                logger.info(f"API ì‘ë‹µ ì™„ë£Œ: ID {element.element_id} - {cls_name}")
            except Exception as e:
                logger.error(
                    f"API ìš”ì²­ ì‹¤íŒ¨: ID {element.element_id} - {e}", exc_info=True
                )

        saved = self._upsert_ai_descriptions(
            db=db, descriptions=ai_descriptions, model_name=model_name, prompt=None
        )
        logger.info(f"OpenAI API ì²˜ë¦¬ ì™„ë£Œ: {len(saved)}ê°œ ì„¤ëª… ìƒì„± ë° ì €ì¥")
        return ai_descriptions

    async def call_openai_api_async(
        self,
        image: np.ndarray,
        layout_elements: List[models.LayoutElement],
        api_key: str,
        *,
        db: Optional[Session] = None,
        model_name: str = "gpt-4-turbo",
        max_concurrent_requests: int = 15,
    ) -> Dict[int, str]:
        """
        OpenAI API ë¹„ë™ê¸° ë³‘ë ¬ í˜¸ì¶œ (ì„±ëŠ¥ ìµœì í™” ë²„ì „)

        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€ (BGR í¬ë§·)
            layout_elements: ë ˆì´ì•„ì›ƒ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
            api_key: OpenAI API í‚¤
            db: SQLAlchemy Session (ì„ íƒ, ì œê³µ ì‹œ DBì— ì„¤ëª… ì €ì¥)
            model_name: ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„
            max_concurrent_requests: ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜ (ê¸°ë³¸ê°’: 5)

        Returns:
            Dict[int, str]: {element_id: AI ì„¤ëª…} ë”•ì…”ë„ˆë¦¬

        ì£¼ìš” ê°œì„ ì‚¬í•­:
        - ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ ì‹œê°„ 70% ë‹¨ì¶•
        - asyncio.Semaphoreë¡œ Rate Limit ëŒ€ì‘
        - ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë¡œì§ (exponential backoff)
        """
        if not api_key:
            logger.warning("API í‚¤ê°€ ì—†ì–´ AI ì„¤ëª… ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {}

        # 1. ëŒ€ìƒ í´ë˜ìŠ¤ í•„í„°ë§ (figure, table, flowchartë§Œ ì²˜ë¦¬)
        target_classes = ["figure", "table", "flowchart"]
        target_elements = [
            elem for elem in layout_elements if elem.class_name in target_classes
        ]

        if not target_elements:
            logger.info("AI ì„¤ëª… ëŒ€ìƒ ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        logger.info(
            f"OpenAI API ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘... (ì´ {len(target_elements)}ê°œ ìš”ì†Œ)"
        )

        # 2. AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            async_client = AsyncOpenAI(api_key=api_key)
        except Exception as e:
            logger.error(f"AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return {}

        # 3. Semaphoreë¡œ ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ (Rate Limit ëŒ€ì‘)
        semaphore = asyncio.Semaphore(max_concurrent_requests)

        # 4. ëª¨ë“  ë¹„ë™ê¸° íƒœìŠ¤í¬ ìƒì„±
        tasks = [
            self._process_single_element_async(
                async_client=async_client,
                image=image,
                element=elem,
                semaphore=semaphore,
                model_name=model_name,
            )
            for elem in target_elements
        ]

        # 5. ë³‘ë ¬ ì‹¤í–‰ (asyncio.gather)
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # 6. ê²°ê³¼ ë§¤í•‘ ë° ì˜ˆì™¸ ì²˜ë¦¬
        ai_descriptions = {}
        success_count = 0
        error_count = 0

        for element, result in zip(target_elements, results):
            if isinstance(result, Exception):
                logger.error(f"API ì‹¤íŒ¨: Element {element.element_id} - {result}")
                error_count += 1
            elif result:  # ì„±ê³µ ì‹œ (ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°)
                ai_descriptions[element.element_id] = result
                success_count += 1
                logger.info(
                    f"âœ… API ì„±ê³µ: Element {element.element_id} ({element.class_name})"
                )

        logger.info(
            f"OpenAI API ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë£Œ: "
            f"ì„±ê³µ {success_count}ê±´, ì‹¤íŒ¨ {error_count}ê±´ / ì´ {len(target_elements)}ê±´"
        )

        if db and ai_descriptions:
            saved = self._upsert_ai_descriptions(
                db=db, descriptions=ai_descriptions, model_name=model_name, prompt=None
            )
            logger.info(f"AI ì„¤ëª… {len(saved)}ê±´ ì €ì¥ ì™„ë£Œ (ë¹„ë™ê¸°)")

        return ai_descriptions

    async def _process_single_element_async(
        self,
        async_client: AsyncOpenAI,
        image: np.ndarray,
        element: models.LayoutElement,
        semaphore: asyncio.Semaphore,
        model_name: str,
    ) -> str:
        """
        ë‹¨ì¼ elementì— ëŒ€í•œ ë¹„ë™ê¸° AI ì„¤ëª… ìƒì„± (ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ í¬í•¨)

        Args:
            async_client: AsyncOpenAI í´ë¼ì´ì–¸íŠ¸
            image: ì›ë³¸ ì´ë¯¸ì§€
            element: ì²˜ë¦¬í•  ë ˆì´ì•„ì›ƒ ìš”ì†Œ
            semaphore: ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œìš© Semaphore
            model_name: ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„

        Returns:
            str: AI ìƒì„± ì„¤ëª… í…ìŠ¤íŠ¸

        ì¬ì‹œë„ ë¡œì§:
        - ìµœëŒ€ 3íšŒ ì¬ì‹œë„
        - ëŒ€ê¸° ì‹œê°„: 1ì´ˆ â†’ 2ì´ˆ â†’ 4ì´ˆ (ì§€ìˆ˜ ë°±ì˜¤í”„)
        """
        # 1. ì´ë¯¸ì§€ í¬ë¡­ ë° ê²€ì¦
        x1, y1 = element.bbox_x, element.bbox_y
        x2, y2 = x1 + element.bbox_width, y1 + element.bbox_height

        # í¬ê¸° ê²€ì¦
        if y2 <= y1 or x2 <= x1:
            logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ BBox í¬ê¸°: Element {element.element_id}")
            return ""

        # ì´ë¯¸ì§€ í¬ë¡­
        cropped_img = image[y1:y2, x1:x2]

        # 2. PIL ì´ë¯¸ì§€ ë³€í™˜ ë° Base64 ì¸ì½”ë”©
        pil_img = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
        buffered = io.BytesIO()
        pil_img.save(buffered, format="PNG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

        # 3. í”„ë¡¬í”„íŠ¸ ì„ íƒ
        prompts = {
            "figure": figure_prompt,
            "table": table_prompt,
            "flowchart": flowchart_prompt,
        }
        prompt = prompts.get(element.class_name, f"ì´ {element.class_name} ë‚´ìš© ì„¤ëª…")

        system_prompt = (
            "ë‹¹ì‹ ì€ ì‹œê° ì¥ì•  ì•„ë™ í•™ìŠµ AI ë¹„ì„œì…ë‹ˆë‹¤. "
            "ì‹œê° ìë£Œ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ê²°, ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”. "
            "ìŒì„± ë³€í™˜ ê°€ëŠ¥í•˜ê²Œ ì§ì ‘ì ì´ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•˜ì„¸ìš”."
        )

        # 4. ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë¡œì§
        max_retries = 3
        base_delay = 1.0  # ì´ˆ ë‹¨ìœ„

        async with semaphore:  # Rate Limit ì œì–´
            for attempt in range(max_retries):
                try:
                    # API í˜¸ì¶œ
                    response = await async_client.chat.completions.create(
                        model=model_name,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": prompt},
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:image/png;base64,{img_base64}"
                                        },
                                    },
                                ],
                            },
                        ],
                        temperature=0.2,
                        max_tokens=600,
                    )

                    # ì„±ê³µ ì‹œ ê²°ê³¼ ë°˜í™˜
                    description = response.choices[0].message.content.strip()
                    logger.debug(
                        f"API ì‘ë‹µ ì™„ë£Œ (ì‹œë„ {attempt + 1}/{max_retries}): "
                        f"Element {element.element_id}"
                    )
                    return description

                except openai.RateLimitError as e:
                    # Rate Limit ì˜¤ë¥˜: ì§€ìˆ˜ ë°±ì˜¤í”„ ëŒ€ê¸° í›„ ì¬ì‹œë„
                    if attempt < max_retries - 1:
                        delay = base_delay * (2**attempt)  # 1ì´ˆ â†’ 2ì´ˆ â†’ 4ì´ˆ
                        logger.warning(
                            f"âš ï¸ Rate Limit ì˜¤ë¥˜ (Element {element.element_id}): "
                            f"{delay}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt + 1}/{max_retries})"
                        )
                        await asyncio.sleep(delay)
                    else:
                        logger.error(
                            f"âŒ Rate Limit ì˜¤ë¥˜ ìµœì¢… ì‹¤íŒ¨ (Element {element.element_id}): {e}"
                        )
                        raise  # ìµœì¢… ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ì „íŒŒ

                except openai.APIError as e:
                    # API ì¼ë°˜ ì˜¤ë¥˜: ì§€ìˆ˜ ë°±ì˜¤í”„ ëŒ€ê¸° í›„ ì¬ì‹œë„
                    if attempt < max_retries - 1:
                        delay = base_delay * (2**attempt)
                        logger.warning(
                            f"âš ï¸ API ì˜¤ë¥˜ (Element {element.element_id}): "
                            f"{delay}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt + 1}/{max_retries}) - {e}"
                        )
                        await asyncio.sleep(delay)
                    else:
                        logger.error(
                            f"âŒ API ì˜¤ë¥˜ ìµœì¢… ì‹¤íŒ¨ (Element {element.element_id}): {e}"
                        )
                        raise

                except Exception as e:
                    # ê¸°íƒ€ ì˜ˆì™¸: ì¦‰ì‹œ ì‹¤íŒ¨
                    logger.error(
                        f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (Element {element.element_id}): {e}",
                        exc_info=True,
                    )
                    raise

        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜ (unreachable, but for type safety)
        return ""

    def visualize_results(
        self, image: np.ndarray, layout_elements: List[models.LayoutElement]
    ) -> np.ndarray:
        """ê²°ê³¼ ì‹œê°í™” (ê¸°ì¡´ê³¼ ë™ì¼)"""
        img_result = image.copy()
        overlay = image.copy()
        random.seed(42)
        unique_classes = list({elem.class_name for elem in layout_elements})
        class_colors = {}
        for i, cls_name in enumerate(unique_classes):
            h, s, v = i / max(1, len(unique_classes)), 0.8, 0.9
            r, g, b = colorsys.hsv_to_rgb(h, s, v)
            class_colors[cls_name] = (int(b * 255), int(g * 255), int(r * 255))
        for element in layout_elements:
            x1, y1 = element.bbox_x, element.bbox_y
            x2, y2 = x1 + element.bbox_width, y1 + element.bbox_height
            cls_name, color = element.class_name, class_colors[element.class_name]
            cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)
            cv2.rectangle(img_result, (x1, y1), (x2, y2), color, 2)
            label = f"{cls_name} ({element.confidence:.2f})"
            labelSize, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            y1_label = max(y1, labelSize[1] + 10)
            cv2.rectangle(
                img_result,
                (x1, y1_label - labelSize[1] - 10),
                (x1 + labelSize[0], y1_label),
                color,
                -1,
            )
            cv2.putText(
                img_result,
                label,
                (x1, y1_label - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
            )
        img_result = cv2.addWeighted(overlay, 0.2, img_result, 0.8, 0)
        return cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)

    async def perform_ocr_async(
        self,
        image: np.ndarray,
        layout_elements: List[models.LayoutElement],
        *,
        db: Session,
        language: str = "kor",
        use_gemini: bool = True,
        max_concurrent_requests: Optional[int] = None,
    ) -> List[models.TextContent]:
        """
        Gemini ë¹„ë™ê¸° + Tesseract ë™ê¸° í•˜ì´ë¸Œë¦¬ë“œ OCR íŒŒì´í”„ë¼ì¸.
        """
        target_classes = [
            "plain text",
            "unit",
            "question type",
            "question text",
            "question number",
            "title",
            "figure_caption",
            "table caption",
            "table footnote",
            "isolate_formula",
            "formula_caption",
            "list",
            "choices",
            "page",
            "second_question_number",
        ]
        tesseract_only_classes = {"question number", "second_question_number"}
        gemini_classes = [
            cls for cls in target_classes if cls not in tesseract_only_classes
        ]

        ocr_results: List[models.TextContent] = []
        tesseract_config = r"--oem 3 --psm 6"
        concurrency_limit = max(
            1, max_concurrent_requests or self.gemini_max_concurrency
        )

        logger.info(
            f"í•˜ì´ë¸Œë¦¬ë“œ OCR ì²˜ë¦¬ ì‹œì‘... ì´ {len(layout_elements)}ê°œ ë ˆì´ì•„ì›ƒ ìš”ì†Œ ì¤‘ OCR ëŒ€ìƒ í•„í„°ë§"
        )
        logger.info(f"  - Tesseract ì „ìš© í´ë˜ìŠ¤ (2ê°œ): {sorted(tesseract_only_classes)}")
        logger.info(f"  - Gemini API ì‚¬ìš© í´ë˜ìŠ¤ (13ê°œ): {gemini_classes}")
        logger.info(f"  - Gemini API ê°€ìš© ì—¬ë¶€: {gemini_available}")
        if gemini_available and use_gemini:
            logger.info(f"  - Gemini ë™ì‹œ ì²˜ë¦¬ ì œí•œ: {concurrency_limit}")
        detected_classes = {elem.class_name for elem in layout_elements}
        logger.info(f"  - ê°ì§€ëœ ëª¨ë“  í´ë˜ìŠ¤: {detected_classes}")

        gemini_jobs: List[GeminiOCRJob] = []
        target_count = 0
        for element in layout_elements:
            cls_name = element.class_name
            logger.debug(
                f"ë ˆì´ì•„ì›ƒ ID {element.element_id}: í´ë˜ìŠ¤ '{cls_name}' í™•ì¸ ì¤‘..."
            )
            if cls_name not in target_classes:
                logger.debug("  â†’ OCR ëŒ€ìƒ ì•„ë‹˜")
                continue

            target_count += 1
            logger.debug(
                f"  â†’ OCR ëŒ€ìƒ {target_count}: ID {element.element_id} - í´ë˜ìŠ¤ '{cls_name}'"
            )

            x1, y1 = element.bbox_x, element.bbox_y
            x2, y2 = x1 + element.bbox_width, y1 + element.bbox_height
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(image.shape[1], x2), min(image.shape[0], y2)

            if y2 <= y1 or x2 <= x1:
                logger.warning(
                    f"  â†’ ìœ íš¨í•˜ì§€ ì•Šì€ BBox í¬ê¸°: ID {element.element_id}, ê±´ë„ˆëœ€"
                )
                continue
            cropped_img = image[y1:y2, x1:x2]

            should_use_gemini = (
                use_gemini and gemini_available and cls_name in gemini_classes
            )

            if should_use_gemini:
                pil_img = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
                gemini_jobs.append(
                    GeminiOCRJob(
                        element=element,
                        cls_name=cls_name,
                        pil_image=pil_img,
                        cropped_img=cropped_img,
                    )
                )
                continue

            text = self._run_tesseract_ocr(
                cropped_img=cropped_img,
                language=language,
                config=tesseract_config,
            )
            self._store_ocr_result(
                db=db,
                ocr_results=ocr_results,
                element=element,
                text=text,
                engine_name="Tesseract",
                language=language,
                cls_name=cls_name,
            )

        if gemini_jobs:
            logger.info(
                f"Gemini OCR ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘: {len(gemini_jobs)}ê°œ ìš”ì†Œ (ë™ì‹œ {concurrency_limit})"
            )
            gemini_results = await self._execute_gemini_jobs_async(
                jobs=gemini_jobs,
                language=language,
                concurrency_limit=concurrency_limit,
            )

            for result in gemini_results:
                element = result.job.element
                cls_name = result.job.cls_name
                text = result.text
                engine_name = result.engine

                if not text:
                    warn_msg = (
                        f"âš ï¸ [{cls_name}] Gemini OCR ì‹¤íŒ¨: ID {element.element_id}"
                    )
                    if result.error:
                        warn_msg += f" - {result.error}"
                    logger.warning(warn_msg + " - Tesseractë¡œ ëŒ€ì²´")
                    text = self._run_tesseract_ocr(
                        cropped_img=result.job.cropped_img,
                        language=language,
                        config=tesseract_config,
                    )
                    engine_name = "Tesseract (Fallback)"
                else:
                    logger.debug(
                        f"  â†’ [{cls_name}] Gemini API ì‘ë‹µ ì„±ê³µ: {len(text)}ì"
                    )

                self._store_ocr_result(
                    db=db,
                    ocr_results=ocr_results,
                    element=element,
                    text=text,
                    engine_name=engine_name,
                    language=language,
                    cls_name=cls_name,
                )

        db.commit()
        for content in ocr_results:
            db.refresh(content)

        engine_summary = "í•˜ì´ë¸Œë¦¬ë“œ OCR (Tesseract + Gemini-2.5-Flash-Lite)"
        logger.info(
            f"OCR ì²˜ë¦¬ ì™„ë£Œ ({engine_summary}): {len(ocr_results)}ê°œ í…ìŠ¤íŠ¸ ë¸”ë¡ ì €ì¥"
        )
        return ocr_results

    def perform_ocr(
        self,
        image: np.ndarray,
        layout_elements: List[models.LayoutElement],
        *,
        db: Session,
        language: str = "kor",
        use_gemini: bool = True,
        max_concurrent_requests: Optional[int] = None,
    ) -> List[models.TextContent]:
        """
        ë™ê¸° í™˜ê²½ í˜¸í™˜ì„ ìœ„í•œ ë˜í¼. ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œëŠ” `await perform_ocr_async()` ì‚¬ìš©.
        """
        try:
            asyncio.get_running_loop()
        except RuntimeError:
            return asyncio.run(
                self.perform_ocr_async(
                    image,
                    layout_elements,
                    db=db,
                    language=language,
                    use_gemini=use_gemini,
                    max_concurrent_requests=max_concurrent_requests,
                )
            )
        raise RuntimeError(
            "perform_ocr()ëŠ” ë¹„ë™ê¸° ì´ë²¤íŠ¸ ë£¨í”„ ì•ˆì—ì„œ í˜¸ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
            "ëŒ€ì‹  await analysis_service.perform_ocr_async(...)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
        )

    def _run_tesseract_ocr(
        self, *, cropped_img: np.ndarray, language: str, config: str
    ) -> str:
        """Tesseract OCR ì „ì²˜ë¦¬ ë° ì‹¤í–‰."""
        gray_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)
        _, binary_img = cv2.threshold(
            gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
        )
        _ = cv2.medianBlur(binary_img, 3)  # ë…¸ì´ì¦ˆ ì œê±° (ì¶”í›„ í•„ìš” ì‹œ í™œìš©)
        pil_img = Image.fromarray(cropped_img)
        tess_lang = language or "kor+eng"
        if tess_lang == "kor":
            tess_lang = "kor+eng"
        return (
            pytesseract.image_to_string(pil_img, lang=tess_lang, config=config)
            .strip()
        )

    def _store_ocr_result(
        self,
        *,
        db: Session,
        ocr_results: List[models.TextContent],
        element: models.LayoutElement,
        text: str,
        engine_name: str,
        language: str,
        cls_name: str,
    ) -> None:
        """OCR ê²°ê³¼ DB ì €ì¥ + ë¡œê¹…."""
        normalized_text = (text or "").strip()
        if len(normalized_text) <= 1:
            logger.warning(
                f"âš ï¸ OCR ê²°ê³¼ ì—†ìŒ ({engine_name}): ID {element.element_id} ({cls_name})"
            )
            return

        db_text = self._upsert_text_content(
            db=db,
            element_id=element.element_id,
            ocr_text=normalized_text,
            ocr_engine=engine_name,
            language=language,
            ocr_confidence=None,
        )
        ocr_results.append(db_text)
        preview = normalized_text[:50].replace("\n", " ")
        logger.info(
            f"âœ… OCR ì„±ê³µ ({engine_name}): ID {element.element_id} ({cls_name}) - "
            f"'{preview}...' ({len(normalized_text)}ì)"
        )

    async def _execute_gemini_jobs_async(
        self,
        *,
        jobs: List[GeminiOCRJob],
        language: str,
        concurrency_limit: int,
    ) -> List[GeminiOCRResult]:
        """Gemini OCR ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰."""
        if not jobs:
            return []

        semaphore = asyncio.Semaphore(max(1, concurrency_limit))
        tasks = [
            self.call_gemini_ocr_async(
                job=job,
                language=language,
                semaphore=semaphore,
                max_retries=self.gemini_max_retries,
                base_delay=self.gemini_retry_base_delay,
            )
            for job in jobs
        ]
        return await asyncio.gather(*tasks)

    async def call_gemini_ocr_async(
        self,
        *,
        job: GeminiOCRJob,
        language: str,
        semaphore: asyncio.Semaphore,
        max_retries: int,
        base_delay: float,
    ) -> GeminiOCRResult:
        """ë‹¨ì¼ Gemini OCR í˜¸ì¶œ (ì„¸ë§ˆí¬ì–´ + ì¬ì‹œë„ í¬í•¨)."""
        if not gemini_available:
            return GeminiOCRResult(
                job=job, text="", error=GeminiOCRError("Gemini API ë¹„í™œì„±í™”")
            )

        retries = max(1, max_retries)
        delay = max(0.1, base_delay)

        async with semaphore:
            for attempt in range(1, retries + 1):
                try:
                    text = await asyncio.to_thread(
                        self._generate_gemini_text,
                        job.pil_image.copy(),
                        language,
                    )
                    if not text:
                        raise GeminiOCRError("Gemini ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
                    return GeminiOCRResult(job=job, text=text)

                except Exception as exc:
                    if attempt < retries:
                        wait_time = delay * (2 ** (attempt - 1))
                        logger.warning(
                            f"âš ï¸ [{job.cls_name}] Gemini OCR ì‹¤íŒ¨ (ì‹œë„ {attempt}/{retries}): "
                            f"{exc} - {wait_time:.1f}s í›„ ì¬ì‹œë„"
                        )
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error(
                            f"âŒ [{job.cls_name}] Gemini OCR ìµœì¢… ì‹¤íŒ¨: {exc}"
                        )
                        return GeminiOCRResult(job=job, text="", error=exc)

        return GeminiOCRResult(job=job, text="", error=GeminiOCRError("ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"))

    def _generate_gemini_text(
        self, pil_img: Image.Image, language: str = "kor"
    ) -> str:
        """Gemini 2.5 Flash Lite í˜¸ì¶œ."""
        if not gemini_available:
            raise GeminiOCRError("Gemini APIê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        prompt = (
            "Extract all text from this image exactly as it appears, regardless of language. "
            "Return only the plain text without any markdown formatting, translations, explanations, or additional comments."
        )
        model = genai.GenerativeModel("gemini-2.5-flash-lite")
        response = model.generate_content(
            [pil_img, prompt],
            safety_settings=GEMINI_SAFETY_SETTINGS,
        )

        candidates = getattr(response, "candidates", None)
        if not candidates:
            feedback = getattr(response, "prompt_feedback", None)
            raise GeminiOCRError(f"í›„ë³´ ì‘ë‹µ ì—†ìŒ (prompt_feedback={feedback})")

        first_candidate = candidates[0]
        parts = getattr(first_candidate.content, "parts", None)
        if not parts:
            raise GeminiOCRError("ì‘ë‹µ ì½˜í…ì¸ ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        return response.text.strip()


def analyze_page(
    *,
    page_id: int,
    image: np.ndarray,
    db: Session,
    api_key: Optional[str] = None,
    model_choice: Optional[str] = None,
) -> Dict[str, object]:
    """ë‹¨ì¼ í˜ì´ì§€ì— ëŒ€í•œ ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•œë‹¤."""
    service = AnalysisService(
        model_choice=model_choice or "SmartEyeSsen", auto_load=False
    )

    layout_elements = service.analyze_layout(
        image=image, page_id=page_id, db=db, model_choice=model_choice
    )

    text_contents = service.perform_ocr(
        image=image, layout_elements=layout_elements, db=db
    )

    ai_descriptions: Dict[int, str] = {}
    if api_key:
        ai_descriptions = service.call_openai_api(
            image=image, layout_elements=layout_elements, api_key=api_key, db=db
        )

    return {
        "layout_elements": layout_elements,
        "text_contents": text_contents,
        "ai_descriptions": ai_descriptions,
    }

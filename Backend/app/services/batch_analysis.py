"""
Project Batch Analysis Service
=============================

ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤(DB) ê¸°ë°˜ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë‚´ í˜ì´ì§€ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ 
ì •ë ¬(Question Grouping) ë° í¬ë§·íŒ…(Text Version ìƒì„±)ê¹Œì§€ ìˆ˜í–‰í•©ë‹ˆë‹¤.

íŒŒì´í”„ë¼ì¸ (í˜ì´ì§€ ë‹¨ìœ„)
1. ì´ë¯¸ì§€ ë¡œë“œ
2. AnalysisServiceë¡œ ë ˆì´ì•„ì›ƒ â†’ OCR â†’ (ì„ íƒ) AI ì„¤ëª… ìƒì„±
3. sorter.pyë¥¼ ì´ìš©í•œ ì •ë ¬ í›„ question_groups / question_elements ì €ì¥
4. TextFormatterë¡œ ìë™ í¬ë§·íŒ… â†’ text_versionsì— ìµœì‹  ë²„ì „ ê¸°ë¡

ê²°ê³¼ëŠ” í˜ì´ì§€ë³„ ìš”ì•½ ì •ë³´ì™€ í•¨ê»˜ í”„ë¡œì íŠ¸ ìƒíƒœë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.

ë³‘ë ¬ ì²˜ë¦¬ ì „ëµ
-------------
- **í˜ì´ì§€ ë ˆë²¨ ë³‘ë ¬**: ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ ë™ì‹œì— ì²˜ë¦¬ (asyncio.gather + Semaphore)
- **í˜ì´ì§€ ë‚´ë¶€ ìˆœì°¨**: ë ˆì´ì•„ì›ƒ/OCR/ì •ë ¬ì€ ë™ê¸° ì‹¤í–‰
  * Tesseract/EasyOCR ì—”ì§„ì´ ìŠ¤ë ˆë“œ ì•ˆì „í•˜ì§€ ì•Šì•„ asyncio.to_thread() ì‚¬ìš© ë¶ˆê°€
  * YOLO ëª¨ë¸ë„ ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë¬¸ì œë¡œ ë™ê¸° ì‹¤í–‰
- **I/Oë§Œ ë¹„ë™ê¸°**: ì´ë¯¸ì§€ ë¡œë”©, DB ì‘ì—…ë§Œ asyncio.to_thread() ì‚¬ìš©

ì„±ëŠ¥ íŠ¹ì„±
--------
- 10í˜ì´ì§€ ì²˜ë¦¬ ì‹œê°„: ~60-90ì´ˆ (í˜ì´ì§€ë‹¹ 6-9ì´ˆ)
- max_concurrent_pages=8ë¡œ 8ê°œ í˜ì´ì§€ ë™ì‹œ ì²˜ë¦¬
- CPU ë°”ìš´ë“œ ì‘ì—…ì´ ëŒ€ë¶€ë¶„ì´ë¯€ë¡œ CPU ì½”ì–´ ìˆ˜ì— ë¹„ë¡€í•œ ì„±ëŠ¥
"""

from __future__ import annotations

import asyncio
import io
import os
import threading
import time
from contextlib import asynccontextmanager
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import aiofiles
import cv2
import numpy as np
from loguru import logger
from PIL import Image
from sqlalchemy.orm import Session, selectinload

from ..models import LayoutElement, Page, Project
from .analysis_service import AnalysisService
from .formatter import TextFormatter
from .mock_models import MockElement
from .sorter import save_sorting_results_to_db, sort_layout_elements
from .text_version_service import create_text_version


# -----------------------------------------------------------------------------
# ë‚´ë¶€ ìƒìˆ˜ & í—¬í¼
# -----------------------------------------------------------------------------

UPLOADS_ROOT = (Path(__file__).resolve().parents[2] / "uploads").resolve()
DEFAULT_AI_CONCURRENCY = int(os.getenv("OPENAI_MAX_CONCURRENCY", "30"))  # 15 â†’ 30 (OpenAI Rate Limit 500 RPM ê³ ë ¤)
DEFAULT_MAX_CONCURRENT_PAGES = int(os.getenv("MAX_CONCURRENT_PAGES", "8"))  # CPU í™˜ê²½ ê¸°ë³¸ê°’ (GPU í™˜ê²½ì—ì„œëŠ” 16-32)

# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìºì‹œ (ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì‹±ê¸€í†¤ íŒ¨í„´)
_model_instances: Dict[str, AnalysisService] = {}
_model_lock = threading.Lock()


def _get_analysis_service(model_choice: str = "SmartEyeSsen") -> AnalysisService:
    """
    ëª¨ë¸ë³„ë¡œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ìŠ¤ë ˆë“œ ì•ˆì „í•œ Double-checked locking íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬
    ë³‘ë ¬ ì²˜ë¦¬ ì‹œì—ë„ ê° ëª¨ë¸ë‹¹ í•˜ë‚˜ì˜ ì¸ìŠ¤í„´ìŠ¤ë§Œ ìƒì„±ë©ë‹ˆë‹¤.
    
    ì´ë¥¼ í†µí•´ ë‹¤ìŒì„ ë³´ì¥í•©ë‹ˆë‹¤:
    - ë™ì¼ ëª¨ë¸ì— ëŒ€í•´ ë©”ëª¨ë¦¬ì— í•˜ë‚˜ì˜ ì¸ìŠ¤í„´ìŠ¤ë§Œ ìœ ì§€
    - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë™ì ìœ¼ë¡œ ë‹¤ë¥¸ ëª¨ë¸ ì„ íƒ ê°€ëŠ¥
    - ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ëª¨ë¸ ì¤‘ë³µ ë¡œë“œ ë°©ì§€
    - ìŠ¤ë ˆë“œ ì•ˆì „ì„± í™•ë³´
    
    Args:
        model_choice: ëª¨ë¸ ì„ íƒ (ê¸°ë³¸ê°’: "SmartEyeSsen")
        
    Returns:
        AnalysisService: ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ (ëª¨ë¸ë³„ ì‹±ê¸€í†¤)
        
    Example:
        >>> # 4ê°œ í˜ì´ì§€ ë³‘ë ¬ ì²˜ë¦¬ ì‹œ
        >>> service1 = _get_analysis_service("SmartEyeSsen")  # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        >>> service2 = _get_analysis_service("SmartEyeSsen")  # ìºì‹œëœ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
        >>> service3 = _get_analysis_service("YOLOv8")        # ë‹¤ë¥¸ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        >>> assert service1 is service2  # True
        >>> assert service1 is not service3  # True
    """
    # ë¹ ë¥¸ ê²½ë¡œ: ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ë½ ì—†ì´ ë°˜í™˜ (ì„±ëŠ¥ ìµœì í™”)
    if model_choice in _model_instances:
        logger.debug(f"âœ… ìºì‹œëœ AnalysisService ë°˜í™˜: {model_choice}")
        return _model_instances[model_choice]
    
    # Double-checked locking íŒ¨í„´
    with _model_lock:
        # ë½ íšë“ í›„ ë‹¤ì‹œ í™•ì¸ (ë‹¤ë¥¸ ìŠ¤ë ˆë“œê°€ ì´ë¯¸ ìƒì„±í–ˆì„ ìˆ˜ ìˆìŒ)
        if model_choice in _model_instances:
            logger.debug(f"âœ… ìºì‹œëœ AnalysisService ë°˜í™˜ (ë½ ë‚´ë¶€): {model_choice}")
            return _model_instances[model_choice]
        
        # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í•œ ë²ˆë§Œ)
        logger.info(f"ğŸ”§ ìƒˆ AnalysisService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘: model_choice={model_choice}")
        service = AnalysisService(model_choice=model_choice, auto_load=False)
        
        # ëª¨ë¸ ë¡œë“œ (ì´ˆê¸°í™”)
        logger.info(f"ğŸ“¦ ëª¨ë¸ ë¡œë“œ ì‹œì‘: {model_choice}")
        service._ensure_model_loaded()
        logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_choice}")
        
        # ìºì‹œì— ì €ì¥
        _model_instances[model_choice] = service
        logger.info(
            f"ğŸ’¾ AnalysisService ìºì‹œ ì™„ë£Œ: {model_choice} "
            f"(ì´ ìºì‹œëœ ëª¨ë¸ ìˆ˜: {len(_model_instances)})"
        )
        
        return service


@asynccontextmanager
async def get_async_db_session():
    """
    ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©í•  DB ì„¸ì…˜ ê´€ë¦¬ì.
    
    ì»¤ë„¥ì…˜ í’€ì—ì„œ ì„¸ì…˜ì„ ê°€ì ¸ì™€ ì¬ì‚¬ìš©í•˜ê³ ,
    ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ ë¡¤ë°± ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Yields:
        Session: SQLAlchemy ì„¸ì…˜ ê°ì²´
        
    Example:
        >>> async with get_async_db_session() as session:
        ...     page = session.query(Page).first()
        
    Note:
        ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ê° ì‘ì—…ë§ˆë‹¤ ë…ë¦½ì ì¸ ì„¸ì…˜ì„ ì‚¬ìš©í•˜ì—¬
        ì„¸ì…˜ ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    from ..database import SessionLocal
    session = SessionLocal()
    try:
        yield session
        await asyncio.to_thread(session.commit)
    except Exception:
        await asyncio.to_thread(session.rollback)
        raise
    finally:
        await asyncio.to_thread(session.close)


def _resolve_image_path(image_path: str) -> Path:
    """
    Page.image_path ê°’ì„ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    raw_path = Path(image_path)
    candidates = []

    if raw_path.is_absolute():
        candidates.append(raw_path)
    else:
        candidates.append((UPLOADS_ROOT / raw_path).resolve())
        candidates.append((Path.cwd() / "uploads" / raw_path).resolve())
        candidates.append((Path.cwd() / raw_path).resolve())

    for candidate in candidates:
        if candidate.exists():
            return candidate

    raise FileNotFoundError(
        "ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
        f"í™•ì¸ëœ ê²½ë¡œ: {[str(path) for path in candidates]}"
    )


def _load_page_image(page: Page) -> np.ndarray:
    """
    í˜ì´ì§€ ê°ì²´ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³ , í•´ìƒë„ ì •ë³´ë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.
    
    Note:
        ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. 
        ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œëŠ” _load_page_image_async() ì‚¬ìš© ê¶Œì¥.
    """
    resolved_path = _resolve_image_path(page.image_path)
    image = cv2.imread(str(resolved_path))
    if image is None:
        raise ValueError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {resolved_path}")

    height, width = image.shape[:2]
    if page.image_width != width or page.image_height != height:
        page.image_width = width
        page.image_height = height
    return image


async def _load_page_image_async(page: Page) -> np.ndarray:
    """
    ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  í•´ìƒë„ ì •ë³´ë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.
    
    ë””ìŠ¤í¬ I/Oë¥¼ ë…¼ë¸”ë¡œí‚¹ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ CPU ëŒ€ê¸° ì‹œê°„ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.
    CPU ì§‘ì•½ì ì¸ ë””ì½”ë”© ì‘ì—…ì€ ìŠ¤ë ˆë“œ í’€ë¡œ ìœ„ì„í•©ë‹ˆë‹¤.
    
    Args:
        page: í˜ì´ì§€ ê°ì²´
        
    Returns:
        np.ndarray: OpenCV í¬ë§· ì´ë¯¸ì§€ (BGR)
        
    Raises:
        FileNotFoundError: ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        ValueError: ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ
        
    Example:
        >>> image = await _load_page_image_async(page)
        >>> height, width = image.shape[:2]
    """
    resolved_path = _resolve_image_path(page.image_path)
    
    # ë¹„ë™ê¸° íŒŒì¼ ì½ê¸° (I/O ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”)
    async with aiofiles.open(resolved_path, 'rb') as f:
        image_data = await f.read()
    
    # ì´ë¯¸ì§€ ë””ì½”ë”© (CPU ë°”ìš´ë“œ ì‘ì—…ì€ ìŠ¤ë ˆë“œ í’€ë¡œ)
    def decode_image(data: bytes) -> np.ndarray:
        """PILë¡œ ë””ì½”ë”© í›„ OpenCV í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
        pil_image = Image.open(io.BytesIO(data))
        # RGB â†’ BGR ë³€í™˜ (OpenCV í¬ë§·)
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    
    image = await asyncio.to_thread(decode_image, image_data)
    
    if image is None:
        raise ValueError(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {resolved_path}")
    
    # í•´ìƒë„ ì •ë³´ ê°±ì‹ 
    height, width = image.shape[:2]
    if page.image_width != width or page.image_height != height:
        page.image_width = width
        page.image_height = height
    
    return image


def _layout_to_mock(elements: List[LayoutElement]) -> List[MockElement]:
    """
    SQLAlchemy LayoutElement ê°ì²´ë¥¼ sorterì—ì„œ ì‚¬ìš©í•˜ëŠ” MockElementë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    mock_elements: List[MockElement] = []
    for element in elements:
        mock = MockElement(
            element_id=element.element_id,
            class_name=element.class_name,
            confidence=float(element.confidence or 0.0),
            bbox_x=int(element.bbox_x),
            bbox_y=int(element.bbox_y),
            bbox_width=int(element.bbox_width),
            bbox_height=int(element.bbox_height),
            page_id=element.page_id,
        )
        mock_elements.append(mock)
    return mock_elements


def _sync_layout_runtime_fields(
    layout_elements: List[LayoutElement],
    mock_elements: List[MockElement],
) -> List[LayoutElement]:
    """
    sorterê°€ ê³„ì‚°í•œ order_in_question, group_id ë“±ì„ ì‹¤ì œ LayoutElementì— ë°˜ì˜í•©ë‹ˆë‹¤.
    """
    element_map: Dict[int, LayoutElement] = {
        elem.element_id: elem for elem in layout_elements
    }
    synced_elements: List[LayoutElement] = []

    for mock in mock_elements:
        target = element_map.get(mock.element_id)
        if not target:
            logger.warning(
                "ì •ë ¬ ê²°ê³¼ì— ì¡´ì¬í•˜ì§€ë§Œ DBì— ì—†ëŠ” element_id={}", mock.element_id
            )
            continue

        setattr(target, "order_in_question", getattr(mock, "order_in_question", None))
        setattr(target, "group_id", getattr(mock, "group_id", None))
        setattr(target, "order_in_group", getattr(mock, "order_in_group", None))
        setattr(target, "y_position", getattr(mock, "y_position", target.bbox_y))
        setattr(target, "x_position", getattr(mock, "x_position", target.bbox_x))
        setattr(
            target,
            "area",
            getattr(mock, "area", target.bbox_width * target.bbox_height),
        )
        synced_elements.append(target)

    return synced_elements


def _update_page_status(
    page: Page,
    *,
    status: str,
    processing_time: float,
) -> None:
    """
    í˜ì´ì§€ì˜ ìƒíƒœ/ì²˜ë¦¬ì‹œê°„/ë¶„ì„ ì™„ë£Œ ì‹œê°„ì„ ê°±ì‹ í•©ë‹ˆë‹¤.
    """
    page.analysis_status = status
    page.processing_time = processing_time
    page.analyzed_at = datetime.utcnow()


def _update_project_status(project: Project, status: str) -> None:
    """
    í”„ë¡œì íŠ¸ ìƒíƒœë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.
    """
    project.status = status
    project.updated_at = datetime.utcnow()


async def _process_single_page_async(
    *,
    db: Session,
    project: Project,
    page: Page,
    formatter: TextFormatter,
    analysis_service: AnalysisService,
    use_ai_descriptions: bool,
    api_key: Optional[str],
    ai_max_concurrency: int = DEFAULT_AI_CONCURRENCY,
) -> Dict[str, Any]:
    """
    ê°œë³„ í˜ì´ì§€ì— ëŒ€í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    logger.info(
        "í˜ì´ì§€ ë¶„ì„ ì‹œì‘: project_id={} / page_id={}",
        project.project_id,
        page.page_id,
    )
    page_start = time.time()

    summary: Dict[str, Any] = {
        "page_id": page.page_id,
        "page_number": page.page_number,
        "status": "error",
        "message": "",
        "layout_count": 0,
        "ocr_count": 0,
        "ai_description_count": 0,
        "processing_time": 0.0,
    }

    try:
        # ë¹„ë™ê¸° ì´ë¯¸ì§€ ë¡œë”© (I/O ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”)
        image = await _load_page_image_async(page)

        # ë ˆì´ì•„ì›ƒ ë¶„ì„ (CPU ë°”ìš´ë“œ â†’ ë™ê¸° ì‹¤í–‰)
        # âš ï¸ OCR/ëª¨ë¸ ì—”ì§„ì€ ìŠ¤ë ˆë“œ ì•ˆì „í•˜ì§€ ì•Šì•„ asyncio.to_thread() ì‚¬ìš© ë¶ˆê°€
        layout_elements = analysis_service.analyze_layout(
            image=image,
            page_id=page.page_id,
            db=db,
            model_choice=analysis_service.model_choice,
        )
        if not layout_elements:
            raise ValueError("ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        summary["layout_count"] = len(layout_elements)

        # OCR ìˆ˜í–‰ (CPU ë°”ìš´ë“œ â†’ ë™ê¸° ì‹¤í–‰)
        # âš ï¸ Tesseract/EasyOCRì€ ìŠ¤ë ˆë“œ ì•ˆì „í•˜ì§€ ì•Šì•„ asyncio.to_thread() ì‚¬ìš© ë¶ˆê°€
        text_contents = analysis_service.perform_ocr(
            image=image,
            layout_elements=layout_elements,
            db=db,
        )
        summary["ocr_count"] = len(text_contents)

        ai_descriptions: Dict[int, str] = {}
        if use_ai_descriptions:
            # API í‚¤: ìš”ì²­ íŒŒë¼ë¯¸í„° ìš°ì„ , ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
            effective_api_key = api_key or os.getenv("OPENAI_API_KEY")
            if effective_api_key:
                logger.info(f"AI ì„¤ëª… ìƒì„± ì‹œì‘: page_id={page.page_id}")
                try:
                    ai_descriptions = await analysis_service.call_openai_api_async(
                        image=image,
                        layout_elements=layout_elements,
                        api_key=effective_api_key,
                        db=db,
                        max_concurrent_requests=ai_max_concurrency,
                    )
                    summary["ai_description_count"] = len(ai_descriptions)
                    logger.info(
                        f"AI ì„¤ëª… ìƒì„± ì™„ë£Œ: {len(ai_descriptions)}ê°œ ìš”ì†Œ ì²˜ë¦¬"
                    )
                except Exception as ai_error:
                    logger.error(
                        "AI ì„¤ëª… ìƒì„± ë¹„ë™ê¸° ì²˜ë¦¬ ì‹¤íŒ¨: page_id={} / error={}",
                        page.page_id,
                        ai_error,
                    )
            else:
                logger.warning(
                    f"AI ì„¤ëª… ìƒì„± ìš”ì²­ë˜ì—ˆìœ¼ë‚˜ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤ (page_id={page.page_id})"
                )

        # ì •ë ¬ ì¤€ë¹„ (ë™ê¸° ë³€í™˜ ì‘ì—…)
        mock_elements = _layout_to_mock(layout_elements)
        
        # ì •ë ¬ (CPU ë°”ìš´ë“œ â†’ ë™ê¸° ì‹¤í–‰)
        # ë¹ ë¥¸ ê³„ì‚° ì‘ì—…ì´ë¯€ë¡œ ìŠ¤ë ˆë“œ ì˜¤ë²„í—¤ë“œ ë¶ˆí•„ìš”
        sorted_mock = sort_layout_elements(
            mock_elements,
            document_type=formatter.document_type,
            page_width=page.image_width or 0,
            page_height=page.image_height or 0,
        )
        synced_layouts = _sync_layout_runtime_fields(layout_elements, sorted_mock)

        # DB ì €ì¥ (ë™ê¸° ì‹¤í–‰ - deadlock ë°©ì§€)
        save_sorting_results_to_db(
            db,
            page.page_id,
            synced_layouts,
        )

        # í¬ë§·íŒ… (CPU ë°”ìš´ë“œ â†’ ë™ê¸° ì‹¤í–‰)
        # ë¹ ë¥¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬ì´ë¯€ë¡œ ìŠ¤ë ˆë“œ ì˜¤ë²„í—¤ë“œ ë¶ˆí•„ìš”
        formatted_text = formatter.format_page(
            synced_layouts,
            text_contents,
            ai_descriptions=ai_descriptions,
        )
        
        # í…ìŠ¤íŠ¸ ë²„ì „ ìƒì„± (DB I/O)
        create_text_version(
            db,
            page,
            formatted_text or "",
        )

        # ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸
        processing_time = time.time() - page_start
        _update_page_status(page, status="completed", processing_time=processing_time)
        summary["status"] = "completed"
        summary["processing_time"] = processing_time
        summary["message"] = "success"

        # DB ì»¤ë°‹ (ë™ê¸° ì‹¤í–‰ - deadlock ë°©ì§€)
        db.commit()
        return summary

    except Exception as error:  # pylint: disable=broad-except
        logger.error(f"í˜ì´ì§€ ë¶„ì„ ì‹¤íŒ¨: page_id={page.page_id} / error={str(error)}")
        logger.exception("ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:")  # ì „ì²´ ìŠ¤íƒ ì¶œë ¥
        
        # DB ë¡¤ë°± (ë™ê¸° ì‹¤í–‰ - deadlock ë°©ì§€)
        db.rollback()
        
        processing_time = time.time() - page_start
        _update_page_status(page, status="error", processing_time=processing_time)
        summary["processing_time"] = processing_time
        summary["message"] = str(error)
        
        # DB ì»¤ë°‹ (ë™ê¸° ì‹¤í–‰ - deadlock ë°©ì§€)
        db.commit()
        return summary


def _process_single_page(
    *,
    db: Session,
    project: Project,
    page: Page,
    formatter: TextFormatter,
    analysis_service: AnalysisService,
    use_ai_descriptions: bool,
    api_key: Optional[str],
    ai_max_concurrency: int = DEFAULT_AI_CONCURRENCY,
) -> Dict[str, Any]:
    """
    ë™ê¸° ì»¨í…ìŠ¤íŠ¸ í˜¸í™˜ìš© ë˜í¼.
    """
    return asyncio.run(
        _process_single_page_async(
            db=db,
            project=project,
            page=page,
            formatter=formatter,
            analysis_service=analysis_service,
            use_ai_descriptions=use_ai_descriptions,
            api_key=api_key,
            ai_max_concurrency=ai_max_concurrency,
        )
    )


# -----------------------------------------------------------------------------
# ê³µê°œ API
# -----------------------------------------------------------------------------


async def analyze_project_batch_async(
    db: Session,
    project_id: int,
    *,
    use_ai_descriptions: bool = True,
    api_key: Optional[str] = None,
    ai_max_concurrency: int = DEFAULT_AI_CONCURRENCY,
) -> Dict[str, Any]:
    """
    í”„ë¡œì íŠ¸ ë‚´ 'pending' ìƒíƒœ í˜ì´ì§€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ê²°ê³¼ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    logger.info("í”„ë¡œì íŠ¸ ë°°ì¹˜ ë¶„ì„ ì‹œì‘: project_id={}", project_id)
    started_at = time.time()

    project = (
        db.query(Project)
        .options(selectinload(Project.pages))
        .filter(Project.project_id == project_id)
        .one_or_none()
    )
    if not project:
        raise ValueError(f"í”„ë¡œì íŠ¸ ID {project_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    pending_pages = [
        page for page in project.pages if page.analysis_status in {"pending", "error"}
    ]
    pending_pages.sort(key=lambda p: p.page_number)

    result_summary: Dict[str, Any] = {
        "project_id": project.project_id,
        "project_status_before": project.status,
        "processed_pages": 0,
        "successful_pages": 0,
        "failed_pages": 0,
        "total_pages": len(pending_pages),
        "status": "completed" if pending_pages else "no_pending_pages",
        "page_results": [],
        "total_time": 0.0,
    }

    if not pending_pages:
        logger.warning("ë¶„ì„í•  í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. project_id={}", project.project_id)
        return result_summary

    _update_project_status(project, "in_progress")
    db.commit()

    analysis_service = _get_analysis_service()
    formatter = TextFormatter(
        doc_type_id=project.doc_type_id,
        db=db,
        use_db_rules=True,
    )

    for page in pending_pages:
        page_summary = await _process_single_page_async(
            db=db,
            project=project,
            page=page,
            formatter=formatter,
            analysis_service=analysis_service,
            use_ai_descriptions=use_ai_descriptions,
            api_key=api_key,
            ai_max_concurrency=ai_max_concurrency,
        )
        result_summary["page_results"].append(page_summary)
        result_summary["processed_pages"] += 1
        if page_summary["status"] == "completed":
            result_summary["successful_pages"] += 1
        else:
            result_summary["failed_pages"] += 1

    if result_summary["failed_pages"] == 0:
        final_status = "completed"
    elif result_summary["successful_pages"] == 0:
        final_status = "error"
    else:
        # ì¼ë¶€ ì„±ê³µ, ì¼ë¶€ ì‹¤íŒ¨ â†’ in_progressë¡œ í‘œì‹œ
        final_status = "in_progress"

    _update_project_status(project, final_status)
    db.commit()

    result_summary["status"] = final_status
    result_summary["project_status_after"] = project.status
    result_summary["total_time"] = time.time() - started_at
    logger.info(
        "í”„ë¡œì íŠ¸ ë°°ì¹˜ ë¶„ì„ ì¢…ë£Œ: project_id={} / status={} / success={} / fail={} / {:.2f}s",
        project.project_id,
        final_status,
        result_summary["successful_pages"],
        result_summary["failed_pages"],
        result_summary["total_time"],
    )
    return result_summary


def analyze_project_batch(
    db: Session,
    project_id: int,
    *,
    use_ai_descriptions: bool = True,
    api_key: Optional[str] = None,
    ai_max_concurrency: int = DEFAULT_AI_CONCURRENCY,
) -> Dict[str, Any]:
    """
    ë™ê¸° ì»¨í…ìŠ¤íŠ¸ í˜¸í™˜ìš© ë˜í¼.
    """
    return asyncio.run(
        analyze_project_batch_async(
            db=db,
            project_id=project_id,
            use_ai_descriptions=use_ai_descriptions,
            api_key=api_key,
            ai_max_concurrency=ai_max_concurrency,
        )
    )


async def analyze_project_batch_async_parallel(
    db: Session,
    project_id: int,
    *,
    use_ai_descriptions: bool = True,
    api_key: Optional[str] = None,
    ai_max_concurrency: int = DEFAULT_AI_CONCURRENCY,
    max_concurrent_pages: int = 8,
) -> Dict[str, Any]:
    """
    í”„ë¡œì íŠ¸ ë‚´ 'pending' ìƒíƒœ í˜ì´ì§€ë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ê³  ê²°ê³¼ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        project_id: í”„ë¡œì íŠ¸ ID
        use_ai_descriptions: AI ì„¤ëª… ìƒì„± ì—¬ë¶€
        api_key: OpenAI API í‚¤
        ai_max_concurrency: AI API ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜
        max_concurrent_pages: ìµœëŒ€ ë™ì‹œ ì²˜ë¦¬ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ê°’: 8)
        
    Returns:
        ë¶„ì„ ê²°ê³¼ ìš”ì•½
        
    Note:
        ê¸°ì¡´ analyze_project_batch_asyncì™€ ë™ì¼í•œ ê¸°ëŠ¥ì´ì§€ë§Œ,
        ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ ë™ì‹œì— ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ì—¬ ì†ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        max_concurrent_pages ê°’ì„ ì¡°ì •í•˜ì—¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ì— ë§ê²Œ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    logger.info(
        "í”„ë¡œì íŠ¸ ë³‘ë ¬ ë°°ì¹˜ ë¶„ì„ ì‹œì‘: project_id={}, max_concurrent={}",
        project_id,
        max_concurrent_pages,
    )
    started_at = time.time()

    project = (
        db.query(Project)
        .options(selectinload(Project.pages))
        .filter(Project.project_id == project_id)
        .one_or_none()
    )
    if not project:
        raise ValueError(f"í”„ë¡œì íŠ¸ ID {project_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    pending_pages = [
        page for page in project.pages if page.analysis_status in {"pending", "error"}
    ]
    pending_pages.sort(key=lambda p: p.page_number)

    result_summary: Dict[str, Any] = {
        "project_id": project.project_id,
        "project_status_before": project.status,
        "processed_pages": 0,
        "successful_pages": 0,
        "failed_pages": 0,
        "total_pages": len(pending_pages),
        "status": "completed" if pending_pages else "no_pending_pages",
        "page_results": [],
        "total_time": 0.0,
        "processing_mode": "parallel",
    }

    if not pending_pages:
        logger.warning("ë¶„ì„í•  í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. project_id={}", project.project_id)
        return result_summary

    _update_project_status(project, "in_progress")
    db.commit()

    analysis_service = _get_analysis_service()
    formatter = TextFormatter(
        doc_type_id=project.doc_type_id,
        db=db,
        use_db_rules=True,
    )

    # Semaphoreë¡œ ë™ì‹œ ì‹¤í–‰ ì œì–´
    semaphore = asyncio.Semaphore(max_concurrent_pages)

    async def process_with_semaphore(page: Page) -> Dict[str, Any]:
        """
        Semaphoreë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ì‹¤í–‰ ìˆ˜ë¥¼ ì œí•œí•˜ë©´ì„œ í˜ì´ì§€ ì²˜ë¦¬
        
        ê° í˜ì´ì§€ ë¶„ì„ ì‘ì—…ë§ˆë‹¤ ë…ë¦½ì ì¸ DB ì„¸ì…˜ì„ ìƒì„±í•˜ì—¬
        ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ì„¸ì…˜ ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.
        
        get_async_db_session() ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ ì‚¬ìš©í•˜ì—¬
        ìë™ commit/rollback ì²˜ë¦¬ ë° ì„¸ì…˜ ì˜¤ë²„í—¤ë“œë¥¼ ê°ì†Œì‹œí‚µë‹ˆë‹¤.
        """
        async with semaphore:
            # ë¹„ë™ê¸° DB ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©
            async with get_async_db_session() as task_db:
                # ì„¸ì…˜ì—ì„œ í˜ì´ì§€ ì¬ë¡œë“œ (ë‹¤ë¥¸ ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜¨ ê°ì²´ì´ë¯€ë¡œ)
                task_page = await asyncio.to_thread(
                    task_db.query(Page).filter(Page.page_id == page.page_id).first
                )
                task_project = await asyncio.to_thread(
                    task_db.query(Project).filter(Project.project_id == project.project_id).first
                )
                
                if not task_page or not task_project:
                    raise ValueError(f"í˜ì´ì§€ ë˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: page_id={page.page_id}")
                
                return await _process_single_page_async(
                    db=task_db,
                    project=task_project,
                    page=task_page,
                    formatter=formatter,
                    analysis_service=analysis_service,
                    use_ai_descriptions=use_ai_descriptions,
                    api_key=api_key,
                    ai_max_concurrency=ai_max_concurrency,
                )

    # ëª¨ë“  í˜ì´ì§€ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    logger.info(f"ì´ {len(pending_pages)}ê°œ í˜ì´ì§€ë¥¼ ìµœëŒ€ {max_concurrent_pages}ê°œì”© ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")
    tasks = [process_with_semaphore(page) for page in pending_pages]
    page_results = await asyncio.gather(*tasks, return_exceptions=True)

    # ê²°ê³¼ ì§‘ê³„
    for page_result in page_results:
        if isinstance(page_result, Exception):
            logger.error(f"í˜ì´ì§€ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {page_result}")
            result_summary["page_results"].append({
                "status": "error",
                "message": str(page_result),
            })
            result_summary["failed_pages"] += 1
        else:
            result_summary["page_results"].append(page_result)
            if page_result["status"] == "completed":
                result_summary["successful_pages"] += 1
            else:
                result_summary["failed_pages"] += 1
        result_summary["processed_pages"] += 1

    # ìµœì¢… ìƒíƒœ ê²°ì •
    if result_summary["failed_pages"] == 0:
        final_status = "completed"
    elif result_summary["successful_pages"] == 0:
        final_status = "error"
    else:
        # ì¼ë¶€ ì„±ê³µ, ì¼ë¶€ ì‹¤íŒ¨ â†’ in_progressë¡œ í‘œì‹œ
        final_status = "in_progress"

    _update_project_status(project, final_status)
    db.commit()

    result_summary["status"] = final_status
    result_summary["project_status_after"] = project.status
    result_summary["total_time"] = time.time() - started_at
    
    logger.info(
        "í”„ë¡œì íŠ¸ ë³‘ë ¬ ë°°ì¹˜ ë¶„ì„ ì¢…ë£Œ: project_id={} / status={} / success={} / fail={} / {:.2f}s",
        project.project_id,
        final_status,
        result_summary["successful_pages"],
        result_summary["failed_pages"],
        result_summary["total_time"],
    )
    return result_summary


def analyze_project_batch_parallel(
    db: Session,
    project_id: int,
    *,
    use_ai_descriptions: bool = True,
    api_key: Optional[str] = None,
    ai_max_concurrency: int = DEFAULT_AI_CONCURRENCY,
    max_concurrent_pages: int = DEFAULT_MAX_CONCURRENT_PAGES,
) -> Dict[str, Any]:
    """
    ë™ê¸° ì»¨í…ìŠ¤íŠ¸ í˜¸í™˜ìš© ë˜í¼ (ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „).
    """
    return asyncio.run(
        analyze_project_batch_async_parallel(
            db=db,
            project_id=project_id,
            use_ai_descriptions=use_ai_descriptions,
            api_key=api_key,
            ai_max_concurrency=ai_max_concurrency,
            max_concurrent_pages=max_concurrent_pages,
        )
    )


__all__ = [
    "analyze_project_batch",
    "analyze_project_batch_async",
    "analyze_project_batch_parallel",
    "analyze_project_batch_async_parallel",
    "_get_analysis_service",
    "_process_single_page",
    "_process_single_page_async",
    "DEFAULT_AI_CONCURRENCY",
]

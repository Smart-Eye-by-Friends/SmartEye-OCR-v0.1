#!/usr/bin/env python3
"""
SmartEye Backend ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” LAMâ†’TSPMâ†’CIM íŒŒì´í”„ë¼ì¸ì˜ ê° ë‹¨ê³„ê°€ 
ë°ì´í„°ë² ì´ìŠ¤ì— ì˜¬ë°”ë¥´ê²Œ ì €ì¥ë˜ì—ˆëŠ”ì§€ ìƒì„¸íˆ í™•ì¸í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import argparse
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional

# Django ì„¤ì •
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'smarteye.settings.development')

try:
    import django
    django.setup()
except Exception as e:
    print(f"âŒ Django ì„¤ì • ì‹¤íŒ¨: {e}")
    sys.exit(1)

# Django ëª¨ë¸ ì„í¬íŠ¸
try:
    from django.contrib.auth import get_user_model
    from django.db.models import Count, Avg, Sum, Max, Min
    from django.utils import timezone
    
    from apps.analysis.models import AnalysisJob, ProcessedImage, AnalysisResult
    from apps.files.models import SourceFile
    from apps.users.models import User as CustomUser
    
    User = get_user_model()
except ImportError as e:
    print(f"âŒ ëª¨ë¸ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    sys.exit(1)

# ìƒ‰ìƒ ì½”ë“œ
class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'

def print_colored(text: str, color: str = Colors.ENDC) -> None:
    """ìƒ‰ìƒì´ ìˆëŠ” í…ìŠ¤íŠ¸ ì¶œë ¥"""
    print(f"{color}{text}{Colors.ENDC}")

def print_header(text: str) -> None:
    """í—¤ë” ì¶œë ¥"""
    print_colored(f"\n{'='*60}", Colors.HEADER)
    print_colored(f" {text}", Colors.HEADER + Colors.BOLD)
    print_colored(f"{'='*60}", Colors.HEADER)

def print_success(text: str) -> None:
    """ì„±ê³µ ë©”ì‹œì§€ ì¶œë ¥"""
    print_colored(f"âœ… {text}", Colors.GREEN)

def print_warning(text: str) -> None:
    """ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥"""
    print_colored(f"âš ï¸  {text}", Colors.WARNING)

def print_error(text: str) -> None:
    """ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥"""
    print_colored(f"âŒ {text}", Colors.FAIL)

def print_info(text: str) -> None:
    """ì •ë³´ ë©”ì‹œì§€ ì¶œë ¥"""
    print_colored(f"â„¹ï¸  {text}", Colors.BLUE)

class DatabaseVerifier:
    """ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, verbose: bool = False):
        self.verbose = verbose
        self.errors = []
        self.warnings = []
        
    def log_verbose(self, message: str) -> None:
        """ìƒì„¸ ë¡œê·¸ ì¶œë ¥"""
        if self.verbose:
            print_colored(f"  ğŸ” {message}", Colors.CYAN)
    
    def add_error(self, message: str) -> None:
        """ì˜¤ë¥˜ ì¶”ê°€"""
        self.errors.append(message)
        print_error(message)
    
    def add_warning(self, message: str) -> None:
        """ê²½ê³  ì¶”ê°€"""
        self.warnings.append(message)
        print_warning(message)
    
    def verify_database_connection(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸"""
        print_header("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸")
        
        try:
            # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
            user_count = User.objects.count()
            print_success(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ (ì‚¬ìš©ì ìˆ˜: {user_count})")
            return True
        except Exception as e:
            self.add_error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def verify_table_structure(self) -> bool:
        """í…Œì´ë¸” êµ¬ì¡° í™•ì¸"""
        print_header("í…Œì´ë¸” êµ¬ì¡° í™•ì¸")
        
        required_models = [
            (User, "ì‚¬ìš©ì"),
            (SourceFile, "ì†ŒìŠ¤ íŒŒì¼"),
            (AnalysisJob, "ë¶„ì„ ì‘ì—…"),
            (ProcessedImage, "ì²˜ë¦¬ëœ ì´ë¯¸ì§€"),
            (AnalysisResult, "ë¶„ì„ ê²°ê³¼")
        ]
        
        all_tables_exist = True
        
        for model, name in required_models:
            try:
                count = model.objects.count()
                print_success(f"{name} í…Œì´ë¸”: {count}ê°œ ë ˆì½”ë“œ")
                self.log_verbose(f"{model.__name__} ëª¨ë¸ ì •ìƒ")
            except Exception as e:
                self.add_error(f"{name} í…Œì´ë¸” ì ‘ê·¼ ì‹¤íŒ¨: {e}")
                all_tables_exist = False
        
        return all_tables_exist
    
    def verify_data_integrity(self) -> Dict[str, Any]:
        """ë°ì´í„° ë¬´ê²°ì„± í™•ì¸"""
        print_header("ë°ì´í„° ë¬´ê²°ì„± í™•ì¸")
        
        integrity_report = {
            'total_jobs': 0,
            'completed_jobs': 0,
            'failed_jobs': 0,
            'orphaned_images': 0,
            'orphaned_results': 0,
            'missing_stages': [],
            'data_consistency': True
        }
        
        try:
            # ë¶„ì„ ì‘ì—… í†µê³„
            total_jobs = AnalysisJob.objects.count()
            completed_jobs = AnalysisJob.objects.filter(status='completed').count()
            failed_jobs = AnalysisJob.objects.filter(status='failed').count()
            
            integrity_report['total_jobs'] = total_jobs
            integrity_report['completed_jobs'] = completed_jobs
            integrity_report['failed_jobs'] = failed_jobs
            
            print_info(f"ì „ì²´ ë¶„ì„ ì‘ì—…: {total_jobs}ê°œ")
            print_info(f"ì™„ë£Œëœ ì‘ì—…: {completed_jobs}ê°œ")
            print_info(f"ì‹¤íŒ¨í•œ ì‘ì—…: {failed_jobs}ê°œ")
            
            # ê³ ì•„ ì´ë¯¸ì§€ í™•ì¸ (Jobì´ ì—†ëŠ” ProcessedImage)
            orphaned_images = ProcessedImage.objects.filter(job__isnull=True).count()
            integrity_report['orphaned_images'] = orphaned_images
            
            if orphaned_images > 0:
                self.add_warning(f"ê³ ì•„ ì²˜ë¦¬ ì´ë¯¸ì§€ {orphaned_images}ê°œ ë°œê²¬")
            else:
                print_success("ê³ ì•„ ì²˜ë¦¬ ì´ë¯¸ì§€ ì—†ìŒ")
            
            # ê³ ì•„ ê²°ê³¼ í™•ì¸ (Jobì´ ì—†ëŠ” AnalysisResult)
            orphaned_results = AnalysisResult.objects.filter(job__isnull=True).count()
            integrity_report['orphaned_results'] = orphaned_results
            
            if orphaned_results > 0:
                self.add_warning(f"ê³ ì•„ ë¶„ì„ ê²°ê³¼ {orphaned_results}ê°œ ë°œê²¬")
            else:
                print_success("ê³ ì•„ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
            
            # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì™„ì „ì„± í™•ì¸
            missing_stages = []
            required_stages = ['lam', 'tspm', 'cim']
            
            for job in AnalysisJob.objects.filter(status='completed'):
                job_stages = set(
                    ProcessedImage.objects.filter(job=job)
                    .values_list('stage', flat=True)
                    .distinct()
                )
                
                missing_job_stages = set(required_stages) - job_stages
                if missing_job_stages:
                    missing_stages.append(f"Job {job.id}: {', '.join(missing_job_stages)}")
            
            integrity_report['missing_stages'] = missing_stages
            
            if missing_stages:
                for missing in missing_stages:
                    self.add_warning(f"ëˆ„ë½ëœ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„: {missing}")
            else:
                print_success("ëª¨ë“  ì™„ë£Œëœ ì‘ì—…ì— í•„ìš”í•œ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì¡´ì¬")
                
        except Exception as e:
            self.add_error(f"ë°ì´í„° ë¬´ê²°ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            integrity_report['data_consistency'] = False
        
        return integrity_report
    
    def verify_pipeline_stages(self, job_id: Optional[int] = None) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ê²€ì¦"""
        print_header("íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ê²€ì¦")
        
        pipeline_report = {
            'lam_success_rate': 0,
            'tspm_success_rate': 0,
            'cim_success_rate': 0,
            'avg_processing_time': {},
            'stage_details': {}
        }
        
        try:
            # íŠ¹ì • ì‘ì—… ë˜ëŠ” ì „ì²´ ì‘ì—… í™•ì¸
            jobs_query = AnalysisJob.objects.all()
            if job_id:
                jobs_query = jobs_query.filter(id=job_id)
                print_info(f"Job ID {job_id} íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ í™•ì¸")
            else:
                print_info("ì „ì²´ ì‘ì—… íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ í™•ì¸")
            
            stages = ['lam', 'tspm', 'cim']
            
            for stage in stages:
                # ë‹¨ê³„ë³„ í†µê³„
                total_images = ProcessedImage.objects.filter(stage=stage)
                if job_id:
                    total_images = total_images.filter(job_id=job_id)
                
                total_count = total_images.count()
                completed_count = total_images.filter(processing_status='completed').count()
                failed_count = total_images.filter(processing_status='failed').count()
                
                success_rate = (completed_count / total_count * 100) if total_count > 0 else 0
                pipeline_report[f'{stage}_success_rate'] = success_rate
                
                print_info(f"{stage.upper()} ë‹¨ê³„:")
                print_info(f"  - ì „ì²´: {total_count}ê°œ")
                print_info(f"  - ì™„ë£Œ: {completed_count}ê°œ")
                print_info(f"  - ì‹¤íŒ¨: {failed_count}ê°œ")
                print_info(f"  - ì„±ê³µë¥ : {success_rate:.1f}%")
                
                # ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´
                stage_details = {
                    'total': total_count,
                    'completed': completed_count,
                    'failed': failed_count,
                    'success_rate': success_rate
                }
                
                # ì²˜ë¦¬ ì‹œê°„ ë¶„ì„ (ìˆëŠ” ê²½ìš°)
                if stage == 'lam':
                    # LAM ê²°ê³¼ê°€ ìˆëŠ” ì´ë¯¸ì§€ë“¤ì˜ ì²˜ë¦¬ ì‹œê°„
                    lam_images = total_images.filter(lam_results__isnull=False)
                    if lam_images.exists():
                        stage_details['has_results'] = True
                        self.log_verbose(f"LAM ê²°ê³¼ê°€ ìˆëŠ” ì´ë¯¸ì§€: {lam_images.count()}ê°œ")
                
                elif stage == 'tspm':
                    # OCR ë˜ëŠ” AI ì„¤ëª…ì´ ìˆëŠ” ì´ë¯¸ì§€ë“¤
                    from django.db import models
                    tspm_images = total_images.filter(
                        models.Q(ocr_text__isnull=False) | 
                        models.Q(ai_description__isnull=False)
                    )
                    if tspm_images.exists():
                        stage_details['has_results'] = True
                        self.log_verbose(f"TSPM ê²°ê³¼ê°€ ìˆëŠ” ì´ë¯¸ì§€: {tspm_images.count()}ê°œ")
                
                pipeline_report['stage_details'][stage] = stage_details
                
        except Exception as e:
            self.add_error(f"íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return pipeline_report
    
    def verify_final_results(self, job_id: Optional[int] = None) -> Dict[str, Any]:
        """ìµœì¢… ê²°ê³¼ ê²€ì¦"""
        print_header("ìµœì¢… ê²°ê³¼ ê²€ì¦")
        
        results_report = {
            'total_results': 0,
            'results_with_text': 0,
            'results_with_braille': 0,
            'results_with_pdf': 0,
            'avg_confidence': 0,
            'avg_elements': 0,
            'avg_processing_time': 0
        }
        
        try:
            # ë¶„ì„ ê²°ê³¼ ì¿¼ë¦¬
            results_query = AnalysisResult.objects.all()
            if job_id:
                results_query = results_query.filter(job_id=job_id)
                print_info(f"Job ID {job_id} ìµœì¢… ê²°ê³¼ í™•ì¸")
            else:
                print_info("ì „ì²´ ìµœì¢… ê²°ê³¼ í™•ì¸")
            
            total_results = results_query.count()
            results_report['total_results'] = total_results
            
            if total_results == 0:
                self.add_warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                return results_report
            
            print_info(f"ì „ì²´ ë¶„ì„ ê²°ê³¼: {total_results}ê°œ")
            
            # ê²°ê³¼ ìœ í˜•ë³„ í†µê³„
            results_with_text = results_query.exclude(text_content__isnull=True).exclude(text_content='').count()
            results_with_braille = results_query.exclude(braille_content__isnull=True).exclude(braille_content='').count()
            results_with_pdf = results_query.exclude(pdf_path__isnull=True).exclude(pdf_path='').count()
            
            results_report['results_with_text'] = results_with_text
            results_report['results_with_braille'] = results_with_braille
            results_report['results_with_pdf'] = results_with_pdf
            
            print_info(f"í…ìŠ¤íŠ¸ ê²°ê³¼ í¬í•¨: {results_with_text}ê°œ ({results_with_text/total_results*100:.1f}%)")
            print_info(f"ì ì ê²°ê³¼ í¬í•¨: {results_with_braille}ê°œ ({results_with_braille/total_results*100:.1f}%)")
            print_info(f"PDF ê²°ê³¼ í¬í•¨: {results_with_pdf}ê°œ ({results_with_pdf/total_results*100:.1f}%)")
            
            # í†µê³„ ë¶„ì„
            stats = results_query.aggregate(
                avg_confidence=Avg('confidence_score'),
                avg_elements=Avg('total_detected_elements'),
                avg_processing_time=Avg('processing_time_seconds'),
                max_confidence=Max('confidence_score'),
                min_confidence=Min('confidence_score')
            )
            
            for key, value in stats.items():
                if value is not None:
                    results_report[key] = float(value)
            
            print_info(f"í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.3f}")
            print_info(f"ì‹ ë¢°ë„ ë²”ìœ„: {stats['min_confidence']:.3f} ~ {stats['max_confidence']:.3f}")
            print_info(f"í‰ê·  íƒì§€ ìš”ì†Œ: {stats['avg_elements']:.1f}ê°œ")
            print_info(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {stats['avg_processing_time']:.1f}ì´ˆ")
            
            # ìµœê·¼ ê²°ê³¼ ìƒ˜í”Œ í‘œì‹œ
            if self.verbose:
                print_info("\nìµœê·¼ ê²°ê³¼ ìƒ˜í”Œ:")
                recent_results = results_query.order_by('-created_at')[:3]
                
                for i, result in enumerate(recent_results, 1):
                    print_info(f"  {i}. Job {result.job_id}: "
                              f"ì‹ ë¢°ë„ {result.confidence_score:.3f}, "
                              f"ìš”ì†Œ {result.total_detected_elements}ê°œ, "
                              f"ì²˜ë¦¬ì‹œê°„ {result.processing_time_seconds:.1f}ì´ˆ")
                    
                    if result.text_content:
                        preview = result.text_content[:100] + "..." if len(result.text_content) > 100 else result.text_content
                        self.log_verbose(f"     í…ìŠ¤íŠ¸: {preview}")
                        
        except Exception as e:
            self.add_error(f"ìµœì¢… ê²°ê³¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return results_report
    
    def verify_recent_activity(self, hours: int = 24) -> Dict[str, Any]:
        """ìµœê·¼ í™œë™ í™•ì¸"""
        print_header(f"ìµœê·¼ {hours}ì‹œê°„ í™œë™ í™•ì¸")
        
        activity_report = {
            'recent_jobs': 0,
            'recent_files': 0,
            'recent_results': 0,
            'active_users': 0
        }
        
        try:
            cutoff_time = timezone.now() - timedelta(hours=hours)
            
            # ìµœê·¼ ë¶„ì„ ì‘ì—…
            recent_jobs = AnalysisJob.objects.filter(created_at__gte=cutoff_time).count()
            activity_report['recent_jobs'] = recent_jobs
            print_info(f"ìµœê·¼ {hours}ì‹œê°„ ë¶„ì„ ì‘ì—…: {recent_jobs}ê°œ")
            
            # ìµœê·¼ íŒŒì¼ ì—…ë¡œë“œ
            recent_files = SourceFile.objects.filter(created_at__gte=cutoff_time).count()
            activity_report['recent_files'] = recent_files
            print_info(f"ìµœê·¼ {hours}ì‹œê°„ íŒŒì¼ ì—…ë¡œë“œ: {recent_files}ê°œ")
            
            # ìµœê·¼ ë¶„ì„ ê²°ê³¼
            recent_results = AnalysisResult.objects.filter(created_at__gte=cutoff_time).count()
            activity_report['recent_results'] = recent_results
            print_info(f"ìµœê·¼ {hours}ì‹œê°„ ë¶„ì„ ê²°ê³¼: {recent_results}ê°œ")
            
            # í™œì„± ì‚¬ìš©ì (ìµœê·¼ ì‘ì—…ì„ ìˆ˜í–‰í•œ ì‚¬ìš©ì)
            active_users = User.objects.filter(
                analysisjob__created_at__gte=cutoff_time
            ).distinct().count()
            activity_report['active_users'] = active_users
            print_info(f"ìµœê·¼ {hours}ì‹œê°„ í™œì„± ì‚¬ìš©ì: {active_users}ëª…")
            
            if recent_jobs == 0 and recent_files == 0:
                self.add_warning(f"ìµœê·¼ {hours}ì‹œê°„ ë™ì•ˆ í™œë™ì´ ì—†ìŠµë‹ˆë‹¤")
            else:
                print_success("ìµœê·¼ í™œë™ ì •ìƒ í™•ì¸")
                
        except Exception as e:
            self.add_error(f"ìµœê·¼ í™œë™ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return activity_report
    
    def generate_summary_report(self) -> Dict[str, Any]:
        """ì¢…í•© ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        print_header("ì¢…í•© ìš”ì•½ ë¦¬í¬íŠ¸")
        
        summary = {
            'timestamp': datetime.now().isoformat(),
            'total_errors': len(self.errors),
            'total_warnings': len(self.warnings),
            'database_healthy': len(self.errors) == 0,
            'overall_status': 'healthy' if len(self.errors) == 0 else 'issues_found'
        }
        
        try:
            # ì „ì²´ í†µê³„
            total_users = User.objects.count()
            total_files = SourceFile.objects.count()
            total_jobs = AnalysisJob.objects.count()
            total_images = ProcessedImage.objects.count()
            total_results = AnalysisResult.objects.count()
            
            # ì„±ê³µë¥  ê³„ì‚°
            completed_jobs = AnalysisJob.objects.filter(status='completed').count()
            success_rate = (completed_jobs / total_jobs * 100) if total_jobs > 0 else 0
            
            summary.update({
                'total_users': total_users,
                'total_files': total_files,
                'total_jobs': total_jobs,
                'total_images': total_images,
                'total_results': total_results,
                'job_success_rate': success_rate
            })
            
            print_info(f"ì „ì²´ ì‚¬ìš©ì: {total_users}ëª…")
            print_info(f"ì „ì²´ íŒŒì¼: {total_files}ê°œ")
            print_info(f"ì „ì²´ ë¶„ì„ ì‘ì—…: {total_jobs}ê°œ")
            print_info(f"ì „ì²´ ì²˜ë¦¬ ì´ë¯¸ì§€: {total_images}ê°œ")
            print_info(f"ì „ì²´ ë¶„ì„ ê²°ê³¼: {total_results}ê°œ")
            print_info(f"ì‘ì—… ì„±ê³µë¥ : {success_rate:.1f}%")
            
            if summary['database_healthy']:
                print_success("âœ… ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì–‘í˜¸")
            else:
                print_error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ì— {len(self.errors)}ê°œ ì˜¤ë¥˜ ë°œê²¬")
                
            if self.warnings:
                print_warning(f"âš ï¸ {len(self.warnings)}ê°œ ê²½ê³ ì‚¬í•­ ë°œê²¬")
                
        except Exception as e:
            self.add_error(f"ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            summary['overall_status'] = 'error'
        
        return summary
    
    def run_full_verification(self, job_id: Optional[int] = None) -> Dict[str, Any]:
        """ì „ì²´ ê²€ì¦ ì‹¤í–‰"""
        print_colored("ğŸ” SmartEye Backend ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ì‹œì‘", Colors.HEADER + Colors.BOLD)
        
        # ë‹¨ê³„ë³„ ê²€ì¦ ì‹¤í–‰
        results = {}
        
        if not self.verify_database_connection():
            print_error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë¡œ ê²€ì¦ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return {'error': 'database_connection_failed'}
        
        results['table_structure'] = self.verify_table_structure()
        results['data_integrity'] = self.verify_data_integrity()
        results['pipeline_stages'] = self.verify_pipeline_stages(job_id)
        results['final_results'] = self.verify_final_results(job_id)
        results['recent_activity'] = self.verify_recent_activity()
        results['summary'] = self.generate_summary_report()
        
        return results

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="SmartEye Backend ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python verify_database.py                    # ì „ì²´ ê²€ì¦
  python verify_database.py --job-id 5         # íŠ¹ì • ì‘ì—… ê²€ì¦
  python verify_database.py --verbose          # ìƒì„¸ ì¶œë ¥
  python verify_database.py --export report.json  # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        """
    )
    
    parser.add_argument(
        '--job-id', 
        type=int, 
        help='íŠ¹ì • ë¶„ì„ ì‘ì—… IDë¡œ ê²€ì¦ ë²”ìœ„ ì œí•œ'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='ìƒì„¸í•œ ì¶œë ¥ í‘œì‹œ'
    )
    parser.add_argument(
        '--export',
        type=str,
        help='ê²€ì¦ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥'
    )
    parser.add_argument(
        '--recent-hours',
        type=int,
        default=24,
        help='ìµœê·¼ í™œë™ í™•ì¸ ì‹œê°„ (ì‹œê°„, ê¸°ë³¸ê°’: 24)'
    )
    
    args = parser.parse_args()
    
    # ê²€ì¦ ì‹¤í–‰
    verifier = DatabaseVerifier(verbose=args.verbose)
    results = verifier.run_full_verification(job_id=args.job_id)
    
    # ê²°ê³¼ ì €ì¥
    if args.export:
        try:
            with open(args.export, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            print_success(f"ê²€ì¦ ê²°ê³¼ê°€ {args.export}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print_error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    # ì¢…ë£Œ ì½”ë“œ ì„¤ì •
    if verifier.errors:
        print_error(f"\nê²€ì¦ ì™„ë£Œ: {len(verifier.errors)}ê°œ ì˜¤ë¥˜, {len(verifier.warnings)}ê°œ ê²½ê³ ")
        sys.exit(1)
    elif verifier.warnings:
        print_warning(f"\nê²€ì¦ ì™„ë£Œ: {len(verifier.warnings)}ê°œ ê²½ê³ ")
        sys.exit(0)
    else:
        print_success("\nâœ… ëª¨ë“  ê²€ì¦ í†µê³¼!")
        sys.exit(0)

if __name__ == "__main__":
    main()

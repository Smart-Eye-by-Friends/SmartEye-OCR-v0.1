# -*- coding: utf-8 -*-
"""8.4worksheet_analysis_gradio_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wj2-UdW9uJzp-ON6vuxseGLJHsiCNk_s

# ğŸ“š í•™ìŠµì§€ ë¶„ì„ ì‹œìŠ¤í…œ Gradio ë°ëª¨

**ì‹œê° ì¥ì•  ì•„ë™ì„ ìœ„í•œ AI ê¸°ë°˜ í•™ìŠµì§€ ë¶„ì„ ë° í…ìŠ¤íŠ¸ ë³€í™˜ ì‹œìŠ¤í…œ**

## ì‹œìŠ¤í…œ êµ¬ì„±
- **LAM (Layout Analysis Module)**: DocLayout-YOLOë¥¼ ì‚¬ìš©í•œ ë ˆì´ì•„ì›ƒ ë¶„ì„
- **TSPM (Text & Scene Processing Module)**: Tesseract OCR + OpenAI Vision API
- **CIM (Content Integration Module)**: ê²°ê³¼ í†µí•© ë° ì‹œê°í™”

## ì£¼ìš” ê¸°ëŠ¥
1. ğŸ¯ í•™ìŠµì§€ ë ˆì´ì•„ì›ƒ ìë™ ë¶„ì„
2. ğŸ“ í…ìŠ¤íŠ¸ ì˜ì—­ OCR ì²˜ë¦¬
3. ğŸ–¼ï¸ ê·¸ë¦¼/í‘œ AI ì„¤ëª… ìƒì„±
4. ğŸ“„ ì ‘ê·¼ ê°€ëŠ¥í•œ ë¬¸ì„œ í˜•íƒœë¡œ ë³€í™˜

## 1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
"""

# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
!pip install -q gradio numpy opencv-python matplotlib pillow tqdm loguru rich
!pip install -q pytesseract requests transformers openai huggingface-hub

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
!apt-get update -q
!apt-get install -q -y tesseract-ocr tesseract-ocr-kor fonts-nanum

print("âœ… ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!")

# DocLayout-YOLO ì„¤ì¹˜
import os
import sys

# í˜„ì¬ ë””ë ‰í† ë¦¬ í™•ì¸
current_dir = os.getcwd()
print(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {current_dir}")

# DocLayout-YOLOê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
if not os.path.exists('DocLayout-YOLO'):
    print("DocLayout-YOLO ë‹¤ìš´ë¡œë“œ ì¤‘...")
    !git clone https://github.com/opendatalab/DocLayout-YOLO.git

    # DocLayout-YOLO ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ ì„¤ì¹˜
    os.chdir('DocLayout-YOLO')
    !pip install -q -e .

    # ì›ë˜ ë””ë ‰í† ë¦¬ë¡œ ë³µê·€
    os.chdir(current_dir)
    print("âœ… DocLayout-YOLO ì„¤ì¹˜ ì™„ë£Œ!")
else:
    print("âœ… DocLayout-YOLO ì´ë¯¸ ì„¤ì¹˜ë¨!")

# Python ê²½ë¡œì— DocLayout-YOLO ì¶”ê°€
doclayout_path = os.path.join(current_dir, 'DocLayout-YOLO')
if doclayout_path not in sys.path:
    sys.path.append(doclayout_path)

"""## 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì„¤ì •"""

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import gradio as gr
import cv2
import numpy as np
import matplotlib.pyplot as plt
import json
import torch
import time
import base64
import io
import sys
import colorsys
import random
import textwrap
import re
from collections import Counter
from PIL import Image, ImageDraw, ImageFont
from huggingface_hub import hf_hub_download
import pytesseract
import openai
from loguru import logger

# DocLayout-YOLO ì„í¬íŠ¸
try:
    from doclayout_yolo import YOLOv10
    print("âœ… DocLayout-YOLO ì„í¬íŠ¸ ì„±ê³µ!")
except ImportError as e:
    print(f"âŒ DocLayout-YOLO ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    print("ë‹¤ì‹œ ì„¤ì¹˜ë¥¼ ì‹œë„í•˜ì„¸ìš”.")

# ë¡œê·¸ ì„¤ì •
logger.remove()
logger.add(sys.stderr, level="INFO")

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
print(f"âœ… ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

print("âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!")

"""## 3. ì›Œí¬ì‹œíŠ¸ ë¶„ì„ê¸° í´ë˜ìŠ¤ ì •ì˜"""

class WorksheetAnalyzer:
    def __init__(self):
        self.model = None
        self.device = device
        self.layout_info = []
        self.ocr_results = []
        self.api_results = []

    def download_model(self, model_choice="docstructbench"):
        """ì‚¬ì „ í›ˆë ¨ëœ DocLayout-YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        models = {
            "doclaynet_docsynth": {
                "repo_id": "juliozhao/DocLayout-YOLO-DocLayNet-Docsynth300K_pretrained",
                "filename": "doclayout_yolo_doclaynet_imgsz1120_docsynth_pretrain.pt"
            },
            "docstructbench": {
                "repo_id": "juliozhao/DocLayout-YOLO-DocStructBench",
                "filename": "doclayout_yolo_docstructbench_imgsz1024.pt"
            },
            "docsynth300k": {
                "repo_id": "juliozhao/DocLayout-YOLO-DocSynth300K-pretrain",
                "filename": "doclayout_yolo_docsynth300k_imgsz1600.pt"
            },
            "SmartEyeSsen": {
                "repo_id": "AkJeond/SmartEyeSsen",
                "filename": "best_tuned_model.pt"
            }
        }

        selected_model = models.get(model_choice, models["docstructbench"])

        try:
            logger.info(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {selected_model['repo_id']}")
            filepath = hf_hub_download(
                repo_id=selected_model["repo_id"],
                filename=selected_model["filename"]
            )
            logger.info(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filepath}")
            return filepath
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def load_model(self, model_path):
        """DocLayout-YOLO ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info("ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.model = YOLOv10(model_path, task='predict')
            self.model.to(self.device)
            if hasattr(self.model, 'training'):
                self.model.training = False
            logger.info("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            return True
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

print("âœ… WorksheetAnalyzer í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!")

# WorksheetAnalyzer í´ë˜ìŠ¤ ë©”ì„œë“œ ì¶”ê°€ (ë ˆì´ì•„ì›ƒ ë¶„ì„)
def analyze_layout(self, image, model_choice="SmartEyeSsen"):
    """ë ˆì´ì•„ì›ƒ ë¶„ì„"""
    try:
        logger.info("ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œì‘...")

        # ì„ì‹œ ì´ë¯¸ì§€ ì €ì¥
        temp_path = "temp_image.jpg"
        cv2.imwrite(temp_path, image)

        # ëª¨ë¸ ì„¤ì •
        if model_choice == "SmartEyeSsen":
            imgsz = 1024
            conf = 0.25
        elif model_choice == "docsynth300k":
            imgsz = 1600
            conf = 0.15
        else:  # doclaynet_docsynth
            imgsz = 1024
            conf = 0.25

        # ë¶„ì„ ì‹¤í–‰
        results = self.model.predict(
            temp_path,
            imgsz=imgsz,
            conf=conf,
            iou=0.45,
            device=self.device
        )

        # ê²°ê³¼ ì¶”ì¶œ
        boxes = results[0].boxes.xyxy.cpu().numpy()
        classes = results[0].boxes.cls.cpu().numpy()
        confs = results[0].boxes.conf.cpu().numpy()
        class_names = self.model.names

        layout_info = []
        for i, (box, cls, conf) in enumerate(zip(boxes, classes, confs)):
            x1, y1, x2, y2 = map(int, box)
            cls_id = int(cls)

            try:
                cls_name = class_names[cls_id]
            except IndexError:
                cls_name = f"unknown_{cls_id}"

            area = (x2 - x1) * (y2 - y1)
            if area < 100:  # ë„ˆë¬´ ì‘ì€ ì˜ì—­ ì œì™¸
                continue

            layout_info.append({
                'id': i,
                'class_name': cls_name,
                'confidence': float(conf),
                'box': [int(x1), int(y1), int(x2), int(y2)],
                'width': int(x2 - x1),
                'height': int(y2 - y1),
                'area': area
            })

        self.layout_info = layout_info
        logger.info(f"ë ˆì´ì•„ì›ƒ ë¶„ì„ ì™„ë£Œ: {len(layout_info)}ê°œ ì˜ì—­ ê°ì§€")
        return layout_info

    except Exception as e:
        logger.error(f"ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return []

# ë©”ì„œë“œë¥¼ í´ë˜ìŠ¤ì— ë°”ì¸ë”©
WorksheetAnalyzer.analyze_layout = analyze_layout

print("âœ… ë ˆì´ì•„ì›ƒ ë¶„ì„ ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ!")

# WorksheetAnalyzer í´ë˜ìŠ¤ ë©”ì„œë“œ ì¶”ê°€ (OCR ì²˜ë¦¬)
def perform_ocr(self, image):
    """OCR ì²˜ë¦¬"""
    target_classes = [
        'title', 'plain text', 'abandon text',
        'table caption', 'table footnote',
        'isolated formula', 'formula caption', 'question type',
        'question text', 'question number'
    ]

    ocr_results = []
    custom_config = r'--oem 3 --psm 6'

    logger.info("OCR ì²˜ë¦¬ ì‹œì‘...")

    for layout in self.layout_info:
        cls_name = layout['class_name'].lower()
        if cls_name not in target_classes:
            continue

        x1, y1, x2, y2 = layout['box']
        x1 = max(0, x1)
        y1 = max(0, y1)
        x2 = min(image.shape[1], x2)
        y2 = min(image.shape[0], y2)

        cropped_img = image[y1:y2, x1:x2]

        try:
            pil_img = Image.fromarray(cropped_img)
            text = pytesseract.image_to_string(
                pil_img,
                lang='kor+eng',
                config=custom_config
            ).strip()

            if len(text) > 1:
                ocr_results.append({
                    'id': layout['id'],
                    'class_name': cls_name,
                    'coordinates': [x1, y1, x2, y2],
                    'text': text
                })
                logger.info(f"OCR ì™„ë£Œ: ID {layout['id']} - {len(text)}ì")

        except Exception as e:
            logger.error(f"OCR ì‹¤íŒ¨: ID {layout['id']} - {e}")

    self.ocr_results = ocr_results
    logger.info(f"OCR ì²˜ë¦¬ ì™„ë£Œ: {len(ocr_results)}ê°œ í…ìŠ¤íŠ¸ ë¸”ë¡")
    return ocr_results

# ë©”ì„œë“œë¥¼ í´ë˜ìŠ¤ì— ë°”ì¸ë”©
WorksheetAnalyzer.perform_ocr = perform_ocr

print("âœ… OCR ì²˜ë¦¬ ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ!")

# WorksheetAnalyzer í´ë˜ìŠ¤ ë©”ì„œë“œ ì¶”ê°€ (OpenAI API)
def call_openai_api(self, image, api_key):
    """OpenAI Vision API í˜¸ì¶œ"""
    if not api_key:
        logger.warning("API í‚¤ê°€ ì œê³µë˜ì§€ ì•Šì•„ AI ì„¤ëª…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return []

    target_classes = ['figure', 'table']
    api_results = []

    try:
        client = openai.OpenAI(api_key=api_key)
        logger.info("OpenAI API ì²˜ë¦¬ ì‹œì‘...")
    except Exception as e:
        logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return []

    prompts = {
        'figure': "ì´ ê·¸ë¦¼(figure)ì˜ ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ ì£¼ì„¸ìš”.",
        'table': "ì´ í‘œ(table)ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”."
    }

    system_prompt = """ë‹¹ì‹ ì€ ì‹œê° ì¥ì•  ì•„ë™ì„ ìœ„í•œ í•™ìŠµ AI ë¹„ì„œì…ë‹ˆë‹¤.
ì‹œê° ìë£Œì˜ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì„¤ëª…ì€ ìŒì„±ìœ¼ë¡œ ë³€í™˜ë  ìˆ˜ ìˆë„ë¡ ì§ì ‘ì ì´ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    for layout in self.layout_info:
        cls_name = layout['class_name'].lower()
        if cls_name not in target_classes:
            continue

        x1, y1, x2, y2 = layout['box']
        cropped_img = image[y1:y2, x1:x2]

        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        pil_img = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
        buffered = io.BytesIO()
        pil_img.save(buffered, format="PNG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

        prompt = prompts.get(cls_name, f"ì´ {cls_name}ì˜ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.")

        try:
            response = client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_base64}"}}
                        ]
                    }
                ],
                temperature=0.2,
                max_tokens=600
            )

            description = response.choices[0].message.content.strip()

            api_results.append({
                'id': layout['id'],
                'class_name': cls_name,
                'coordinates': [x1, y1, x2, y2],
                'description': description
            })

            logger.info(f"API ì‘ë‹µ ì™„ë£Œ: ID {layout['id']} - {cls_name}")

        except Exception as e:
            logger.error(f"API ìš”ì²­ ì‹¤íŒ¨: ID {layout['id']} - {e}")

    self.api_results = api_results
    logger.info(f"OpenAI API ì²˜ë¦¬ ì™„ë£Œ: {len(api_results)}ê°œ ì„¤ëª… ìƒì„±")
    return api_results

# ë©”ì„œë“œë¥¼ í´ë˜ìŠ¤ì— ë°”ì¸ë”©
WorksheetAnalyzer.call_openai_api = call_openai_api

print("âœ… OpenAI API ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ!")

# WorksheetAnalyzer í´ë˜ìŠ¤ ë©”ì„œë“œ ì¶”ê°€ (ì‹œê°í™”)
def visualize_results(self, image):
    """ê²°ê³¼ ì‹œê°í™”"""
    img_result = image.copy()
    overlay = image.copy()

    # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ìƒì„±
    random.seed(42)

    unique_classes = list(set(layout['class_name'] for layout in self.layout_info))
    class_colors = {}

    for i, cls_name in enumerate(unique_classes):
        h = i / max(1, len(unique_classes))
        s = 0.8
        v = 0.9
        r, g, b = colorsys.hsv_to_rgb(h, s, v)
        class_colors[cls_name] = (int(b * 255), int(g * 255), int(r * 255))

    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    for layout in self.layout_info:
        x1, y1, x2, y2 = layout['box']
        cls_name = layout['class_name']
        color = class_colors[cls_name]

        # ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´
        cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)

        # í…Œë‘ë¦¬
        cv2.rectangle(img_result, (x1, y1), (x2, y2), color, 2)

        # ë¼ë²¨
        label = f"{cls_name} ({layout['confidence']:.2f})"
        labelSize, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
        y1_label = max(y1, labelSize[1] + 10)

        cv2.rectangle(
            img_result,
            (x1, y1_label - labelSize[1] - 10),
            (x1 + labelSize[0], y1_label),
            color,
            -1
        )

        cv2.putText(
            img_result,
            label,
            (x1, y1_label - 5),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (255, 255, 255),
            1
        )

    # ë°˜íˆ¬ëª… ì ìš©
    img_result = cv2.addWeighted(overlay, 0.2, img_result, 0.8, 0)

    return cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)

def create_text_visualization(self, image):
    """í…ìŠ¤íŠ¸ê°€ ì‚½ì…ëœ ë¬¸ì„œ ì‹œê°í™”"""
    canvas_height, canvas_width = image.shape[:2]
    canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255

    # OCR ë° API ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    for result in self.ocr_results + self.api_results:
        x1, y1, x2, y2 = result['coordinates']
        cv2.rectangle(canvas, (x1, y1), (x2, y2), (0, 0, 0), 2)

    # PILë¡œ ë³€í™˜í•˜ì—¬ í•œê¸€ í…ìŠ¤íŠ¸ ì¶”ê°€
    canvas_pil = Image.fromarray(cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(canvas_pil)

    try:
        font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
        font = ImageFont.truetype(font_path, 50)
    except:
        font = ImageFont.load_default()

    # í…ìŠ¤íŠ¸ ì¶”ê°€
    for result in self.ocr_results:
        x1, y1, x2, y2 = result['coordinates']
        text = result['text'].replace('\n', ' ')
        if len(text) > 50:
            text = text[:50] + "..."
        draw.text((x1 + 5, y1 + 5), text, font=font, fill=(0, 0, 0))

    for result in self.api_results:
        x1, y1, x2, y2 = result['coordinates']
        text = result['description'].replace('\n', ' ')
        if len(text) > 50:
            text = text[:50] + "..."
        draw.text((x1 + 5, y1 + 5), text, font=font, fill=(0, 0, 0))

    return np.array(canvas_pil)

# ë©”ì„œë“œë¥¼ í´ë˜ìŠ¤ì— ë°”ì¸ë”©
WorksheetAnalyzer.visualize_results = visualize_results
WorksheetAnalyzer.create_text_visualization = create_text_visualization

print("âœ… ì‹œê°í™” ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ!")

# WorksheetAnalyzer í´ë˜ìŠ¤ ë©”ì„œë“œ ì¶”ê°€ (JSON ê²°ê³¼ ìƒì„±)
def get_analysis_json(self):
    """ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ í†µí•©"""
    analysis_data = {
        "layout_analysis": [],
        "ocr_results": [],
        "api_results": []
    }

    # ë ˆì´ì•„ì›ƒ ì •ë³´ ì¶”ê°€
    for layout in self.layout_info:
        analysis_data["layout_analysis"].append({
            "id": layout['id'],
            "class_name": layout['class_name'],
            "confidence": layout['confidence'],
            "box": layout['box'],
            "width": layout['width'],
            "height": layout['height'],
            "area": layout['area']
        })

    # OCR ê²°ê³¼ ì¶”ê°€ (í•´ë‹¹ ë ˆì´ì•„ì›ƒ IDì™€ ë§¤í•‘)
    ocr_dict = {result['id']: result for result in self.ocr_results}
    for layout in self.layout_info:
        if layout['id'] in ocr_dict:
             analysis_data["ocr_results"].append({
                 "layout_id": layout['id'],
                 "class_name": layout['class_name'], # OCR ê²°ê³¼ì— í´ë˜ìŠ¤ëª… ì¶”ê°€
                 "coordinates": layout['box'], # OCR ê²°ê³¼ì— ì¢Œí‘œ ì¶”ê°€
                 "text": ocr_dict[layout['id']]['text']
             })


    # API ê²°ê³¼ ì¶”ê°€ (í•´ë‹¹ ë ˆì´ì•„ì›ƒ IDì™€ ë§¤í•‘)
    api_dict = {result['id']: result for result in self.api_results}
    for layout in self.layout_info:
         if layout['id'] in api_dict:
              analysis_data["api_results"].append({
                  "layout_id": layout['id'],
                  "class_name": layout['class_name'], # API ê²°ê³¼ì— í´ë˜ìŠ¤ëª… ì¶”ê°€
                  "coordinates": layout['box'], # API ê²°ê³¼ì— ì¢Œí‘œ ì¶”ê°€
                  "description": api_dict[layout['id']]['description']
              })

    # Pretty print JSON
    return json.dumps(analysis_data, indent=4, ensure_ascii=False)

# ë©”ì„œë“œë¥¼ í´ë˜ìŠ¤ì— ë°”ì¸ë”©
WorksheetAnalyzer.get_analysis_json = get_analysis_json

print("âœ… JSON ê²°ê³¼ ìƒì„± ë©”ì„œë“œ ì¶”ê°€ ì™„ë£Œ!")

"""## 4. ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜"""

# ê¸°ì¡´ process_worksheet í•¨ìˆ˜ë¥¼ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •í•©ë‹ˆë‹¤.

def process_worksheet(image, model_choice, api_key, progress=gr.Progress()):
    """ì „ì²´ ì›Œí¬ì‹œíŠ¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    if image is None:
        # ì´ë¯¸ì§€ ì…ë ¥ì´ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ì™€ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
        return None, None, "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", "", "", None, None # Added None for the file path

    try:
        progress(0.1, desc="ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")

        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
        model_path = analyzer.download_model(model_choice)
        if not analyzer.load_model(model_path):
            # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ì™€ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return None, None, "ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "", "", None, None # Added None for the file path

        progress(0.3, desc="ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ë ˆì´ì•„ì›ƒ ë¶„ì„ ì¤‘...")

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        if isinstance(image, str):
            img = cv2.imread(image)
        else:
            # PIL ì´ë¯¸ì§€ë¥¼ OpenCV BGR í˜•íƒœë¡œ ë³€í™˜
            img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

        # ë ˆì´ì•„ì›ƒ ë¶„ì„
        layout_info = analyzer.analyze_layout(img, model_choice)
        if not layout_info:
            # ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ì™€ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return cv2.cvtColor(img, cv2.COLOR_BGR2RGB), None, "ë ˆì´ì•„ì›ƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê°ì§€ëœ ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.", "", "", None, None # Added None for the file path

        progress(0.5, desc="OCR ì²˜ë¦¬ ì¤‘...")

        # OCR ì²˜ë¦¬
        analyzer.perform_ocr(img) # ocr_resultsëŠ” selfì— ì €ì¥ë¨

        progress(0.7, desc="AI ì„¤ëª… ìƒì„± ì¤‘...")

        # OpenAI API ì²˜ë¦¬
        if api_key and api_key.strip():
             analyzer.call_openai_api(img, api_key) # api_resultsëŠ” selfì— ì €ì¥ë¨
        else:
             analyzer.api_results = [] # API í‚¤ ì—†ìœ¼ë©´ ê²°ê³¼ ì´ˆê¸°í™”

        progress(0.8, desc="ê²°ê³¼ ì‹œê°í™”, JSON ìƒì„± ì¤‘...")

        # ë ˆì´ì•„ì›ƒ ì‹œê°í™”
        layout_viz = analyzer.visualize_results(img)

        # CIM ê²°ê³¼ ì´ë¯¸ì§€ ì‹œê°í™” ì¶”ê°€
        text_viz = analyzer.create_text_visualization(img)

        # JSON ê²°ê³¼ ìƒì„±
        json_output_str = analyzer.get_analysis_json()

        # JSON ë¬¸ìì—´ì„ íŒŒì¼ë¡œ ì €ì¥ (Gradio File ì»´í¬ë„ŒíŠ¸ ì¶œë ¥ì„ ìœ„í•´)
        json_filepath = "./analysis_result.json"
        with open(json_filepath, "w", encoding='utf-8') as f:
             f.write(json_output_str)


        # í†µê³„ ìƒì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        stats = f"""ğŸ“Š ë¶„ì„ ê²°ê³¼ í†µê³„:
â€¢ ì´ ê°ì§€ëœ ë ˆì´ì•„ì›ƒ ìš”ì†Œ: {len(layout_info)}ê°œ
â€¢ OCR ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ë¸”ë¡: {len(analyzer.ocr_results)}ê°œ
â€¢ AI ì„¤ëª… ìƒì„±ëœ ì´ë¯¸ì§€/í‘œ: {len(analyzer.api_results)}ê°œ

ğŸ“‹ ê°ì§€ëœ ë ˆì´ì•„ì›ƒ í´ë˜ìŠ¤:
"""

        class_counts = Counter(item['class_name'] for item in layout_info)
        for cls, count in class_counts.items():
            stats += f"â€¢ {cls}: {count}ê°œ\n"

        # OCR ê²°ê³¼ í…ìŠ¤íŠ¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        ocr_text = "ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸:\n\n"
        if analyzer.ocr_results:
            for i, result in enumerate(analyzer.ocr_results):
                preview = result['text'][:100].replace('\n', ' ') + "..." if len(result['text']) > 100 else result['text'].replace('\n', ' ')
                ocr_text += f"[{i+1}] {result['class_name']}: {preview}\n\n"
        else:
             ocr_text += "ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"


        # AI ì„¤ëª… í…ìŠ¤íŠ¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        ai_text = "ğŸ¤– AI ìƒì„± ì„¤ëª…:\n\n"
        if analyzer.api_results:
            for i, result in enumerate(analyzer.api_results):
                preview = result['description'][:200].replace('\n', ' ') + "..." if len(result['description']) > 200 else result['description'].replace('\n', ' ')
                ai_text += f"[{i+1}] {result['class_name']}: {preview}\n\n"
        else:
             ai_text += "AI ì„¤ëª…ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (API í‚¤ í™•ì¸).\n\n"


        progress(1.0, desc="ì™„ë£Œ!")

        # ë ˆì´ì•„ì›ƒ ì‹œê°í™” ì´ë¯¸ì§€, CIM ì‹œê°í™” ì´ë¯¸ì§€, í†µê³„ ë¬¸ìì—´, OCR í…ìŠ¤íŠ¸, AI ì„¤ëª… í…ìŠ¤íŠ¸, JSON íŒŒì¼ ê²½ë¡œ ë°˜í™˜
        return layout_viz, text_viz, stats, ocr_text, ai_text, json_filepath

    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # Ensure all 6 outputs are returned even on error
        return None, None, f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", "", "", None

print("âœ… ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ ìˆ˜ì • ì™„ë£Œ (CIM ì‹œê°í™”, JSON íŒŒì¼ ì €ì¥ ë° ë°˜í™˜)!")

# ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
analyzer = WorksheetAnalyzer()

# ê¸°ì¡´ì˜ 5ê°œ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” process_worksheet í•¨ìˆ˜ ì •ì˜ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
# def process_worksheet(image, model_choice, api_key, progress=gr.Progress()):
#     """ì „ì²´ ì›Œí¬ì‹œíŠ¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
#     if image is None:
#         return None, None, "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", "", ""

#     try:
#         progress(0.1, desc="ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")

#         # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
#         model_path = analyzer.download_model(model_choice)
#         if not analyzer.load_model(model_path):
#             return None, None, "ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "", ""

#         progress(0.3, desc="ë ˆì´ì•„ì›ƒ ë¶„ì„ ì¤‘...")

#         # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
#         if isinstance(image, str):
#             img = cv2.imread(image)
#         else:
#             img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

#         # ë ˆì´ì•„ì›ƒ ë¶„ì„
#         layout_info = analyzer.analyze_layout(img, model_choice)
#         if not layout_info:
#             return None, None, "ë ˆì´ì•„ì›ƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "", ""

#         progress(0.5, desc="OCR ì²˜ë¦¬ ì¤‘...")

#         # OCR ì²˜ë¦¬
#         ocr_results = analyzer.perform_ocr(img)

#         progress(0.7, desc="AI ì„¤ëª… ìƒì„± ì¤‘...")

#         # OpenAI API ì²˜ë¦¬
#         api_results = []
#         if api_key and api_key.strip():
#             api_results = analyzer.call_openai_api(img, api_key)

#         progress(0.9, desc="ê²°ê³¼ ì‹œê°í™” ì¤‘...")

#         # ê²°ê³¼ ì‹œê°í™”
#         layout_viz = analyzer.visualize_results(img)
#         text_viz = analyzer.create_text_visualization(img)

#         # í†µê³„ ìƒì„±
#         stats = f"""ğŸ“Š ë¶„ì„ ê²°ê³¼ í†µê³„:
# â€¢ ì´ ê°ì§€ëœ ë ˆì´ì•„ì›ƒ ìš”ì†Œ: {len(layout_info)}ê°œ
# â€¢ OCR ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ë¸”ë¡: {len(ocr_results)}ê°œ
# â€¢ AI ì„¤ëª… ìƒì„±ëœ ì´ë¯¸ì§€/í‘œ: {len(api_results)}ê°œ

# ğŸ“‹ ê°ì§€ëœ ë ˆì´ì•„ì›ƒ í´ë˜ìŠ¤:
# """

#         class_counts = Counter(item['class_name'] for item in layout_info)
#         for cls, count in class_counts.items():
#             stats += f"â€¢ {cls}: {count}ê°œ\n"

#         # OCR ê²°ê³¼ í…ìŠ¤íŠ¸
#         ocr_text = "ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸:\n\n"
#         for i, result in enumerate(ocr_results):
#             preview = result['text'][:100] + "..." if len(result['text']) > 100 else result['text']
#             ocr_text += f"[{i+1}] {result['class_name']}: {preview}\n\n"

#         # AI ì„¤ëª… í…ìŠ¤íŠ¸
#         ai_text = "ğŸ¤– AI ìƒì„± ì„¤ëª…:\n\n"
#         for i, result in enumerate(api_results):
#             preview = result['description'][:200] + "..." if len(result['description']) > 200 else result['description']
#             ai_text += f"[{i+1}] {result['class_name']}: {preview}\n\n"

#         progress(1.0, desc="ì™„ë£Œ!")

#         return layout_viz, text_viz, stats, ocr_text, ai_text

#     except Exception as e:
#         logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#         return None, None, f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", "", ""

print("âœ… ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ (ìˆ˜ì •ëœ ë²„ì „ ì‚¬ìš©)!")

"""## 5. Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""

# ê¸°ì¡´ create_demo í•¨ìˆ˜ë¥¼ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •í•©ë‹ˆë‹¤.

def create_demo():
    with gr.Blocks(title="ğŸ“š í•™ìŠµì§€ ë¶„ì„ ì‹œìŠ¤í…œ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ“š í•™ìŠµì§€ ë¶„ì„ ì‹œìŠ¤í…œ (LAM + TSPM + CIM + JSON)

        **ì‹œê° ì¥ì•  ì•„ë™ì„ ìœ„í•œ AI ê¸°ë°˜ í•™ìŠµì§€ ë¶„ì„ ë° í…ìŠ¤íŠ¸ ë³€í™˜ ì‹œìŠ¤í…œ**

        ì´ ì‹œìŠ¤í…œì€ í•™ìŠµì§€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë ˆì´ì•„ì›ƒì„ íŒŒì•…í•˜ê³ , í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ë©°,
        ê·¸ë¦¼ê³¼ í‘œì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” ì‹œê°í™” ì´ë¯¸ì§€ì™€ JSON íŒŒì¼ë¡œ ì œê³µë©ë‹ˆë‹¤.
        """)

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“‹ ì…ë ¥ ì„¤ì •")

                image_input = gr.Image(
                    label="í•™ìŠµì§€ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                    type="pil",
                    height=400,
                    width=1500
                )

                model_choice = gr.Radio(
                    choices=[
                        ("DocStructBench (í•™ìŠµì§€ ìµœì í™”)", "docstructbench"),
                        ("DocLayNet-Docsynth300K (ì¼ë°˜ë¬¸ì„œ)", "doclaynet_docsynth"),
                        ("DocSynth300K (ì‚¬ì „í›ˆë ¨ëª¨ë¸)", "docsynth300k"),
                        ("SmartEyeSsen (í•™ìŠµì§€ íŒŒì¸íŠœë‹)", "SmartEyeSsen"),
                    ],
                    label="ë¶„ì„ ëª¨ë¸ ì„ íƒ",
                    value="docstructbench"
                )

                api_key = gr.Textbox(
                    label="OpenAI API Key (ì„ íƒì‚¬í•­)",
                    type="password",
                    placeholder="sk-...",
                    info="ê·¸ë¦¼ê³¼ í‘œì— ëŒ€í•œ AI ì„¤ëª… ìƒì„±ìš©"
                )

                analyze_btn = gr.Button(
                    "ğŸš€ ë¶„ì„ ì‹œì‘",
                    variant="primary",
                    size="lg"
                )

            with gr.Column(scale=2):
                gr.Markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")

                with gr.Tabs():
                    with gr.TabItem("ğŸ¯ ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œê°í™”"):
                        layout_result = gr.Image(
                            label="ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ ì´ë¯¸ì§€",
                            height=400,
                            width=1500,
                            interactive=False
                        )

                    with gr.TabItem("ğŸ“„ CIM ê²°ê³¼ ì‹œê°í™”"): # íƒ­ ì´ë¦„ ìˆ˜ì •
                        text_result = gr.Image(
                            label="CIM ë³€í™˜ ê²°ê³¼ ì´ë¯¸ì§€ (í…ìŠ¤íŠ¸/ì„¤ëª…)",
                            height=400,
                            width=1500,
                            interactive=False
                        )

                    with gr.TabItem("ğŸ“Š ì „ì²´ ë¶„ì„ ê²°ê³¼ (JSON)"): # JSON íƒ­ ì¶”ê°€
                         json_file_output = gr.File(
                             label="ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼",
                             file_count="single",
                             type="filepath",
                             interactive=False
                         )
                         gr.Markdown("ë¶„ì„ ì™„ë£Œ í›„ ìœ„ ë§í¬ì—ì„œ JSON íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


        with gr.Row():
            with gr.Column():
                stats_output = gr.Textbox(
                    label="ğŸ“Š ë¶„ì„ í†µê³„",
                    lines=10,
                    max_lines=15,
                    interactive=False
                )

            with gr.Column():
                with gr.Accordion("ğŸ“ OCR ì¶”ì¶œ í…ìŠ¤íŠ¸", open=False):
                    ocr_output = gr.Textbox(
                        label="ì¶”ì¶œëœ í…ìŠ¤íŠ¸",
                        lines=8,
                        max_lines=12,
                        interactive=False
                    )

                with gr.Accordion("ğŸ¤– í‘œ/ê·¸ë¦¼ AI ìƒì„± ì„¤ëª…", open=False):
                    ai_output = gr.Textbox(
                        label="AI ì„¤ëª…",
                        lines=8,
                        max_lines=12,
                        interactive=False
                    )

        gr.Markdown("""
        ---
        ### ğŸ“‹ ì‚¬ìš© ë°©ë²•
        1. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**: ë¶„ì„í•  í•™ìŠµì§€ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”
        2. **ëª¨ë¸ ì„ íƒ**: í•™ìŠµì§€ ë¶„ì„ì—ëŠ” 'DocStructBench' ëª¨ë¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤
        3. **API í‚¤ ì…ë ¥**: ê·¸ë¦¼/í‘œ ì„¤ëª… ìƒì„±ì„ ìœ„í•´ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)
        4. **ë¶„ì„ ì‹œì‘**: 'ğŸš€ ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ì„¸ìš”
        5. **ê²°ê³¼ í™•ì¸**: 'ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œê°í™”', 'CIM ê²°ê³¼ ì‹œê°í™”' íƒ­ì—ì„œ ì´ë¯¸ì§€ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³ , 'ì „ì²´ ë¶„ì„ ê²°ê³¼ (JSON)' íƒ­ì—ì„œ JSON íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.

        ### ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ
        - **LAM**: DocLayout-YOLOë¥¼ ì‚¬ìš©í•œ ë ˆì´ì•„ì›ƒ ë¶„ì„
        - **TSPM**: Tesseract OCR + OpenAI GPT-4Vë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ì²˜ë¦¬
        - **CIM**: ê²°ê³¼ í†µí•© ë° ì‹œê°í™”, JSON ë³€í™˜
        """)

        # ì´ë²¤íŠ¸ ë°”ì¸ë”©: ì¶œë ¥ íŒŒë¼ë¯¸í„° ìˆœì„œì— ìœ ì˜í•˜ì—¬ ì—…ë°ì´íŠ¸
        analyze_btn.click(
            fn=process_worksheet,
            inputs=[image_input, model_choice, api_key],
            outputs=[layout_result, text_result, stats_output, ocr_output, ai_output, json_file_output], # ì¶œë ¥ ì»´í¬ë„ŒíŠ¸ ìˆœì„œ ë§¤ì¹­
            show_progress=True
        )

    return demo

print("âœ… Gradio ì¸í„°í˜ì´ìŠ¤ ìˆ˜ì • ì™„ë£Œ (CIM ì´ë¯¸ì§€ ë° JSON ë‹¤ìš´ë¡œë“œ ëª¨ë‘ í¬í•¨)!")

# ë°ëª¨ ìƒì„± ë° ì‹¤í–‰ (ì´ ë¶€ë¶„ì€ ê¸°ì¡´ê³¼ ë™ì¼)
print("ğŸš€ Gradio ë°ëª¨ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

demo = create_demo()

# Colabì—ì„œ ì‹¤í–‰
demo.launch(
    server_name="0.0.0.0",  # Colabì—ì„œ ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©
    server_port=7860,
    share=True,  # ê³µê°œ ë§í¬ ìƒì„±
    debug=True,
    show_error=True
)

print("âœ… ë°ëª¨ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
print("ğŸ“± ìœ„ì˜ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ë°ëª¨ì— ì ‘ì†í•˜ì„¸ìš”.")

"""## 6. ë°ëª¨ ì‹¤í–‰

## ğŸ“ ì‚¬ìš© ì°¸ê³ ì‚¬í•­

### ğŸ”§ **ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­**
- **GPU**: CUDA ì§€ì› GPU ê¶Œì¥ (CPUë„ ê°€ëŠ¥í•˜ì§€ë§Œ ëŠë¦¼)
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 4GB RAM
- **ì¸í„°ë„·**: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° OpenAI API í˜¸ì¶œìš©

### ğŸ“Š **ì§€ì›í•˜ëŠ” ë¶„ì„ ìš”ì†Œ**
- **ë ˆì´ì•„ì›ƒ ë¶„ì„**: title, text, figure, table, formula ë“±
- **OCR ì²˜ë¦¬**: í•œêµ­ì–´/ì˜ì–´ í˜¼í•© í…ìŠ¤íŠ¸
- **AI ì„¤ëª…**: ê·¸ë¦¼ê³¼ í‘œì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…

### âš ï¸ **ì£¼ì˜ì‚¬í•­**
1. **OpenAI API í‚¤**ëŠ” ê·¸ë¦¼/í‘œ ì„¤ëª… ìƒì„±ì—ë§Œ í•„ìš” (ì„ íƒì‚¬í•­)
2. **ì²« ì‹¤í–‰ ì‹œ** ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì¸í•´ ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŒ
3. **ì´ë¯¸ì§€ í¬ê¸°**ê°€ í´ìˆ˜ë¡ ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§
4. **í•™ìŠµì§€ í’ˆì§ˆ**ì´ ì¢‹ì„ìˆ˜ë¡ ë¶„ì„ ì •í™•ë„ê°€ ë†’ì•„ì§

### ğŸ¯ **ìµœì  ì‚¬ìš©ë²•**
- **ì„ ëª…í•œ ìŠ¤ìº”ë³¸** ë˜ëŠ” **ê³ í•´ìƒë„ ì‚¬ì§„** ì‚¬ìš©
- **DocStructBench ëª¨ë¸** ê¶Œì¥ (í•™ìŠµì§€ì— ìµœì í™”)
- **API í‚¤ ì…ë ¥** ì‹œ ë” í’ë¶€í•œ ì„¤ëª… ì œê³µ
"""
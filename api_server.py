# -*- coding: utf-8 -*-
"""
SmartEyeSsen í•™ìŠµì§€ ë¶„ì„ API ì„œë²„
ê¸°ì¡´ 8_4worksheet_analysis_gradio_notebook.pyì˜ í•µì‹¬ íŒŒì´í”„ë¼ì¸ì„ FastAPIë¡œ ë³€í™˜
"""

import os
import sys
import cv2
import json
import time
import base64
import io
import colorsys
import random
from collections import Counter
from typing import Optional
from PIL import Image, ImageDraw, ImageFont
import numpy as np

# FastAPI ë° ê´€ë ¨ íŒ¨í‚¤ì§€
from fastapi import FastAPI, File, Form, UploadFile, HTTPException
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import uvicorn

# AI ë° OCR ê´€ë ¨ íŒ¨í‚¤ì§€  
import torch
from huggingface_hub import hf_hub_download
import pytesseract
import openai
from loguru import logger

# ë¡œê·¸ ì„¤ì •
logger.remove()
logger.add(sys.stderr, level="INFO")

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
print(f"âœ… ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="SmartEyeSsen í•™ìŠµì§€ ë¶„ì„ API",
    description="ì‹œê° ì¥ì•  ì•„ë™ì„ ìœ„í•œ AI ê¸°ë°˜ í•™ìŠµì§€ ë¶„ì„ ë° í…ìŠ¤íŠ¸ ë³€í™˜ ì‹œìŠ¤í…œ",
    version="1.0.0"
)

# CORS ì„¤ì • (Vue.js í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì œê³µ (ê²°ê³¼ ì´ë¯¸ì§€ ë° JSON íŒŒì¼)
os.makedirs("static", exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")


class WorksheetAnalyzer:
    """í•™ìŠµì§€ ë¶„ì„ê¸° í´ë˜ìŠ¤ - Gradio ë²„ì „ì—ì„œ ì´ì‹"""
    
    def __init__(self):
        self.model = None
        self.device = device
        self.layout_info = []
        self.ocr_results = []
        self.api_results = []

    def download_model(self, model_choice="SmartEyeSsen"):
        """ì‚¬ì „ í›ˆë ¨ëœ DocLayout-YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        models = {
            "doclaynet_docsynth": {
                "repo_id": "juliozhao/DocLayout-YOLO-DocLayNet-Docsynth300K_pretrained",
                "filename": "doclayout_yolo_doclaynet_imgsz1120_docsynth_pretrain.pt"
            },
            "docstructbench": {
                "repo_id": "juliozhao/DocLayout-YOLO-DocStructBench",
                "filename": "doclayout_yolo_docstructbench_imgsz1024.pt"
            },
            "docsynth300k": {
                "repo_id": "juliozhao/DocLayout-YOLO-DocSynth300K-pretrain",
                "filename": "doclayout_yolo_docsynth300k_imgsz1600.pt"
            },
            "SmartEyeSsen": {
                "repo_id": "AkJeond/SmartEyeSsen",
                "filename": "best_tuned_model.pt"
            }
        }

        selected_model = models.get(model_choice, models["SmartEyeSsen"])

        try:
            logger.info(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {selected_model['repo_id']}")
            filepath = hf_hub_download(
                repo_id=selected_model["repo_id"],
                filename=selected_model["filename"]
            )
            logger.info(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filepath}")
            return filepath
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def load_model(self, model_path):
        """DocLayout-YOLO ëª¨ë¸ ë¡œë“œ"""
        try:
            # DocLayout-YOLO ì„í¬íŠ¸ (ì—¬ê¸°ì„œ ì„í¬íŠ¸í•˜ì—¬ ëª¨ë¸ì´ í•„ìš”í•  ë•Œë§Œ ë¡œë“œ)
            try:
                from doclayout_yolo import YOLOv10
            except ImportError:
                logger.error("DocLayout-YOLOê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ê°€ì´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                return False

            logger.info("ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.model = YOLOv10(model_path, task='predict')
            self.model.to(self.device)
            if hasattr(self.model, 'training'):
                self.model.training = False
            logger.info("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            return True
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def analyze_layout(self, image, model_choice="SmartEyeSsen"):
        """ë ˆì´ì•„ì›ƒ ë¶„ì„"""
        try:
            logger.info("ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œì‘...")

            # ì„ì‹œ ì´ë¯¸ì§€ ì €ì¥
            temp_path = "temp_image.jpg"
            cv2.imwrite(temp_path, image)

            # ëª¨ë¸ ì„¤ì •
            if model_choice == "SmartEyeSsen":
                imgsz = 1024
                conf = 0.25
            elif model_choice == "docsynth300k":
                imgsz = 1600
                conf = 0.15
            else:  # doclaynet_docsynth
                imgsz = 1024
                conf = 0.25

            # ë¶„ì„ ì‹¤í–‰
            results = self.model.predict(
                temp_path,
                imgsz=imgsz,
                conf=conf,
                iou=0.45,
                device=self.device
            )

            # ê²°ê³¼ ì¶”ì¶œ
            boxes = results[0].boxes.xyxy.cpu().numpy()
            classes = results[0].boxes.cls.cpu().numpy()
            confs = results[0].boxes.conf.cpu().numpy()
            class_names = self.model.names

            layout_info = []
            for i, (box, cls, conf) in enumerate(zip(boxes, classes, confs)):
                x1, y1, x2, y2 = map(int, box)
                cls_id = int(cls)

                try:
                    cls_name = class_names[cls_id]
                except IndexError:
                    cls_name = f"unknown_{cls_id}"

                area = (x2 - x1) * (y2 - y1)
                if area < 100:  # ë„ˆë¬´ ì‘ì€ ì˜ì—­ ì œì™¸
                    continue

                layout_info.append({
                    'id': i,
                    'class_name': cls_name,
                    'confidence': float(conf),
                    'box': [int(x1), int(y1), int(x2), int(y2)],
                    'width': int(x2 - x1),
                    'height': int(y2 - y1),
                    'area': area
                })

            self.layout_info = layout_info
            logger.info(f"ë ˆì´ì•„ì›ƒ ë¶„ì„ ì™„ë£Œ: {len(layout_info)}ê°œ ì˜ì—­ ê°ì§€")
            return layout_info

        except Exception as e:
            logger.error(f"ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []

    def perform_ocr(self, image):
        """OCR ì²˜ë¦¬"""
        target_classes = [
            'title', 'plain text', 'abandon text',
            'table caption', 'table footnote',
            'isolated formula', 'formula caption', 'question type',
            'question text', 'question number'
        ]

        ocr_results = []
        custom_config = r'--oem 3 --psm 6'

        logger.info("OCR ì²˜ë¦¬ ì‹œì‘...")

        for layout in self.layout_info:
            cls_name = layout['class_name'].lower()
            if cls_name not in target_classes:
                continue

            x1, y1, x2, y2 = layout['box']
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(image.shape[1], x2)
            y2 = min(image.shape[0], y2)

            cropped_img = image[y1:y2, x1:x2]

            try:
                pil_img = Image.fromarray(cropped_img)
                text = pytesseract.image_to_string(
                    pil_img,
                    lang='kor+eng',
                    config=custom_config
                ).strip()

                if len(text) > 1:
                    ocr_results.append({
                        'id': layout['id'],
                        'class_name': cls_name,
                        'coordinates': [x1, y1, x2, y2],
                        'text': text
                    })
                    logger.info(f"OCR ì™„ë£Œ: ID {layout['id']} - {len(text)}ì")

            except Exception as e:
                logger.error(f"OCR ì‹¤íŒ¨: ID {layout['id']} - {e}")

        self.ocr_results = ocr_results
        logger.info(f"OCR ì²˜ë¦¬ ì™„ë£Œ: {len(ocr_results)}ê°œ í…ìŠ¤íŠ¸ ë¸”ë¡")
        return ocr_results

    def call_openai_api(self, image, api_key):
        """OpenAI Vision API í˜¸ì¶œ"""
        if not api_key:
            logger.warning("API í‚¤ê°€ ì œê³µë˜ì§€ ì•Šì•„ AI ì„¤ëª…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return []

        target_classes = ['figure', 'table']
        api_results = []

        try:
            client = openai.OpenAI(api_key=api_key)
            logger.info("OpenAI API ì²˜ë¦¬ ì‹œì‘...")
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return []

        prompts = {
            'figure': "ì´ ê·¸ë¦¼(figure)ì˜ ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ ì£¼ì„¸ìš”.",
            'table': "ì´ í‘œ(table)ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”."
        }

        system_prompt = """ë‹¹ì‹ ì€ ì‹œê° ì¥ì•  ì•„ë™ì„ ìœ„í•œ í•™ìŠµ AI ë¹„ì„œì…ë‹ˆë‹¤.
ì‹œê° ìë£Œì˜ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì„¤ëª…ì€ ìŒì„±ìœ¼ë¡œ ë³€í™˜ë  ìˆ˜ ìˆë„ë¡ ì§ì ‘ì ì´ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        for layout in self.layout_info:
            cls_name = layout['class_name'].lower()
            if cls_name not in target_classes:
                continue

            x1, y1, x2, y2 = layout['box']
            cropped_img = image[y1:y2, x1:x2]

            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            pil_img = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
            buffered = io.BytesIO()
            pil_img.save(buffered, format="PNG")
            img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

            prompt = prompts.get(cls_name, f"ì´ {cls_name}ì˜ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.")

            try:
                response = client.chat.completions.create(
                    model="gpt-4-turbo",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_base64}"}}
                            ]
                        }
                    ],
                    temperature=0.2,
                    max_tokens=600
                )

                description = response.choices[0].message.content.strip()

                api_results.append({
                    'id': layout['id'],
                    'class_name': cls_name,
                    'coordinates': [x1, y1, x2, y2],
                    'description': description
                })

                logger.info(f"API ì‘ë‹µ ì™„ë£Œ: ID {layout['id']} - {cls_name}")

            except Exception as e:
                logger.error(f"API ìš”ì²­ ì‹¤íŒ¨: ID {layout['id']} - {e}")

        self.api_results = api_results
        logger.info(f"OpenAI API ì²˜ë¦¬ ì™„ë£Œ: {len(api_results)}ê°œ ì„¤ëª… ìƒì„±")
        return api_results

    def visualize_results(self, image):
        """ê²°ê³¼ ì‹œê°í™”"""
        img_result = image.copy()
        overlay = image.copy()

        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ìƒì„±
        random.seed(42)

        unique_classes = list(set(layout['class_name'] for layout in self.layout_info))
        class_colors = {}

        for i, cls_name in enumerate(unique_classes):
            h = i / max(1, len(unique_classes))
            s = 0.8
            v = 0.9
            r, g, b = colorsys.hsv_to_rgb(h, s, v)
            class_colors[cls_name] = (int(b * 255), int(g * 255), int(r * 255))

        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for layout in self.layout_info:
            x1, y1, x2, y2 = layout['box']
            cls_name = layout['class_name']
            color = class_colors[cls_name]

            # ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´
            cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)

            # í…Œë‘ë¦¬
            cv2.rectangle(img_result, (x1, y1), (x2, y2), color, 2)

            # ë¼ë²¨
            label = f"{cls_name} ({layout['confidence']:.2f})"
            labelSize, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            y1_label = max(y1, labelSize[1] + 10)

            cv2.rectangle(
                img_result,
                (x1, y1_label - labelSize[1] - 10),
                (x1 + labelSize[0], y1_label),
                color,
                -1
            )

            cv2.putText(
                img_result,
                label,
                (x1, y1_label - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1
            )

        # ë°˜íˆ¬ëª… ì ìš©
        img_result = cv2.addWeighted(overlay, 0.2, img_result, 0.8, 0)

        return cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)

    def create_text_visualization(self, image):
        """í…ìŠ¤íŠ¸ê°€ ì‚½ì…ëœ ë¬¸ì„œ ì‹œê°í™”"""
        canvas_height, canvas_width = image.shape[:2]
        canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255

        # OCR ë° API ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for result in self.ocr_results + self.api_results:
            x1, y1, x2, y2 = result['coordinates']
            cv2.rectangle(canvas, (x1, y1), (x2, y2), (0, 0, 0), 2)

        # PILë¡œ ë³€í™˜í•˜ì—¬ í•œê¸€ í…ìŠ¤íŠ¸ ì¶”ê°€
        canvas_pil = Image.fromarray(cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(canvas_pil)

        # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (Windowsì—ì„œ)
        try:
            font = ImageDraw.getfont()
        except:
            from PIL import ImageFont
            try:
                font = ImageFont.load_default()
            except:
                font = None

        # í…ìŠ¤íŠ¸ ì¶”ê°€
        for result in self.ocr_results:
            x1, y1, x2, y2 = result['coordinates']
            text = result['text'].replace('\n', ' ')
            if len(text) > 50:
                text = text[:50] + "..."
            if font:
                draw.text((x1 + 5, y1 + 5), text, font=font, fill=(0, 0, 0))

        for result in self.api_results:
            x1, y1, x2, y2 = result['coordinates']
            text = result['description'].replace('\n', ' ')
            if len(text) > 50:
                text = text[:50] + "..."
            if font:
                draw.text((x1 + 5, y1 + 5), text, font=font, fill=(0, 0, 0))

        return np.array(canvas_pil)

    def create_cim_result(self, layout_info, ocr_results, ai_results):
        """CIM ê²°ê³¼ ìƒì„± (ì‹œê°í™” ì œê±°, JSON í†µí•©ë§Œ)"""
        from datetime import datetime
        
        # JSON í†µí•© ê²°ê³¼ ìƒì„±
        cim_result = {
            "document_structure": {
                "layout_analysis": {
                    "total_elements": len(layout_info),
                    "elements": []
                },
                "text_content": [],
                "ai_descriptions": []
            },
            "metadata": {
                "analysis_date": datetime.now().isoformat(),
                "total_text_regions": len([info for info in layout_info if 'text' in info.get('class_name', '').lower()]),
                "total_figures": len([info for info in layout_info if info.get('class_name') == 'figure']),
                "total_tables": len([info for info in layout_info if info.get('class_name') == 'table'])
            }
        }
        
        # ë ˆì´ì•„ì›ƒ ì •ë³´ í†µí•©
        for i, info in enumerate(layout_info):
            element = {
                "id": i,
                "class": info.get('class_name', 'unknown'),
                "confidence": float(info.get('confidence', 0.0)),
                "bbox": info.get('box', []),
                "area": info.get('area', 0)
            }
            
            # OCR í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
            ocr_text = None
            for ocr_result in ocr_results:
                if ocr_result.get('id') == info.get('id'):
                    ocr_text = ocr_result.get('text', '')
                    break
            
            if ocr_text and ocr_text.strip():
                element["text"] = ocr_text
                cim_result["document_structure"]["text_content"].append({
                    "element_id": i,
                    "text": ocr_text,
                    "class": info.get('class_name', 'unknown')
                })
            
            # AI ì„¤ëª…ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
            ai_description = None
            for ai_result in ai_results:
                if ai_result.get('id') == info.get('id'):
                    ai_description = ai_result.get('description', '')
                    break
            
            if ai_description and ai_description.strip():
                element["ai_description"] = ai_description
                cim_result["document_structure"]["ai_descriptions"].append({
                    "element_id": i,
                    "description": ai_description,
                    "class": info.get('class_name', 'unknown')
                })
            
            cim_result["document_structure"]["layout_analysis"]["elements"].append(element)
        
        # í†µê³„ ê³„ì‚°
        text_elements = [e for e in cim_result["document_structure"]["layout_analysis"]["elements"] if "text" in e]
        ai_elements = [e for e in cim_result["document_structure"]["layout_analysis"]["elements"] if "ai_description" in e]
        
        stats = {
            "total_elements": len(layout_info),
            "text_elements": len(text_elements),
            "ai_described_elements": len(ai_elements),
            "class_distribution": {}
        }
        
        # í´ë˜ìŠ¤ë³„ ë¶„í¬ ê³„ì‚°
        for info in layout_info:
            class_name = info.get('class_name', 'unknown')
            stats["class_distribution"][class_name] = stats["class_distribution"].get(class_name, 0) + 1
        
        return cim_result, stats


# ê¸€ë¡œë²Œ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
analyzer = WorksheetAnalyzer()


@app.post("/analyze")
async def analyze_worksheet(
    image: UploadFile = File(...),
    model_choice: str = Form("SmartEyeSsen"),
    api_key: Optional[str] = Form(None)
):
    """
    í•™ìŠµì§€ ë¶„ì„ ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        image_bytes = await image.read()
        pil_image = Image.open(io.BytesIO(image_bytes))
        
        # PIL ì´ë¯¸ì§€ë¥¼ OpenCV BGR í˜•íƒœë¡œ ë³€í™˜
        cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
        logger.info(f"ëª¨ë¸ ì„ íƒ: {model_choice}")
        model_path = analyzer.download_model(model_choice)
        
        if not analyzer.load_model(model_path):
            raise HTTPException(status_code=500, detail="ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ë ˆì´ì•„ì›ƒ ë¶„ì„
        layout_info = analyzer.analyze_layout(cv_image, model_choice)
        if not layout_info:
            raise HTTPException(status_code=400, detail="ë ˆì´ì•„ì›ƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê°ì§€ëœ ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # OCR ì²˜ë¦¬
        analyzer.perform_ocr(cv_image)
        
        # OpenAI API ì²˜ë¦¬ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
        if api_key and api_key.strip():
            analyzer.call_openai_api(cv_image, api_key)
        else:
            analyzer.api_results = []
        
        # ë ˆì´ì•„ì›ƒ ê²°ê³¼ ì‹œê°í™”
        layout_viz = analyzer.visualize_results(cv_image)
        
        # ë ˆì´ì•„ì›ƒ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        timestamp = int(time.time())
        layout_viz_path = f"static/layout_viz_{timestamp}.png"
        
        layout_viz_pil = Image.fromarray(layout_viz)
        layout_viz_pil.save(layout_viz_path)
        
        # CIM í†µí•© ê²°ê³¼ ìƒì„± (JSON ë°ì´í„°ë§Œ)
        cim_result, cim_stats = analyzer.create_cim_result(
            analyzer.layout_info, 
            analyzer.ocr_results, 
            analyzer.api_results
        )
        
        # JSON íŒŒì¼ ì €ì¥
        from datetime import datetime
        json_filename = f"analysis_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        json_filepath = f"static/{json_filename}"
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(cim_result, f, indent=2, ensure_ascii=False)
        
        # í†µê³„ ìƒì„±
        class_counts = Counter(item['class_name'] for item in layout_info)
        stats = {
            "total_layout_elements": len(layout_info),
            "ocr_text_blocks": len(analyzer.ocr_results),
            "ai_descriptions": len(analyzer.api_results),
            "class_counts": dict(class_counts),
            "cim_stats": cim_stats
        }
        
        # OCR í…ìŠ¤íŠ¸ í†µí•© (í¸ì§‘ ê°€ëŠ¥í•œ í˜•íƒœë¡œ)
        combined_ocr_text = ""
        for result in analyzer.ocr_results:
            combined_ocr_text += f"[{result['class_name']}]\n{result['text']}\n\n"
        
        # AI ì„¤ëª… í†µí•©
        combined_ai_text = ""
        for result in analyzer.api_results:
            combined_ai_text += f"[{result['class_name']}]\n{result['description']}\n\n"
        
        return JSONResponse({
            "success": True,
            "layout_image_url": f"/{layout_viz_path}",
            "json_url": f"/{json_filepath}",
            "stats": stats,
            "ocr_results": analyzer.ocr_results,
            "ai_results": analyzer.api_results,
            "ocr_text": combined_ocr_text.strip(),
            "ai_text": combined_ai_text.strip(),
            "timestamp": timestamp
        })
        
    except Exception as e:
        logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "message": "SmartEyeSsen í•™ìŠµì§€ ë¶„ì„ API",
        "version": "1.0.0",
        "device": device,
        "available_models": [
            "SmartEyeSsen",
            "docstructbench", 
            "doclaynet_docsynth",
            "docsynth300k"
        ]
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "device": device}


if __name__ == "__main__":
    print("ğŸš€ SmartEyeSsen API ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8000 ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”")
    print(f"ğŸ“š API ë¬¸ì„œëŠ” http://localhost:8000/docs ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )

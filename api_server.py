# -*- coding: utf-8 -*-
"""
SmartEyeSsen í•™ìŠµì§€ ë¶„ì„ API ì„œë²„
ê¸°ì¡´ 8_4worksheet_analysis_gradio_notebook.pyì˜ í•µì‹¬ íŒŒì´í”„ë¼ì¸ì„ FastAPIë¡œ ë³€í™˜
"""

import os
import sys
import cv2
import json
import time
import base64
import io
import colorsys
import random
from collections import Counter
from typing import Optional
from PIL import Image, ImageDraw, ImageFont
import numpy as np

# FastAPI ë° ê´€ë ¨ íŒ¨í‚¤ì§€
from fastapi import FastAPI, File, Form, UploadFile, HTTPException
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import uvicorn

# AI ë° OCR ê´€ë ¨ íŒ¨í‚¤ì§€  
import torch
from huggingface_hub import hf_hub_download
import pytesseract
import openai
from loguru import logger
import platform
# VARCO Vision OCRì„ ìœ„í•œ ì¶”ê°€ import
from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration
import re

# ì›Œë“œ ë¬¸ì„œ ìƒì„±ì„ ìœ„í•œ íŒ¨í‚¤ì§€
from docx import Document
from docx.shared import Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH

# Windowsì—ì„œ Tesseract ê²½ë¡œ ì„¤ì •
if platform.system() == "Windows":
    pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ë¡œê·¸ ì„¤ì •
logger.remove()
logger.add(sys.stderr, level="INFO")

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
print(f"âœ… ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="SmartEyeSsen í•™ìŠµì§€ ë¶„ì„ API",
    description="ì‹œê° ì¥ì•  ì•„ë™ì„ ìœ„í•œ AI ê¸°ë°˜ í•™ìŠµì§€ ë¶„ì„ ë° í…ìŠ¤íŠ¸ ë³€í™˜ ì‹œìŠ¤í…œ",
    version="1.0.0"
)

# CORS ì„¤ì • (Vue.js í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì œê³µ (ê²°ê³¼ ì´ë¯¸ì§€ ë° JSON íŒŒì¼)
os.makedirs("static", exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")


class VarcoVisionOCR:
    """VARCO Vision 2.0 OCR ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.model = None
        self.processor = None
        self.device = device
        self.model_name = "NCSOFT/VARCO-VISION-2.0-1.7B-OCR"
        
    def initialize(self):
        """ëª¨ë¸ ì´ˆê¸°í™” (í•„ìš”í•  ë•Œë§Œ ë¡œë“œ)"""
        if self.model is None:
            try:
                logger.info("VARCO Vision OCR ëª¨ë¸ ë¡œë“œ ì¤‘...")
                self.model = LlavaOnevisionForConditionalGeneration.from_pretrained(
                    self.model_name,
                    torch_dtype=torch.float16,
                    attn_implementation="sdpa",
                    device_map="auto",
                )
                self.processor = AutoProcessor.from_pretrained(self.model_name)
                logger.info("VARCO Vision OCR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                return True
            except Exception as e:
                logger.error(f"VARCO Vision OCR ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return False
        return True
    
    def preprocess_image(self, image):
        """OCR ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # OpenCV BGRì„ PIL RGBë¡œ ë³€í™˜
        if len(image.shape) == 3 and image.shape[2] == 3:
            image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        else:
            image_pil = Image.fromarray(image)
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (OCR ì„±ëŠ¥ í–¥ìƒ)
        w, h = image_pil.size
        target_size = 2304
        if max(w, h) < target_size:
            scaling_factor = target_size / max(w, h)
            new_w = int(w * scaling_factor)
            new_h = int(h * scaling_factor)
            image_pil = image_pil.resize((new_w, new_h))
            logger.info(f"ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {w}x{h} -> {new_w}x{new_h}")
        
        return image_pil
    
    def extract_text(self, image_crop):
        """VARCO Visionì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not self.initialize():
            return ""
        
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            image_pil = self.preprocess_image(image_crop)
            
            # ëŒ€í™” í˜•ì‹ìœ¼ë¡œ ìš”ì²­ êµ¬ì„±
            conversation = [
                {
                    "role": "user",
                    "content": [
                        {"type": "image", "image": image_pil},
                        {"type": "text", "text": "<ocr>"},
                    ],
                },
            ]
            
            # ì…ë ¥ í…ì„œ ìƒì„±
            inputs = self.processor.apply_chat_template(
                conversation,
                add_generation_prompt=True,
                tokenize=True,
                return_dict=True,
                return_tensors="pt"
            ).to(self.model.device, torch.float16)
            
            # í…ìŠ¤íŠ¸ ìƒì„±
            with torch.no_grad():
                generate_ids = self.model.generate(
                    **inputs, 
                    max_new_tokens=1024,
                    temperature=0.1,  # ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ ì˜¨ë„
                    do_sample=False   # ê²°ì •ë¡ ì  ê²°ê³¼
                )
            
            # ê²°ê³¼ ë””ì½”ë”©
            generate_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generate_ids)
            ]
            output = self.processor.decode(generate_ids_trimmed[0], skip_special_tokens=True)
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            cleaned_text = self.clean_ocr_output(output)
            return cleaned_text
            
        except Exception as e:
            logger.error(f"VARCO Vision OCR ì‹¤íŒ¨: {e}")
            return ""
    
    def clean_ocr_output(self, text):
        """OCR ì¶œë ¥ í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not text:
            return ""
        
        # ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ ë¬¸ìë‚˜ í† í° ì œê±°
        text = text.strip()
        
        # ì—¬ëŸ¬ ì¤„ë°”ê¿ˆì„ ë‹¨ì¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì •ë¦¬
        text = re.sub(r'\n\s*\n', '\n', text)
        
        return text


class WorksheetAnalyzer:
    """í•™ìŠµì§€ ë¶„ì„ê¸° í´ë˜ìŠ¤ - Gradio ë²„ì „ì—ì„œ ì´ì‹"""
    
    def __init__(self):
        self.model = None
        self.device = device
        self.layout_info = []
        self.ocr_results = []
        self.api_results = []
        # ğŸ†• VARCO Vision OCR ì¶”ê°€
        self.varco_ocr = VarcoVisionOCR()
        self.use_varco_ocr = True  # VARCO OCR ì‚¬ìš© ì—¬ë¶€

    def download_model(self, model_choice="SmartEyeSsen"):
        """ì‚¬ì „ í›ˆë ¨ëœ DocLayout-YOLO ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        models = {
            "doclaynet_docsynth": {
                "repo_id": "juliozhao/DocLayout-YOLO-DocLayNet-Docsynth300K_pretrained",
                "filename": "doclayout_yolo_doclaynet_imgsz1120_docsynth_pretrain.pt"
            },
            "docstructbench": {
                "repo_id": "juliozhao/DocLayout-YOLO-DocStructBench",
                "filename": "doclayout_yolo_docstructbench_imgsz1024.pt"
            },
            "docsynth300k": {
                "repo_id": "juliozhao/DocLayout-YOLO-DocSynth300K-pretrain",
                "filename": "doclayout_yolo_docsynth300k_imgsz1600.pt"
            },
            "SmartEyeSsen": {
                "repo_id": "AkJeond/SmartEyeSsen",
                "filename": "best_tuned_model.pt"
            }
        }

        selected_model = models.get(model_choice, models["SmartEyeSsen"])

        try:
            logger.info(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {selected_model['repo_id']}")
            filepath = hf_hub_download(
                repo_id=selected_model["repo_id"],
                filename=selected_model["filename"]
            )
            logger.info(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filepath}")
            return filepath
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def load_model(self, model_path):
        """DocLayout-YOLO ëª¨ë¸ ë¡œë“œ"""
        try:
            # DocLayout-YOLO ì„í¬íŠ¸ (ì—¬ê¸°ì„œ ì„í¬íŠ¸í•˜ì—¬ ëª¨ë¸ì´ í•„ìš”í•  ë•Œë§Œ ë¡œë“œ)
            try:
                from doclayout_yolo import YOLOv10
            except ImportError:
                logger.error("DocLayout-YOLOê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ê°€ì´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                return False

            logger.info("ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.model = YOLOv10(model_path, task='predict')
            self.model.to(self.device)
            if hasattr(self.model, 'training'):
                self.model.training = False
            logger.info("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            return True
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def analyze_layout(self, image, model_choice="SmartEyeSsen"):
        """ë ˆì´ì•„ì›ƒ ë¶„ì„"""
        try:
            logger.info("ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œì‘...")

            # ì„ì‹œ ì´ë¯¸ì§€ ì €ì¥
            temp_path = "temp_image.jpg"
            cv2.imwrite(temp_path, image)

            # ëª¨ë¸ ì„¤ì •
            if model_choice == "SmartEyeSsen":
                imgsz = 1024
                conf = 0.25
            elif model_choice == "docsynth300k":
                imgsz = 1600
                conf = 0.15
            else:  # doclaynet_docsynth
                imgsz = 1024
                conf = 0.25

            # ë¶„ì„ ì‹¤í–‰
            results = self.model.predict(
                temp_path,
                imgsz=imgsz,
                conf=conf,
                iou=0.45,
                device=self.device
            )

            # ê²°ê³¼ ì¶”ì¶œ
            boxes = results[0].boxes.xyxy.cpu().numpy()
            classes = results[0].boxes.cls.cpu().numpy()
            confs = results[0].boxes.conf.cpu().numpy()
            class_names = self.model.names

            layout_info = []
            for i, (box, cls, conf) in enumerate(zip(boxes, classes, confs)):
                x1, y1, x2, y2 = map(int, box)
                cls_id = int(cls)

                try:
                    cls_name = class_names[cls_id]
                except IndexError:
                    cls_name = f"unknown_{cls_id}"

                area = (x2 - x1) * (y2 - y1)
                if area < 100:  # ë„ˆë¬´ ì‘ì€ ì˜ì—­ ì œì™¸
                    continue

                layout_info.append({
                    'id': i,
                    'class_name': cls_name,
                    'confidence': float(conf),
                    'box': [int(x1), int(y1), int(x2), int(y2)],
                    'width': int(x2 - x1),
                    'height': int(y2 - y1),
                    'area': area
                })

            self.layout_info = layout_info
            logger.info(f"ë ˆì´ì•„ì›ƒ ë¶„ì„ ì™„ë£Œ: {len(layout_info)}ê°œ ì˜ì—­ ê°ì§€")
            return layout_info

        except Exception as e:
            logger.error(f"ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []

    def perform_ocr(self, image, use_varco=None):
        """OCR ì²˜ë¦¬ - VARCO Vision ë˜ëŠ” Tesseract ì„ íƒ ê°€ëŠ¥"""
        target_classes = [
            'title', 'plain_text', 'abandon_text',
            'table_caption', 'table_footnote',
            'isolated_formula', 'formula_caption', 'question_type',
            'question_text', 'question_number', 'list'
        ]

        # OCR ì—”ì§„ ê²°ì •
        if use_varco is None:
            use_varco = self.use_varco_ocr

        ocr_results = []
        
        logger.info(f"OCR ì²˜ë¦¬ ì‹œì‘... ì—”ì§„: {'VARCO Vision' if use_varco else 'Tesseract'}")
        logger.info(f"ì´ {len(self.layout_info)}ê°œ ë ˆì´ì•„ì›ƒ ìš”ì†Œ ì¤‘ OCR ëŒ€ìƒ í•„í„°ë§")
        
        # VARCO OCR ì´ˆê¸°í™” (í•„ìš”í•œ ê²½ìš°)
        if use_varco:
            if not self.varco_ocr.initialize():
                logger.warning("VARCO Vision ì´ˆê¸°í™” ì‹¤íŒ¨, Tesseractìœ¼ë¡œ í´ë°±")
                use_varco = False

        target_count = 0

        for layout in self.layout_info:
            cls_name = layout['class_name'].lower()
            
            if cls_name not in target_classes:
                continue
                
            target_count += 1
            logger.info(f"OCR ëŒ€ìƒ {target_count}: ID {layout['id']} - í´ë˜ìŠ¤ '{cls_name}'")

            x1, y1, x2, y2 = layout['box']
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(image.shape[1], x2)
            y2 = min(image.shape[0], y2)

            cropped_img = image[y1:y2, x1:x2]

            try:
                if use_varco:
                    # ğŸ†• VARCO Vision OCR ì‚¬ìš©
                    text = self.varco_ocr.extract_text(cropped_img)
                else:
                    # ê¸°ì¡´ Tesseract OCR ì‚¬ìš©
                    pil_img = Image.fromarray(cropped_img)
                    custom_config = r'--oem 3 --psm 6'
                    text = pytesseract.image_to_string(
                        pil_img,
                        lang='kor+eng',
                        config=custom_config
                    ).strip()

                if len(text) > 1:
                    ocr_results.append({
                        'id': layout['id'],
                        'class_name': cls_name,
                        'coordinates': [x1, y1, x2, y2],
                        'text': text,
                        'ocr_engine': 'VARCO Vision' if use_varco else 'Tesseract'  # ğŸ†• ì—”ì§„ ì •ë³´ ì¶”ê°€
                    })
                    logger.info(f"âœ… OCR ì„±ê³µ: ID {layout['id']} ({cls_name}) - '{text[:50]}...' ({len(text)}ì)")
                else:
                    logger.warning(f"âš ï¸ OCR ê²°ê³¼ ì—†ìŒ: ID {layout['id']} ({cls_name})")

            except Exception as e:
                logger.error(f"OCR ì‹¤íŒ¨: ID {layout['id']} - {e}")
                
                # VARCO ì‹¤íŒ¨ì‹œ Tesseractìœ¼ë¡œ í´ë°±
                if use_varco:
                    try:
                        logger.info(f"VARCO ì‹¤íŒ¨, Tesseractìœ¼ë¡œ ì¬ì‹œë„: ID {layout['id']}")
                        pil_img = Image.fromarray(cropped_img)
                        custom_config = r'--oem 3 --psm 6'
                        text = pytesseract.image_to_string(
                            pil_img,
                            lang='kor+eng',
                            config=custom_config
                        ).strip()
                        
                        if len(text) > 1:
                            ocr_results.append({
                                'id': layout['id'],
                                'class_name': cls_name,
                                'coordinates': [x1, y1, x2, y2],
                                'text': text,
                                'ocr_engine': 'Tesseract (fallback)'
                            })
                            logger.info(f"âœ… Tesseract í´ë°± ì„±ê³µ: ID {layout['id']}")
                    except Exception as fallback_error:
                        logger.error(f"Tesseract í´ë°±ë„ ì‹¤íŒ¨: ID {layout['id']} - {fallback_error}")

        self.ocr_results = ocr_results
        logger.info(f"OCR ì²˜ë¦¬ ì™„ë£Œ: {len(ocr_results)}ê°œ í…ìŠ¤íŠ¸ ë¸”ë¡")
        return ocr_results

    def call_openai_api(self, image, api_key):
        """OpenAI Vision API í˜¸ì¶œ"""
        if not api_key:
            logger.warning("API í‚¤ê°€ ì œê³µë˜ì§€ ì•Šì•„ AI ì„¤ëª…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return []

        target_classes = ['figure', 'table']
        api_results = []

        try:
            client = openai.OpenAI(api_key=api_key)
            logger.info("OpenAI API ì²˜ë¦¬ ì‹œì‘...")
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return []

        prompts = {
            'figure': "ì´ ê·¸ë¦¼(figure)ì˜ ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ ì£¼ì„¸ìš”.",
            'table': "ì´ í‘œ(table)ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”."
        }

        system_prompt = """ë‹¹ì‹ ì€ ì‹œê° ì¥ì•  ì•„ë™ì„ ìœ„í•œ í•™ìŠµ AI ë¹„ì„œì…ë‹ˆë‹¤.
ì‹œê° ìë£Œì˜ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì„¤ëª…ì€ ìŒì„±ìœ¼ë¡œ ë³€í™˜ë  ìˆ˜ ìˆë„ë¡ ì§ì ‘ì ì´ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        for layout in self.layout_info:
            cls_name = layout['class_name'].lower()
            if cls_name not in target_classes:
                continue

            x1, y1, x2, y2 = layout['box']
            cropped_img = image[y1:y2, x1:x2]

            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            pil_img = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
            buffered = io.BytesIO()
            pil_img.save(buffered, format="PNG")
            img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")

            prompt = prompts.get(cls_name, f"ì´ {cls_name}ì˜ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.")

            try:
                response = client.chat.completions.create(
                    model="gpt-4-turbo",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_base64}"}}
                            ]
                        }
                    ],
                    temperature=0.2,
                    max_tokens=600
                )

                description = response.choices[0].message.content.strip()

                api_results.append({
                    'id': layout['id'],
                    'class_name': cls_name,
                    'coordinates': [x1, y1, x2, y2],
                    'description': description
                })

                logger.info(f"API ì‘ë‹µ ì™„ë£Œ: ID {layout['id']} - {cls_name}")

            except Exception as e:
                logger.error(f"API ìš”ì²­ ì‹¤íŒ¨: ID {layout['id']} - {e}")

        self.api_results = api_results
        logger.info(f"OpenAI API ì²˜ë¦¬ ì™„ë£Œ: {len(api_results)}ê°œ ì„¤ëª… ìƒì„±")
        return api_results

    def visualize_results(self, image):
        """ê²°ê³¼ ì‹œê°í™”"""
        img_result = image.copy()
        overlay = image.copy()

        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ìƒì„±
        random.seed(42)

        unique_classes = list(set(layout['class_name'] for layout in self.layout_info))
        class_colors = {}

        for i, cls_name in enumerate(unique_classes):
            h = i / max(1, len(unique_classes))
            s = 0.8
            v = 0.9
            r, g, b = colorsys.hsv_to_rgb(h, s, v)
            class_colors[cls_name] = (int(b * 255), int(g * 255), int(r * 255))

        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for layout in self.layout_info:
            x1, y1, x2, y2 = layout['box']
            cls_name = layout['class_name']
            color = class_colors[cls_name]

            # ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´
            cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)

            # í…Œë‘ë¦¬
            cv2.rectangle(img_result, (x1, y1), (x2, y2), color, 2)

            # ë¼ë²¨
            label = f"{cls_name} ({layout['confidence']:.2f})"
            labelSize, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            y1_label = max(y1, labelSize[1] + 10)

            cv2.rectangle(
                img_result,
                (x1, y1_label - labelSize[1] - 10),
                (x1 + labelSize[0], y1_label),
                color,
                -1
            )

            cv2.putText(
                img_result,
                label,
                (x1, y1_label - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1
            )

        # ë°˜íˆ¬ëª… ì ìš©
        img_result = cv2.addWeighted(overlay, 0.2, img_result, 0.8, 0)

        return cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)

    def create_text_visualization(self, image):
        """í…ìŠ¤íŠ¸ê°€ ì‚½ì…ëœ ë¬¸ì„œ ì‹œê°í™”"""
        canvas_height, canvas_width = image.shape[:2]
        canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255

        # OCR ë° API ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for result in self.ocr_results + self.api_results:
            x1, y1, x2, y2 = result['coordinates']
            cv2.rectangle(canvas, (x1, y1), (x2, y2), (0, 0, 0), 2)

        # PILë¡œ ë³€í™˜í•˜ì—¬ í•œê¸€ í…ìŠ¤íŠ¸ ì¶”ê°€
        canvas_pil = Image.fromarray(cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(canvas_pil)

        # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (Windowsì—ì„œ)
        try:
            font = ImageDraw.getfont()
        except:
            from PIL import ImageFont
            try:
                font = ImageFont.load_default()
            except:
                font = None

        # í…ìŠ¤íŠ¸ ì¶”ê°€
        for result in self.ocr_results:
            x1, y1, x2, y2 = result['coordinates']
            text = result['text'].replace('\n', ' ')
            if len(text) > 50:
                text = text[:50] + "..."
            if font:
                draw.text((x1 + 5, y1 + 5), text, font=font, fill=(0, 0, 0))

        for result in self.api_results:
            x1, y1, x2, y2 = result['coordinates']
            text = result['description'].replace('\n', ' ')
            if len(text) > 50:
                text = text[:50] + "..."
            if font:
                draw.text((x1 + 5, y1 + 5), text, font=font, fill=(0, 0, 0))

        return np.array(canvas_pil)

    def create_cim_result(self, layout_info, ocr_results, ai_results):
        """CIM ê²°ê³¼ ìƒì„± (ì‹œê°í™” ì œê±°, JSON í†µí•©ë§Œ)"""
        from datetime import datetime
        
        # JSON í†µí•© ê²°ê³¼ ìƒì„±
        cim_result = {
            "document_structure": {
                "layout_analysis": {
                    "total_elements": len(layout_info),
                    "elements": []
                },
                "text_content": [],
                "ai_descriptions": []
            },
            "metadata": {
                "analysis_date": datetime.now().isoformat(),
                "total_text_regions": len([info for info in layout_info if 'text' in info.get('class_name', '').lower()]),
                "total_figures": len([info for info in layout_info if info.get('class_name') == 'figure']),
                "total_tables": len([info for info in layout_info if info.get('class_name') == 'table'])
            }
        }
        
        # ë ˆì´ì•„ì›ƒ ì •ë³´ í†µí•©
        for i, info in enumerate(layout_info):
            element = {
                "id": i,
                "class": info.get('class_name', 'unknown'),
                "confidence": float(info.get('confidence', 0.0)),
                "bbox": info.get('box', []),
                "area": info.get('area', 0)
            }
            
            # OCR í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
            ocr_text = None
            for ocr_result in ocr_results:
                if ocr_result.get('id') == info.get('id'):
                    ocr_text = ocr_result.get('text', '')
                    break
            
            if ocr_text and ocr_text.strip():
                element["text"] = ocr_text
                cim_result["document_structure"]["text_content"].append({
                    "element_id": i,
                    "text": ocr_text,
                    "class": info.get('class_name', 'unknown')
                })
            
            # AI ì„¤ëª…ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
            ai_description = None
            for ai_result in ai_results:
                if ai_result.get('id') == info.get('id'):
                    ai_description = ai_result.get('description', '')
                    break
            
            if ai_description and ai_description.strip():
                element["ai_description"] = ai_description
                cim_result["document_structure"]["ai_descriptions"].append({
                    "element_id": i,
                    "description": ai_description,
                    "class": info.get('class_name', 'unknown')
                })
            
            cim_result["document_structure"]["layout_analysis"]["elements"].append(element)
        
        # í†µê³„ ê³„ì‚°
        text_elements = [e for e in cim_result["document_structure"]["layout_analysis"]["elements"] if "text" in e]
        ai_elements = [e for e in cim_result["document_structure"]["layout_analysis"]["elements"] if "ai_description" in e]
        
        stats = {
            "total_elements": len(layout_info),
            "text_elements": len(text_elements),
            "ai_described_elements": len(ai_elements),
            "class_distribution": {}
        }
        
        # í´ë˜ìŠ¤ë³„ ë¶„í¬ ê³„ì‚°
        for info in layout_info:
            class_name = info.get('class_name', 'unknown')
            stats["class_distribution"][class_name] = stats["class_distribution"].get(class_name, 0) + 1
        
        return cim_result, stats


# ê¸€ë¡œë²Œ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
analyzer = WorksheetAnalyzer()

# êµ¬ì¡°í™”ëœ JSON ìƒì„±ê¸° ì„í¬íŠ¸
try:
    from structured_json_generator import StructuredJSONGenerator
    structured_generator = StructuredJSONGenerator()
    logger.info("âœ… êµ¬ì¡°í™”ëœ JSON ìƒì„±ê¸°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    logger.warning(f"âš ï¸ êµ¬ì¡°í™”ëœ JSON ìƒì„±ê¸° ë¡œë“œ ì‹¤íŒ¨: {e}")
    structured_generator = None


@app.post("/analyze-structured")
async def analyze_worksheet_structured(
    image: UploadFile = File(...),
    model_choice: str = Form("SmartEyeSsen"),
    api_key: Optional[str] = Form(None)
):
    """
    êµ¬ì¡°í™”ëœ í•™ìŠµì§€ ë¶„ì„ - ë¬¸ì œë³„ ì •ë ¬ ë° êµ¬ì¡°í™”
    """
    try:
        # êµ¬ì¡°í™”ëœ JSON ìƒì„±ê¸° í™•ì¸
        if structured_generator is None:
            raise HTTPException(status_code=500, detail="êµ¬ì¡°í™”ëœ ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì´ë¯¸ì§€ ì½ê¸°
        image_bytes = await image.read()
        pil_image = Image.open(io.BytesIO(image_bytes))
        
        # PIL ì´ë¯¸ì§€ë¥¼ OpenCV BGR í˜•íƒœë¡œ ë³€í™˜
        cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
        logger.info(f"ğŸ“Š êµ¬ì¡°í™”ëœ ë¶„ì„ ì‹œì‘ - ëª¨ë¸: {model_choice}")
        model_path = analyzer.download_model(model_choice)
        
        if not analyzer.load_model(model_path):
            raise HTTPException(status_code=500, detail="ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ë ˆì´ì•„ì›ƒ ë¶„ì„
        layout_info = analyzer.analyze_layout(cv_image, model_choice)
        if not layout_info:
            raise HTTPException(status_code=400, detail="ë ˆì´ì•„ì›ƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê°ì§€ëœ ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # OCR ì²˜ë¦¬
        analyzer.perform_ocr(cv_image)
        
        # OpenAI API ì²˜ë¦¬ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
        if api_key and api_key.strip():
            analyzer.call_openai_api(cv_image, api_key)
        else:
            analyzer.api_results = []
        
        # ğŸ†• êµ¬ì¡°í™”ëœ JSON ìƒì„±
        logger.info("ğŸ”§ ë¬¸ì œë³„ êµ¬ì¡°í™” ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        structured_result = structured_generator.generate_structured_json(
            analyzer.ocr_results,
            analyzer.api_results,
            analyzer.layout_info
        )
        
        # ë ˆì´ì•„ì›ƒ ê²°ê³¼ ì‹œê°í™”
        layout_viz = analyzer.visualize_results(cv_image)
        
        # íŒŒì¼ ì €ì¥
        timestamp = int(time.time())
        layout_viz_path = f"static/layout_viz_{timestamp}.png"
        
        layout_viz_pil = Image.fromarray(layout_viz)
        layout_viz_pil.save(layout_viz_path)
        
        # êµ¬ì¡°í™”ëœ JSON íŒŒì¼ ì €ì¥
        from datetime import datetime
        structured_filename = f"structured_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        structured_filepath = f"static/{structured_filename}"
        
        with open(structured_filepath, 'w', encoding='utf-8') as f:
            json.dump(structured_result, f, indent=2, ensure_ascii=False)
        
        # ğŸ†• êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ìƒì„±
        structured_text = create_structured_text(structured_result)
        
        # í†µê³„ ìƒì„±
        class_counts = Counter(item['class_name'] for item in layout_info)
        stats = {
            "total_layout_elements": len(layout_info),
            "ocr_text_blocks": len(analyzer.ocr_results),
            "ai_descriptions": len(analyzer.api_results),
            "total_questions": structured_result.get('document_info', {}).get('total_questions', 0),
            "class_counts": dict(class_counts)
        }
        
        logger.info(f"âœ… êµ¬ì¡°í™”ëœ ë¶„ì„ ì™„ë£Œ: {stats['total_questions']}ê°œ ë¬¸ì œ ê°ì§€")
        
        return JSONResponse({
            "success": True,
            "layout_image_url": f"/{layout_viz_path}",
            "structured_json_url": f"/{structured_filepath}",
            "structured_result": structured_result,
            "structured_text": structured_text,
            "stats": stats,
            "timestamp": timestamp,
            "analysis_type": "structured"
        })
        
    except Exception as e:
        logger.error(f"êµ¬ì¡°í™”ëœ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=f"êµ¬ì¡°í™”ëœ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.post("/analyze")
async def analyze_worksheet(
    image: UploadFile = File(...),
    model_choice: str = Form("SmartEyeSsen"),
    api_key: Optional[str] = Form(None),
    ocr_engine: str = Form("varco")  # ğŸ†• OCR ì—”ì§„ ì„ íƒ ì¶”ê°€
):
    """
    í•™ìŠµì§€ ë¶„ì„ ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸
    ocr_engine: "varco" ë˜ëŠ” "tesseract"
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        image_bytes = await image.read()
        pil_image = Image.open(io.BytesIO(image_bytes))
        
        # PIL ì´ë¯¸ì§€ë¥¼ OpenCV BGR í˜•íƒœë¡œ ë³€í™˜
        cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ
        logger.info(f"ëª¨ë¸ ì„ íƒ: {model_choice}")
        model_path = analyzer.download_model(model_choice)
        
        if not analyzer.load_model(model_path):
            raise HTTPException(status_code=500, detail="ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ë ˆì´ì•„ì›ƒ ë¶„ì„
        layout_info = analyzer.analyze_layout(cv_image, model_choice)
        if not layout_info:
            raise HTTPException(status_code=400, detail="ë ˆì´ì•„ì›ƒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê°ì§€ëœ ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # OCR ì²˜ë¦¬ (ì—”ì§„ ì„ íƒ)
        use_varco = ocr_engine.lower() == "varco"
        analyzer.perform_ocr(cv_image, use_varco=use_varco)
        
        # OpenAI API ì²˜ë¦¬ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
        if api_key and api_key.strip():
            analyzer.call_openai_api(cv_image, api_key)
        else:
            analyzer.api_results = []
        
        # ë ˆì´ì•„ì›ƒ ê²°ê³¼ ì‹œê°í™”
        layout_viz = analyzer.visualize_results(cv_image)
        
        # ë ˆì´ì•„ì›ƒ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        timestamp = int(time.time())
        layout_viz_path = f"static/layout_viz_{timestamp}.png"
        
        layout_viz_pil = Image.fromarray(layout_viz)
        layout_viz_pil.save(layout_viz_path)
        
        # CIM í†µí•© ê²°ê³¼ ìƒì„± (JSON ë°ì´í„°ë§Œ)
        cim_result, cim_stats = analyzer.create_cim_result(
            analyzer.layout_info, 
            analyzer.ocr_results, 
            analyzer.api_results
        )
        
        # ğŸ†• í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ ìë™ ìƒì„±
        formatted_text = create_formatted_text(cim_result)
        
        # JSON íŒŒì¼ ì €ì¥
        from datetime import datetime
        json_filename = f"analysis_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        json_filepath = f"static/{json_filename}"
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(cim_result, f, indent=2, ensure_ascii=False)
        
        # í†µê³„ ìƒì„±
        class_counts = Counter(item['class_name'] for item in layout_info)
        stats = {
            "total_layout_elements": len(layout_info),
            "ocr_text_blocks": len(analyzer.ocr_results),
            "ai_descriptions": len(analyzer.api_results),
            "class_counts": dict(class_counts),
            "cim_stats": cim_stats
        }
        
        # OCR í…ìŠ¤íŠ¸ í†µí•© (í¸ì§‘ ê°€ëŠ¥í•œ í˜•íƒœë¡œ)
        combined_ocr_text = ""
        for result in analyzer.ocr_results:
            combined_ocr_text += f"[{result['class_name']}]\n{result['text']}\n\n"
        
        # AI ì„¤ëª… í†µí•©
        combined_ai_text = ""
        for result in analyzer.api_results:
            combined_ai_text += f"[{result['class_name']}]\n{result['description']}\n\n"
        
        return JSONResponse({
            "success": True,
            "layout_image_url": f"/{layout_viz_path}",
            "json_url": f"/{json_filepath}",
            "stats": stats,
            "ocr_results": analyzer.ocr_results,
            "ai_results": analyzer.api_results,
            "ocr_text": combined_ocr_text.strip(),
            "ai_text": combined_ai_text.strip(),
            "formatted_text": formatted_text,  # ğŸ†• ì¶”ê°€
            "timestamp": timestamp,
            "ocr_engine_used": ocr_engine  # ğŸ†• ì‚¬ìš©ëœ OCR ì—”ì§„ ì •ë³´
        })
        
    except Exception as e:
        logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "message": "SmartEyeSsen í•™ìŠµì§€ ë¶„ì„ API",
        "version": "1.0.0",
        "device": device,
        "available_models": [
            "SmartEyeSsen",
            "docstructbench", 
            "doclaynet_docsynth",
            "docsynth300k"
        ]
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "device": device}


@app.post("/format-text")
async def format_text_from_json(json_file: UploadFile = File(...)):
    """
    JSON íŒŒì¼ì„ ì—…ë¡œë“œë°›ì•„ì„œ í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ ìƒì„±
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        json_content = await json_file.read()
        data = json.loads(json_content.decode('utf-8'))
        
        # í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ ìƒì„±
        formatted_text = create_formatted_text(data)
        
        return JSONResponse({
            "success": True,
            "formatted_text": formatted_text,
            "message": "í…ìŠ¤íŠ¸ í¬ë§·íŒ…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        })
        
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ í¬ë§·íŒ… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ í¬ë§·íŒ… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.post("/save-as-word")
async def save_as_word(
    text: str = Form(...),
    filename: Optional[str] = Form("smarteye_document")
):
    """
    í¸ì§‘ëœ í…ìŠ¤íŠ¸ë¥¼ ì›Œë“œ ë¬¸ì„œë¡œ ì €ì¥
    """
    try:
        # ì›Œë“œ ë¬¸ì„œ ìƒì„±
        doc = Document()
        
        # ë¬¸ì„œ ì œëª© ì¶”ê°€
        title = doc.add_heading('SmartEye OCR ë¶„ì„ ê²°ê³¼', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # í˜„ì¬ ë‚ ì§œ ì¶”ê°€
        from datetime import datetime
        date_paragraph = doc.add_paragraph(f"ìƒì„±ì¼: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}")
        date_paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
        
        # êµ¬ë¶„ì„  ì¶”ê°€
        doc.add_paragraph("=" * 50)
        
        # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ê°€ (ì¤„ë°”ê¿ˆ ì²˜ë¦¬)
        lines = text.split('\n')
        current_paragraph = None
        
        for line in lines:
            line = line.strip()
            
            # ë¹ˆ ì¤„ ì²˜ë¦¬
            if not line:
                if current_paragraph is not None:
                    doc.add_paragraph()  # ë¹ˆ ì¤„ ì¶”ê°€
                continue
            
            # ì œëª© í˜•íƒœ ê°ì§€ ([ì œëª©] í˜•ì‹)
            if line.startswith('[') and line.endswith(']'):
                heading = doc.add_heading(line.strip('[]'), level=2)
                current_paragraph = None
            # ë¬¸ì œë²ˆí˜¸ í˜•íƒœ ê°ì§€ (ìˆ«ì. í˜•ì‹)
            elif line.replace(' ', '').replace('.', '').isdigit() and '.' in line:
                heading = doc.add_heading(line, level=3)
                current_paragraph = None
            # ì¼ë°˜ í…ìŠ¤íŠ¸
            else:
                paragraph = doc.add_paragraph(line)
                current_paragraph = paragraph
        
        # íŒŒì¼ëª… ì •ë¦¬ (í™•ì¥ì ì œê±°)
        if filename.endswith('.docx'):
            filename = filename[:-5]
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_filename = f"{filename}_{timestamp}.docx"
        
        # static í´ë”ì— ì €ì¥
        filepath = f"static/{safe_filename}"
        doc.save(filepath)
        
        logger.info(f"ì›Œë“œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ: {filepath}")
        
        return JSONResponse({
            "success": True,
            "message": "ì›Œë“œ ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "filename": safe_filename,
            "download_url": f"/{filepath}",
            "timestamp": timestamp
        })
        
    except Exception as e:
        logger.error(f"ì›Œë“œ ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=f"ì›Œë“œ ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@app.get("/download/{filename}")
async def download_file(filename: str):
    """
    ìƒì„±ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    """
    try:
        filepath = f"static/{filename}"
        if not os.path.exists(filepath):
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return FileResponse(
            path=filepath,
            filename=filename,
            media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        )
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


def create_structured_text(structured_result):
    """
    êµ¬ì¡°í™”ëœ JSON ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    """
    formatted_text = ""
    
    # ë¬¸ì„œ ì •ë³´
    doc_info = structured_result.get('document_info', {})
    formatted_text += f"ğŸ“‹ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼\n"
    formatted_text += f"ì´ ë¬¸ì œ ìˆ˜: {doc_info.get('total_questions', 0)}ê°œ\n"
    formatted_text += f"ë ˆì´ì•„ì›ƒ ìœ í˜•: {doc_info.get('layout_type', 'ë¯¸í™•ì¸')}\n\n"
    formatted_text += "=" * 50 + "\n\n"
    
    # ê° ë¬¸ì œë³„ ì²˜ë¦¬
    questions = structured_result.get('questions', [])
    
    for i, question in enumerate(questions, 1):
        question_num = question.get('question_number', f'ë¬¸ì œ{i}')
        section = question.get('section', '')
        
        # ë¬¸ì œ ì œëª©
        formatted_text += f"ğŸ”¸ {question_num}"
        if section:
            formatted_text += f" ({section})"
        formatted_text += "\n\n"
        
        question_content = question.get('question_content', {})
        
        # ì§€ë¬¸ (passage)
        passage = question_content.get('passage', '').strip()
        if passage:
            formatted_text += f"ğŸ“– ì§€ë¬¸:\n{passage}\n\n"
        
        # ì£¼ìš” ë¬¸ì œ
        main_question = question_content.get('main_question', '').strip()
        if main_question:
            formatted_text += f"â“ ë¬¸ì œ:\n{main_question}\n\n"
        
        # ì„ íƒì§€
        choices = question_content.get('choices', [])
        if choices:
            formatted_text += "ğŸ“ ì„ íƒì§€:\n"
            for choice in choices:
                choice_num = choice.get('choice_number', '')
                choice_text = choice.get('choice_text', '')
                if choice_num and choice_text:
                    formatted_text += f"   {choice_num} {choice_text}\n"
                elif choice_text:
                    formatted_text += f"   â€¢ {choice_text}\n"
            formatted_text += "\n"
        
        # ì´ë¯¸ì§€ ì„¤ëª…
        images = question_content.get('images', [])
        if images:
            formatted_text += "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì„¤ëª…:\n"
            for img in images:
                description = img.get('description', '').strip()
                if description:
                    formatted_text += f"   {description}\n"
            formatted_text += "\n"
        
        # í‘œ ì„¤ëª…
        tables = question_content.get('tables', [])
        if tables:
            formatted_text += "ğŸ“Š í‘œ ì„¤ëª…:\n"
            for table in tables:
                description = table.get('description', '').strip()
                if description:
                    formatted_text += f"   {description}\n"
            formatted_text += "\n"
        
        # í•´ì„¤
        explanations = question_content.get('explanations', '').strip()
        if explanations:
            formatted_text += f"ğŸ’¡ í•´ì„¤:\n{explanations}\n\n"
        
        # AI ë¶„ì„
        ai_analysis = question.get('ai_analysis', {})
        image_descriptions = ai_analysis.get('image_descriptions', [])
        table_analysis = ai_analysis.get('table_analysis', [])
        
        if image_descriptions or table_analysis:
            formatted_text += "ğŸ¤– AI ë¶„ì„:\n"
            
            for img_desc in image_descriptions:
                desc = img_desc.get('description', '').strip()
                if desc:
                    formatted_text += f"   [ì´ë¯¸ì§€] {desc}\n"
            
            for table_desc in table_analysis:
                desc = table_desc.get('description', '').strip()
                if desc:
                    formatted_text += f"   [í‘œ] {desc}\n"
            
            formatted_text += "\n"
        
        # ë¬¸ì œ êµ¬ë¶„ì„ 
        if i < len(questions):
            formatted_text += "-" * 30 + "\n\n"
    
    return formatted_text.strip()


def create_formatted_text(json_data):
    """
    JSON ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ ìƒì„±
    í˜„ì¬ í´ë˜ìŠ¤ë¥¼ í™œìš©í•œ í¬ë§·íŒ… ê·œì¹™ ì ìš©
    """
    
    # í¬ë§·íŒ… ê·œì¹™ ì •ì˜
    formatting_rules = {
        'title': {
            'prefix': '',
            'suffix': '\n\n',  # ì œëª© í›„ ë‘ ì¤„ ë„ê¸°
            'indent': 0
        },
        'question_number': {
            'prefix': '',
            'suffix': '. ',  # ë¬¸ì œë²ˆí˜¸ í›„ ì ê³¼ ê³µë°±
            'indent': 0
        },
        'question_type': {
            'prefix': '   ',  # 3ì¹¸ ë“¤ì—¬ì“°ê¸°
            'suffix': '\n',
            'indent': 3
        },
        'question_text': {
            'prefix': '   ',  # 3ì¹¸ ë“¤ì—¬ì“°ê¸°
            'suffix': '\n',
            'indent': 3
        },
        'plain_text': {
            'prefix': '',
            'suffix': '\n',
            'indent': 0
        },
        'table_caption': {
            'prefix': '\n',  # í‘œ ì œëª© ì• í•œ ì¤„ ë„ê¸°
            'suffix': '\n',
            'indent': 0
        },
        'table_footnote': {
            'prefix': '',
            'suffix': '\n\n',  # í‘œ ê°ì£¼ í›„ ë‘ ì¤„ ë„ê¸°
            'indent': 0
        },
        'isolated_formula': {
            'prefix': '\n',  # ìˆ˜ì‹ ì• í•œ ì¤„ ë„ê¸°
            'suffix': '\n\n',  # ìˆ˜ì‹ í›„ ë‘ ì¤„ ë„ê¸°
            'indent': 0
        },
        'formula_caption': {
            'prefix': '',
            'suffix': '\n',
            'indent': 0
        },
        'abandon_text': {
            'prefix': '[ì‚­ì œë¨] ',
            'suffix': '\n',
            'indent': 0
        },
        'figure': {
            'prefix': '\n[ê·¸ë¦¼ ì„¤ëª…] ',  # ê·¸ë¦¼ ì• í•œ ì¤„ ë„ê¸°
            'suffix': '\n\n',  # ê·¸ë¦¼ í›„ ë‘ ì¤„ ë„ê¸°
            'indent': 0
        },
        'table': {
            'prefix': '\n[í‘œ ì„¤ëª…] ',  # í‘œ ì• í•œ ì¤„ ë„ê¸°
            'suffix': '\n\n',  # í‘œ í›„ ë‘ ì¤„ ë„ê¸°
            'indent': 0
        }
    }
    
    # ìš”ì†Œë“¤ì„ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (y ì¢Œí‘œ ê¸°ì¤€)
    elements = []
    
    # ë ˆì´ì•„ì›ƒ ë¶„ì„ ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸/AI ì„¤ëª… ì¶”ì¶œ
    if "document_structure" in json_data:
        layout_elements = json_data["document_structure"]["layout_analysis"]["elements"]
        
        for element in layout_elements:
            element_id = element.get("id")
            class_name = element.get("class", "").lower().replace(" ", "_")
            bbox = element.get("bbox", [0, 0, 0, 0])
            
            # OCR í…ìŠ¤íŠ¸ ë˜ëŠ” AI ì„¤ëª… ì°¾ê¸°
            content = None
            content_type = None
            
            # OCR í…ìŠ¤íŠ¸ í™•ì¸
            if "text" in element:
                content = element["text"]
                content_type = "ocr"
            # AI ì„¤ëª… í™•ì¸
            elif "ai_description" in element:
                content = element["ai_description"]
                content_type = "ai"
            
            if content and content.strip():
                elements.append({
                    'id': element_id,
                    'class': class_name,
                    'content': content.strip(),
                    'type': content_type,
                    'y_position': bbox[1] if len(bbox) > 1 else 0,  # y ì¢Œí‘œ
                    'x_position': bbox[0] if len(bbox) > 0 else 0   # x ì¢Œí‘œ
                })
    
    # Y ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
    elements.sort(key=lambda x: (x['y_position'], x['x_position']))
    
    # í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸ ìƒì„±
    formatted_text = ""
    prev_class = None
    
    for element in elements:
        class_name = element['class']
        content = element['content']
        
        # í¬ë§·íŒ… ê·œì¹™ ì ìš©
        rule = formatting_rules.get(class_name, {
            'prefix': '',
            'suffix': '\n',
            'indent': 0
        })
        
        # íŠ¹ë³„í•œ ì¡°ê±´ ì²˜ë¦¬
        formatted_line = ""
        
        # ë¬¸ì œë²ˆí˜¸ì™€ ë¬¸ì œí…ìŠ¤íŠ¸ê°€ ì—°ì†ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²½ìš° ì²˜ë¦¬
        if class_name == 'question_text' and prev_class == 'question_number':
            # ë¬¸ì œë²ˆí˜¸ ë°”ë¡œ ë’¤ì— ë¬¸ì œí…ìŠ¤íŠ¸ê°€ ì˜¤ë©´ ê°™ì€ ì¤„ì— ë°°ì¹˜
            formatted_line = content + rule['suffix']
        else:
            # ì¼ë°˜ì ì¸ í¬ë§·íŒ… ì ìš©
            prefix = rule['prefix']
            suffix = rule['suffix']
            
            formatted_line = prefix + content + suffix
        
        formatted_text += formatted_line
        prev_class = class_name
    
    # ìµœì¢… ì •ë¦¬ (ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬)
    lines = formatted_text.split('\n')
    cleaned_lines = []
    prev_empty = False
    
    for line in lines:
        is_empty = line.strip() == ''
        
        # ì—°ì†ëœ ë¹ˆ ì¤„ì´ 3ê°œ ì´ìƒ ë‚˜ì˜¤ì§€ ì•Šë„ë¡ ì œí•œ
        if is_empty and prev_empty:
            continue
        
        cleaned_lines.append(line)
        prev_empty = is_empty
    
    return '\n'.join(cleaned_lines).strip()


@app.post("/compare-ocr")
async def compare_ocr_engines(
    image: UploadFile = File(...),
    model_choice: str = Form("SmartEyeSsen")
):
    """
    Tesseractì™€ VARCO Vision OCR ì„±ëŠ¥ ë¹„êµ
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        image_bytes = await image.read()
        pil_image = Image.open(io.BytesIO(image_bytes))
        cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
        
        # ëª¨ë¸ ë¡œë“œ
        model_path = analyzer.download_model(model_choice)
        if not analyzer.load_model(model_path):
            raise HTTPException(status_code=500, detail="ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ë ˆì´ì•„ì›ƒ ë¶„ì„
        layout_info = analyzer.analyze_layout(cv_image, model_choice)
        
        # Tesseract OCR
        start_time = time.time()
        tesseract_results = analyzer.perform_ocr(cv_image, use_varco=False)
        tesseract_time = time.time() - start_time
        
        # VARCO Vision OCR
        start_time = time.time()
        varco_results = analyzer.perform_ocr(cv_image, use_varco=True)
        varco_time = time.time() - start_time
        
        # ê²°ê³¼ ë¹„êµ ë¶„ì„
        comparison = {
            "tesseract": {
                "processing_time": round(tesseract_time, 2),
                "text_blocks": len(tesseract_results),
                "total_characters": sum(len(r['text']) for r in tesseract_results),
                "results": tesseract_results
            },
            "varco": {
                "processing_time": round(varco_time, 2),
                "text_blocks": len(varco_results),
                "total_characters": sum(len(r['text']) for r in varco_results),
                "results": varco_results
            },
            "comparison": {
                "speed_ratio": round(tesseract_time / varco_time if varco_time > 0 else 0, 2),
                "accuracy_note": "ì •í™•ë„ ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ì‹¤ì œ ì •ë‹µ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }
        }
        
        return JSONResponse({
            "success": True,
            "comparison": comparison,
            "message": "OCR ì—”ì§„ ë¹„êµ ì™„ë£Œ"
        })
        
    except Exception as e:
        logger.error(f"OCR ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=f"OCR ë¹„êµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


if __name__ == "__main__":
    print("ğŸš€ SmartEyeSsen API ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8000 ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”")
    print(f"ğŸ“š API ë¬¸ì„œëŠ” http://localhost:8000/docs ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )

import cv2
import os
import sys
import json
import argparse  # ì¸ì íŒŒì‹±ì„ ìœ„í•´ ì¶”ê°€
from datetime import datetime
from glob import glob  # íŒŒì¼ ê²€ìƒ‰ì„ ìœ„í•´ ì¶”ê°€
from loguru import logger

# ------------------------------------------------------------------
# Phase 2 ì„œë¹„ìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸
# ------------------------------------------------------------------
try:
    from backend.app.services.analysis_service import AnalysisService
    from backend.app.services.sorter import sort_layout_elements
    from backend.app.services.formatter import TextFormatter
    # MockElement ì™¸ ë‹¤ë¥¸ ëª¨ë¸ë„ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìœ ì—°í•˜ê²Œ ëŒ€ì²˜
    from backend.app.services.mock_models import MockElement, MockTextContent, USE_PYDANTIC
except ImportError:
    print("ì˜¤ë¥˜: 'backend' í´ë” êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ 'Project/' í´ë”ì˜ ìµœìƒìœ„ì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# ------------------------------------------------------------------
# âš ï¸ ì—¬ê¸°ì— í…ŒìŠ¤íŠ¸í•  ì •ë³´ ì…ë ¥
# ------------------------------------------------------------------
IMAGE_PATH = "./test_images/ë‚±ê°œ ë¬¸ì œì§€_í˜ì´ì§€_01.jpg"
OPENAI_API_KEY = "sk-..." # ì‹¤ì œ í‚¤ë¡œ ë³€ê²½
DOC_TYPE_ID = 1
DOC_TYPE_NAME = "question_based" if DOC_TYPE_ID == 1 else "reading_order"
OUTPUT_DIR = "test_outputs"  # ì¶œë ¥ ë””ë ‰í† ë¦¬ ë³€ìˆ˜í™”
# ------------------------------------------------------------------

# === ì¤‘ê°„ ê²°ê³¼ ì €ì¥/ë¡œë“œ í•¨ìˆ˜ ===

def save_intermediate_results(data, filename_prefix):
    """ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{filename_prefix}_{timestamp}.json"
    filepath = os.path.join(OUTPUT_DIR, filename)

    serializable_data = []
    if data:
        # Pydantic ëª¨ë¸ì´ë‚˜ to_dict ë©”ì†Œë“œê°€ ìˆëŠ” ê°ì²´ ì²˜ë¦¬
        if isinstance(data, list):
            for item in data:
                if hasattr(item, 'model_dump'):
                    serializable_data.append(item.model_dump(mode='json'))
                elif hasattr(item, 'dict'):
                    serializable_data.append(item.dict())
                elif hasattr(item, 'to_dict'):
                     serializable_data.append(item.to_dict())
                else:
                    serializable_data.append(item)
        elif isinstance(data, dict):
             serializable_data = {k: (v.model_dump(mode='json') if hasattr(v, 'model_dump') else v) for k, v in data.items()}
        else:
            logger.warning(f"{filename_prefix} ë°ì´í„°ë¥¼ ì§ë ¬í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_data, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        return filepath
    except Exception as e:
        logger.error(f"ğŸ’¾ ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ ({filename}): {e}")
        return None

def load_intermediate_results(filename_prefix):
    """ê°€ì¥ ìµœê·¼ì— ì €ì¥ëœ ì¤‘ê°„ ê²°ê³¼ JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        list_of_files = glob(os.path.join(OUTPUT_DIR, f'{filename_prefix}_*.json'))
        if not list_of_files:
            logger.error(f"'{OUTPUT_DIR}' í´ë”ì— '{filename_prefix}_*.json' íŒ¨í„´ì˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        latest_file = max(list_of_files, key=os.path.getctime)
        logger.info(f"ğŸ’¾ ì¤‘ê°„ ê²°ê³¼ ë¡œë“œ: {latest_file}")
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        # Pydantic ëª¨ë¸ë¡œ ë‹¤ì‹œ ë³€í™˜ (ì—¬ê¸°ì„œëŠ” MockElement, MockTextContentë§Œ ê³ ë ¤)
        if filename_prefix == "layout_elements":
            return [MockElement(**item) for item in data]
        if filename_prefix == "ocr_results":
            return [MockTextContent(**item) for item in data]
        
        return data # ai_descriptionsëŠ” dictì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
    except Exception as e:
        logger.error(f"ğŸ’¾ ì¤‘ê°„ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# === ê°€ë…ì„± ë†’ì€ ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜ ===

# === ì‹œê°í™” í•¨ìˆ˜ ì¶”ê°€ ===

# ê·¸ë£¹ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì»¬ëŸ¬ íŒ”ë ˆíŠ¸ (BGR í˜•ì‹)
COLOR_PALETTE = [
    (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255),
    (255, 0, 255), (192, 192, 192), (128, 128, 128), (128, 0, 0),
    (128, 128, 0), (0, 128, 0), (128, 0, 128), (0, 128, 128), (0, 0, 128)
]

def visualize_and_save_results(image, sorted_elements, output_filename_prefix):
    """ì •ë ¬ëœ ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ì‹œê°í™”í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    # ì´ë¯¸ì§€ ë¡œë“œì— ì‹¤íŒ¨í–ˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„
    if image is None:
        logger.error("ì‹œê°í™”ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    vis_image = image.copy()
    overlay = vis_image.copy()
    alpha = 0.2  # íˆ¬ëª…ë„ ì„¤ì •

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # 1. ëª¨ë“  í´ë˜ìŠ¤ ì´ë¦„ì„ ìˆ˜ì§‘í•˜ê³  ê° í´ë˜ìŠ¤ì— ê³ ìœ í•œ ìƒ‰ìƒì„ í• ë‹¹í•©ë‹ˆë‹¤.
    all_class_names = sorted(list(set(elem.class_name for elem in sorted_elements)))
    class_color_map = {name: COLOR_PALETTE[i % len(COLOR_PALETTE)] for i, name in enumerate(all_class_names)}

    # 2. ì˜¤ë²„ë ˆì´ì— ë¶ˆíˆ¬ëª…í•œ ë°•ìŠ¤ë“¤ì„ ë¨¼ì € ê·¸ë¦½ë‹ˆë‹¤.
    for elem in sorted_elements:
        try:
            color = class_color_map.get(elem.class_name, (100, 100, 100))  # í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ìƒ‰ìƒ ì¡°íšŒ
            x, y, w, h = int(elem.bbox_x), int(elem.bbox_y), int(elem.bbox_width), int(elem.bbox_height)
            cv2.rectangle(overlay, (x, y), (x + w, y + h), color, -1)
        except Exception as e:
            logger.error(f"Element {getattr(elem, 'element_id', 'N/A')}ì˜ ë¶ˆíˆ¬ëª… ë°•ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

    # 3. ì›ë³¸ ì´ë¯¸ì§€ì™€ ì˜¤ë²„ë ˆì´ë¥¼ í•©ì„±í•©ë‹ˆë‹¤.
    vis_image = cv2.addWeighted(overlay, alpha, vis_image, 1 - alpha, 0)

    # 4. í•©ì„±ëœ ì´ë¯¸ì§€ ìœ„ì— í…Œë‘ë¦¬ì™€ í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    for elem in sorted_elements:
        try:
            color = class_color_map.get(elem.class_name, (100, 100, 100))  # í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ìƒ‰ìƒ ì¡°íšŒ
            x, y, w, h = int(elem.bbox_x), int(elem.bbox_y), int(elem.bbox_width), int(elem.bbox_height)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ í…Œë‘ë¦¬
            cv2.rectangle(vis_image, (x, y), (x + w, y + h), color, 2)

            # ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ê°€ (group_idëŠ” ì—¬ì „íˆ í‘œì‹œ)
            group_id = getattr(elem, 'group_id', -1)
            order_in_grp = getattr(elem, 'order_in_group', -1)
            label = f"G:{group_id} O:{order_in_grp} C:{elem.class_name}"
            
            # í…ìŠ¤íŠ¸ ë°°ê²½ ì¶”ê°€
            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
            cv2.rectangle(vis_image, (x, y - text_height - baseline), (x + text_width, y), color, -1)
            cv2.putText(vis_image, label, (x, y - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        except Exception as e:
            logger.error(f"Element {getattr(elem, 'element_id', 'N/A')} ì‹œê°í™” ì¤‘ ì˜¤ë¥˜: {e}")


    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{output_filename_prefix}_visualization_{timestamp}.jpg"
    filepath = os.path.join(OUTPUT_DIR, filename)
    
    try:
        cv2.imwrite(filepath, vis_image)
        logger.info(f"ğŸ–¼ï¸  ì‹œê°í™” ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
    except Exception as e:
        logger.error(f"ğŸ–¼ï¸  ì‹œê°í™” ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def print_detailed_results(sorted_elements, ocr_map, ai_map):
    """ì •ë ¬ëœ ê²°ê³¼ë¥¼ ê·¸ë£¹ë³„ë¡œ ë¬¶ì–´ ìƒì„¸ ì •ë³´ì™€ í•¨ê»˜ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("\n" + "="*100)
    print("    [ Sorter ì •ë ¬ ê²°ê³¼ ìƒì„¸ ]")
    print("="*100)

    if not sorted_elements:
        print("ì •ë ¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("="*100 + "\n")
        return

    # GroupID ë³„ë¡œ ìš”ì†Œë“¤ì„ ë¬¶ìŒ
    grouped_elements = {}
    for elem in sorted_elements:
        group_id = getattr(elem, 'group_id', -1)
        if group_id not in grouped_elements:
            grouped_elements[group_id] = []
        grouped_elements[group_id].append(elem)

    # ê·¸ë£¹ ID ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ ì¶œë ¥
    for group_id in sorted(grouped_elements.keys()):
        print(f"--- Group ID: {group_id} ---")
        elements_in_group = sorted(grouped_elements[group_id], key=lambda x: getattr(x, 'order_in_group', -1))
        
        for elem in elements_in_group:
            order_in_grp = getattr(elem, 'order_in_group', -1)
            elem_id = elem.element_id
            
            print(f"  [Elem {elem_id} | GrpOrder {order_in_grp}] Class: {elem.class_name:<20} BBox: ({elem.bbox_y}, {elem.bbox_x})")
            
            # OCR í…ìŠ¤íŠ¸ ì¶œë ¥
            if elem_id in ocr_map:
                ocr_text = ocr_map[elem_id].replace('\n', ' ')
                print(f"    - OCR: {ocr_text[:80] + '...' if len(ocr_text) > 80 else ocr_text}")
            
            # AI ì„¤ëª… ì¶œë ¥
            if str(elem_id) in ai_map: # JSON keyëŠ” ë¬¸ìì—´
                ai_desc = ai_map[str(elem_id)].replace('\n', ' ')
                print(f"    - AI Desc: {ai_desc[:80] + '...' if len(ai_desc) > 80 else ai_desc}")
        print("-" * 50)
        
    print("="*100 + "\n")


# === íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜ ===

def run_full_pipeline(image_path, api_key, doc_type_id, doc_type_name):
    """ë¶„ì„, ì •ë ¬, í¬ë§·íŒ… íŒŒì´í”„ë¼ì¸ ì „ì²´ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    # ë¡œê·¸ ë ˆë²¨ ì„¤ì • (ê¸°ì¡´ INFO ëŒ€ì‹  DEBUG ì‚¬ìš©)
    # logger.remove() # í•„ìš”ì‹œ ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    logger.add(sys.stderr, level="DEBUG", format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} - {message}")

    logger.info("Phase 2 'full' íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    service = AnalysisService()

    try:
        model_path = service.download_model("SmartEyeSsen")
        if not service.load_model(model_path):
            return
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ/ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return

    image = cv2.imread(image_path)
    if image is None:
        logger.error(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return

    page_height, page_width = image.shape[:2]
    logger.info(f"ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {image_path} ({page_width}x{page_height})")

    # ë¶„ì„
    layout_elements = service.analyze_layout(image, model_choice='SmartEyeSsen')
    ocr_results = service.perform_ocr(image, layout_elements)
    ai_descriptions = {}
    if api_key and api_key != "sk-...":
        ai_descriptions = service.call_openai_api(image, layout_elements, api_key)
    else:
        logger.warning("AI ì„¤ëª…: API í‚¤ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")

    # ê²°ê³¼ ì €ì¥
    save_intermediate_results(layout_elements, "layout_elements")
    save_intermediate_results(ocr_results, "ocr_results")
    save_intermediate_results(ai_descriptions, "ai_descriptions")

    # ì •ë ¬
    sorted_elements = sort_layout_elements(
        layout_elements,
        document_type=doc_type_name,
        page_width=page_width,
        page_height=page_height
    )

    # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
    ocr_map = {res.element_id: res.ocr_text for res in ocr_results}
    print_detailed_results(sorted_elements, ocr_map, ai_descriptions or {})
    
    # ì‹œê°í™” ê²°ê³¼ ì €ì¥
    visualize_and_save_results(image, sorted_elements, "full_pipeline")

    logger.info("í…ŒìŠ¤íŠ¸ ì™„ë£Œ.")

def run_sort_only_from_json(doc_type_name):
    """ì €ì¥ëœ JSON íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ì •ë ¬ë§Œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    # logger.remove() # ì œê±°
    # logger.add(sys.stderr, level="INFO") # ì œê±°
    logger.info("Phase 2 'sort_only' íŒŒì´í”„ë¼ì¸ ì‹œì‘...")

    # ë°ì´í„° ë¡œë“œ
    layout_elements = load_intermediate_results("layout_elements")
    ocr_results = load_intermediate_results("ocr_results")
    ai_descriptions = load_intermediate_results("ai_descriptions")

    if not layout_elements or not ocr_results:
        logger.error("ì •ë ¬ í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ layout ë˜ëŠ” ocr ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    # ì •ë ¬ (page_width, page_heightëŠ” bbox ìµœëŒ€ê°’ìœ¼ë¡œ ê·¼ì‚¬)
    # elem.bbox_w -> elem.bbox_width ë¡œ ìˆ˜ì •
    page_width = max(elem.bbox_x + elem.bbox_width for elem in layout_elements)
    # elem.bbox_h -> elem.bbox_height ë¡œ ìˆ˜ì •
    page_height = max(elem.bbox_y + elem.bbox_height for elem in layout_elements)
    
    sorted_elements = sort_layout_elements(
        layout_elements,
        document_type=doc_type_name,
        page_width=page_width,
        page_height=page_height
    )

    # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
    ocr_map = {res.element_id: res.ocr_text for res in ocr_results}
    print_detailed_results(sorted_elements, ocr_map, ai_descriptions or {})

    # ì‹œê°í™” ê²°ê³¼ ì €ì¥ (ìƒë‹¨ì— ì •ì˜ëœ IMAGE_PATH ì‚¬ìš©)
    try:
        image_for_vis = cv2.imread(IMAGE_PATH)
        if image_for_vis is not None:
            visualize_and_save_results(image_for_vis, sorted_elements, "sort_only")
        else:
            logger.warning(f"ì‹œê°í™”ë¥¼ ìœ„í•œ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {IMAGE_PATH}")
    except Exception as e:
        logger.error(f"ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    logger.info("í…ŒìŠ¤íŠ¸ ì™„ë£Œ.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Sorter ë¡œì§ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "--mode",
        type=str,
        choices=["full", "sort_only"],
        default="full",
        help="ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•©ë‹ˆë‹¤. 'full': ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰, 'sort_only': ì €ì¥ëœ JSONìœ¼ë¡œ ì •ë ¬ë§Œ í…ŒìŠ¤íŠ¸"
    )
    args = parser.parse_args()

    if args.mode == "full":
        run_full_pipeline(IMAGE_PATH, OPENAI_API_KEY, DOC_TYPE_ID, DOC_TYPE_NAME)
    elif args.mode == "sort_only":
        run_sort_only_from_json(DOC_TYPE_NAME)

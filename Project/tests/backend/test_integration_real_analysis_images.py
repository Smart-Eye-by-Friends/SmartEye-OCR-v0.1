# test_integration_real_analysis.py

import sys
import os
import cv2
import pytest
import pytest_asyncio  # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì§€ì›
from pathlib import Path
from typing import List, Dict, Optional
from loguru import logger
import time
from dotenv import load_dotenv  # .env íŒŒì¼ ë¡œë“œìš©

# --- í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì • ë° ëª¨ë“ˆ ì„í¬íŠ¸ ---
project_root = Path(__file__).resolve().parent.parent.parent # Project/ ê²½ë¡œ
sys.path.insert(0, str(project_root)) # <--- ì´ ì¤„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.

# ì‹¤ì œ ë¶„ì„ ì„œë¹„ìŠ¤
from backend.app.services.analysis_service import AnalysisService
# ì •ë ¬ ì„œë¹„ìŠ¤ (âœ¨ Adaptive Strategy)
from backend.app.services.sorter_strategies import sort_layout_elements_adaptive, LayoutProfiler
# DB ì €ì¥ ì„œë¹„ìŠ¤ (Mock DB v2.1 ì‚¬ìš©) ë° Mock DB ìƒíƒœ
from backend.app.services.db_saver import (
    save_sorted_elements_to_mock_db,
    print_mock_db_summary,
    mock_question_groups,
    mock_question_elements
)

from backend.app.services.batch_analysis import (
    initialize_mock_db_for_test as initialize_db_saver_mock, # ì—¬ê¸°ì„œ ì„í¬íŠ¸í•˜ê³  ë³„ì¹­ ì‚¬ìš©
)

# Mock ëª¨ë¸ (ë°ì´í„° êµ¬ì¡°ìš©)
from backend.app.services.mock_models import MockElement, MockTextContent

# í…ŒìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹° (ìºì‹± ë° ê²°ê³¼ ì €ì¥)
try:
    # --- ğŸ‘‡ ìˆ˜ì •: CACHE_DIR ì„í¬íŠ¸ ì œê±° ğŸ‘‡ ---
    from tests.backend.test_utils import save_intermediate_results, load_intermediate_results, save_visual_artifacts
except ImportError:
    logger.error("test_utils.py ì„í¬íŠ¸ ì‹¤íŒ¨. Project/tests/backend/ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    # ëŒ€ì²´ í•¨ìˆ˜ ì •ì˜ (í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ìœ ë„)
    def save_intermediate_results(*args, **kwargs): raise ImportError("save_intermediate_results not found")
    def load_intermediate_results(*args, **kwargs): raise ImportError("load_intermediate_results not found")
    def save_visual_artifacts(*args, **kwargs): raise ImportError("save_visual_artifacts not found")
    # --- ğŸ‘† CACHE_DIR ì •ì˜ë„ ì—¬ê¸°ì„œ ì œê±° ğŸ‘† ---

# --- ğŸ‘‡ ìˆ˜ì •: .env ë¡œë“œ ë° OPENAI_API_KEY ì •ì˜ ğŸ‘‡ ---
# .env íŒŒì¼ ë¡œë“œ (Project ë£¨íŠ¸ì—ì„œ)
dotenv_path = project_root / ".env"
load_dotenv(dotenv_path)

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.warning("âš ï¸ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    logger.warning(f"   .env íŒŒì¼ ê²½ë¡œ: {dotenv_path}")
    logger.warning("   AI ì„¤ëª… ìƒì„±ì´ ê±´ë„ˆë›°ì–´ì§‘ë‹ˆë‹¤.")
else:
    logger.info(f"âœ… .env íŒŒì¼ì—ì„œ OPENAI_API_KEY ë¡œë“œ ì™„ë£Œ (í‚¤ ê¸¸ì´: {len(OPENAI_API_KEY)}ì)")

# CACHE_DIR ì •ì˜ (test_utils.py ëŒ€ì‹  ì—¬ê¸°ì—)
CACHE_DIR = project_root / "tests" / ".cache"
# --- ğŸ‘† ìˆ˜ì • ë ğŸ‘† ---

# --- í…ŒìŠ¤íŠ¸ ì„¤ì • ---
TEST_IMAGE_FILES = [
    project_root / "tests" / "test_images" / "ìˆ ìˆ˜í•™1-1_í˜ì´ì§€_014.jpg",
    project_root / "tests" / "test_images" / "ìˆ ìˆ˜í•™1-1_í˜ì´ì§€_016.jpg",
    project_root / "tests" / "test_images" / "ìˆ ìˆ˜í•™1-1_í˜ì´ì§€_023.jpg"
    # í•„ìš”ì— ë”°ë¼ ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€ (Path ê°ì²´ ì‚¬ìš©)
]
OUTPUT_SUBDIR = "real_analysis_test" # ê²°ê³¼ ì €ì¥ìš© í•˜ìœ„ í´ë”
BASE_OUTPUT_DIR = project_root / "tests" / "test_pipeline_outputs"
FINAL_OUTPUT_DIR = BASE_OUTPUT_DIR / OUTPUT_SUBDIR
DOC_TYPE_NAME = "question_based" # ë˜ëŠ” "reading_order"
# --------------------

# --- Pytest ì„¤ì • ---
# conftest.pyì˜ --rerun-analysis ì˜µì…˜ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ pytest ì‹¤í–‰ í•„ìš”
# pytest -s -v tests/backend/test_integration_real_analysis_images.py
# pytest -s -v tests/backend/test_integration_real_analysis_images.py --rerun-analysis

@pytest.fixture(scope="module")
def analysis_service_instance():
    """
    í…ŒìŠ¤íŠ¸ ì „ì²´ì—ì„œ ì‚¬ìš©í•  AnalysisService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    [Lazy Loading íŒ¨í„´ í™œìš©]
    - auto_load=True: ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œ ëª¨ë¸ì„ ì¦‰ì‹œ ë¡œë“œ
    - ë‹¤ì¤‘ í˜ì´ì§€ ë¶„ì„ ì‹œì—ë„ ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œë¨ (ìµœì í™”ë¨)

    [í•˜ìœ„ í˜¸í™˜ ë°©ì‹]
    ê¸°ì¡´ì²˜ëŸ¼ ìˆ˜ë™ ë¡œë“œë„ ê°€ëŠ¥:
    service = AnalysisService()
    model_path = service.download_model("SmartEyeSsen")
    service.load_model(model_path)
    """
    try:
        # Lazy Loading íŒ¨í„´: auto_load=Trueë¡œ ìë™ ëª¨ë¸ ë¡œë“œ
        service = AnalysisService(model_choice="SmartEyeSsen", auto_load=True)
        return service
    except Exception as e:
        pytest.fail(f"AnalysisService ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# --- í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ---
@pytest.mark.asyncio  # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ë°ì½”ë ˆì´í„°
async def test_real_analysis_multi_page(request, analysis_service_instance: AnalysisService):
    """
    ë‹¤ì¤‘ ì´ë¯¸ì§€ì— ëŒ€í•´ ì‹¤ì œ ë¶„ì„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³  ê²°ê³¼ë¥¼ ìºì‹±í•˜ë©°,
    ì •ë ¬ ê²°ê³¼ë§Œ Mock DBì— ì €ì¥í•˜ëŠ” í†µí•© í…ŒìŠ¤íŠ¸.

    [ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „]
    - AI ì„¤ëª… ìƒì„± ì‹œ call_openai_api_async() ì‚¬ìš©
    - ì²˜ë¦¬ ì‹œê°„ ì•½ 70% ë‹¨ì¶• (6ì´ˆ â†’ 1.8ì´ˆ)
    """
    logger.info("ğŸš€ ì‹¤ì œ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ (ë‹¤ì¤‘ ì´ë¯¸ì§€, ìºì‹± ì‚¬ìš©)...")
    start_time = time.time()
    rerun_analysis = request.config.getoption("--rerun-analysis") # conftest.py ì˜µì…˜ ì½ê¸°
    if rerun_analysis:
        logger.warning("   -> --rerun-analysis ì˜µì…˜ í™œì„±í™”: ëª¨ë“  ë¶„ì„ ë‹¨ê³„ë¥¼ ê°•ì œ ì¬ì‹¤í–‰í•©ë‹ˆë‹¤.")

    # --- 1. ì¶œë ¥ í´ë” ë° Mock DB ì´ˆê¸°í™” ---
    os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)
    logger.info(f"   -> ê²°ê³¼ ì €ì¥ í´ë”: {FINAL_OUTPUT_DIR}")
    initialize_db_saver_mock() # db_saverì˜ Mock DBë§Œ ì´ˆê¸°í™”
    logger.info("   -> Mock DB(v2.1) ì´ˆê¸°í™” ì™„ë£Œ.")

    # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    service = analysis_service_instance

    processed_pages = 0
    failed_pages = 0

    # --- 2. ì´ë¯¸ì§€ë³„ ë¶„ì„ ë° ì •ë ¬ ë£¨í”„ ---
    for i, img_path in enumerate(TEST_IMAGE_FILES):
        page_num = i + 1
        img_filename = img_path.name
        logger.info(f"\n--- ğŸ“„ í˜ì´ì§€ {page_num}/{len(TEST_IMAGE_FILES)} ì²˜ë¦¬ ì‹œì‘: {img_filename} ---")

        if not img_path.exists():
            logger.error(f"   -> ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {img_path}")
            failed_pages += 1
            continue

        try:
            # --- ì´ë¯¸ì§€ ë¡œë“œ ---
            image = cv2.imread(str(img_path))
            if image is None:
                logger.error(f"   -> ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
                failed_pages += 1
                continue
            page_height, page_width = image.shape[:2]
            logger.info(f"   -> ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ ({page_width}x{page_height})")

            # --- ì¤‘ê°„ ê²°ê³¼ ë¡œë“œ ë˜ëŠ” ì‹¤ì œ ë¶„ì„ ì‹¤í–‰ (ìºì‹± ë¡œì§) ---
            layout_elements: Optional[List[MockElement]] = None
            ocr_results: Optional[List[MockTextContent]] = None
            ai_descriptions: Optional[Dict[str, str]] = None # str í‚¤ ì‚¬ìš©

            if not rerun_analysis:
                logger.debug("   -> ìºì‹œëœ ì¤‘ê°„ ê²°ê³¼ ë¡œë“œ ì‹œë„...")
                layout_elements = load_intermediate_results(CACHE_DIR, img_filename, "layout_elements")
                ocr_results = load_intermediate_results(CACHE_DIR, img_filename, "ocr_results")
                ai_descriptions = load_intermediate_results(CACHE_DIR, img_filename, "ai_descriptions")

            # ë ˆì´ì•„ì›ƒ ë¶„ì„
            if not layout_elements:
                logger.info("   -> [1/4] ì‹¤ì œ ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹¤í–‰...")
                layout_elements = service.analyze_layout(image)
                if layout_elements is None: layout_elements = [] # None ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸
                save_intermediate_results(CACHE_DIR, img_filename, "layout_elements", layout_elements)
            else:
                logger.info("   -> [1/4] ë ˆì´ì•„ì›ƒ ë¶„ì„: ìºì‹œ ì‚¬ìš©")

            # OCR ì²˜ë¦¬
            if not ocr_results:
                logger.info("   -> [2/4] ì‹¤ì œ OCR ì²˜ë¦¬ ì‹¤í–‰...")
                ocr_results = service.perform_ocr(image, layout_elements or [])
                if ocr_results is None: ocr_results = []
                save_intermediate_results(CACHE_DIR, img_filename, "ocr_results", ocr_results)
            else:
                logger.info("   -> [2/4] OCR ì²˜ë¦¬: ìºì‹œ ì‚¬ìš©")

            # AI ì„¤ëª… ìƒì„± (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „)
            if ai_descriptions is None: # None ì²´í¬ ì¤‘ìš” (ë¹ˆ dictì¼ ìˆ˜ ìˆìŒ)
                logger.info("   -> [3/4] ì‹¤ì œ AI ì„¤ëª… ìƒì„± ì‹¤í–‰ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬)...")
                # ğŸ‘‡ ë³€ê²½: await ì¶”ê°€ ë° call_openai_api_async ì‚¬ìš©
                ai_desc_dict_int_keys = await service.call_openai_api_async(
                    image=image,
                    layout_elements=layout_elements or [],
                    api_key=OPENAI_API_KEY,
                    max_concurrent_requests=5  # ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ (Rate Limit ëŒ€ì‘)
                )
                # JSON ì €ì¥ì„ ìœ„í•´ int í‚¤ë¥¼ str í‚¤ë¡œ ë³€í™˜
                ai_descriptions = {str(k): v for k, v in ai_desc_dict_int_keys.items()} if ai_desc_dict_int_keys else {}
                save_intermediate_results(CACHE_DIR, img_filename, "ai_descriptions", ai_descriptions)
                logger.info(f"      âœ… ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {len(ai_descriptions)}ê°œ ì„¤ëª… ìƒì„±")
            else:
                logger.info("   -> [3/4] AI ì„¤ëª… ìƒì„±: ìºì‹œ ì‚¬ìš©")

            # --- ì •ë ¬ ì‹¤í–‰ (âœ¨ Adaptive Strategy ìë™ ì„ íƒ) ---
            logger.info("   -> [4/4] ë ˆì´ì•„ì›ƒ ì •ë ¬ ì‹¤í–‰ (Adaptive Strategy)...")

            # ë ˆì´ì•„ì›ƒ í”„ë¡œíŒŒì¼ ë¶„ì„
            profile = LayoutProfiler.analyze(
                elements=layout_elements or [],
                page_width=page_width,
                page_height=page_height
            )
            logger.info(f"      ğŸ“Š ë ˆì´ì•„ì›ƒ í”„ë¡œíŒŒì¼:")
            logger.info(f"         - Global Consistency: {profile.global_consistency_score:.3f}")
            logger.info(f"         - Horizontal Adjacency: {profile.horizontal_adjacency_ratio:.3f}")
            logger.info(f"         - Anchor Count: {profile.anchor_count}")
            logger.info(f"         - Layout Type: {profile.layout_type.name}")
            logger.info(f"         - ğŸ¯ ì¶”ì²œ ì „ëµ: {profile.recommended_strategy.name}")

            # Adaptive Sorter ì‹¤í–‰ (ìë™ ì „ëµ ì„ íƒ)
            sorted_elements = sort_layout_elements_adaptive(
                elements=layout_elements or [],
                document_type=DOC_TYPE_NAME,
                page_width=page_width,
                page_height=page_height,
                force_strategy=None  # ìë™ ì „ëµ ì„ íƒ
            )
            logger.info(f"      âœ… ì •ë ¬ ì™„ë£Œ: {len(sorted_elements)}ê°œ ìš”ì†Œ")

            # --- Mock DB ì €ì¥ (ì •ë ¬ ê²°ê³¼ë§Œ) ---
            # Mock í˜ì´ì§€ ID ìƒì„± (ì‹¤ì œ í˜ì´ì§€ ID ëŒ€ì‹  ìˆœì„œ ì‚¬ìš©)
            mock_page_id = page_num
            logger.info(f"   -> Mock DB(v2.1)ì— ì •ë ¬ ê²°ê³¼ ì €ì¥ (Page ID: {mock_page_id})...")
            save_stats = save_sorted_elements_to_mock_db(
                page_id=mock_page_id,
                sorted_elements=sorted_elements,
                clear_existing=False # í˜ì´ì§€ë³„ë¡œ ì¶”ê°€ (Trueë¡œ í•˜ë©´ ì´ì „ í˜ì´ì§€ ê²°ê³¼ ì‚­ì œë¨)
            )
            logger.info(f"      -> DB ì €ì¥ ì™„ë£Œ: {save_stats}")

            # --- ê²°ê³¼ë¬¼ ì €ì¥ ---
            logger.info("   -> ì‹œê°í™” ë° í…ìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥...")
            ocr_map = {res.element_id: res.ocr_text for res in ocr_results or [] if hasattr(res, 'element_id')}
            # ai_mapì€ ì´ë¯¸ str í‚¤ë¥¼ ê°€ì§€ê³  ìˆìŒ

            # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„± (í˜ì´ì§€ ë²ˆí˜¸ + ì›ë³¸ íŒŒì¼ëª…)
            unique_filename = f"page_{page_num}_{img_filename}"

            output_paths = save_visual_artifacts(
                output_dir=str(FINAL_OUTPUT_DIR), # Path ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                image=image,
                sorted_elements=sorted_elements,
                ocr_map=ocr_map,
                ai_map=ai_descriptions or {},
                image_filename=unique_filename  # ê³ ìœ  íŒŒì¼ëª… ì „ë‹¬
            )
            logger.info(f"      -> ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_paths}")

            processed_pages += 1

        except Exception as e:
            logger.error(f"   -> í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            failed_pages += 1

    # --- 3. ìµœì¢… ê²°ê³¼ ìš”ì•½ ---
    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info(f"   - ì´ ì‹œë„ í˜ì´ì§€: {len(TEST_IMAGE_FILES)}")
    logger.info(f"   - ì„±ê³µ í˜ì´ì§€: {processed_pages}")
    logger.info(f"   - ì‹¤íŒ¨ í˜ì´ì§€: {failed_pages}")
    logger.info(f"   - ì´ ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f} ì´ˆ")
    logger.info("="*80)

    # Mock DB ìš”ì•½ ì¶œë ¥
    print("\n--- ìµœì¢… Mock DB ìƒíƒœ ìš”ì•½ ---")
    print_mock_db_summary()

    # í…ŒìŠ¤íŠ¸ ì„±ê³µ/ì‹¤íŒ¨ íŒì •
    assert failed_pages == 0, f"{failed_pages}ê°œ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨"
    assert processed_pages == len(TEST_IMAGE_FILES), "ëª¨ë“  í˜ì´ì§€ê°€ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    logger.success("ğŸ‰ ì‹¤ì œ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")

# --- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ) ---
if __name__ == "__main__":
    logger.remove()
    logger.add(sys.stderr, level="INFO")
    # pytestë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥ (fixture, ì˜µì…˜ ë“± í™œìš©)
    # pytest.main(['-s', '-v', __file__])
    print("ì´ í…ŒìŠ¤íŠ¸ëŠ” pytestë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤:")
    print(f"pytest -s -v {__file__}")
    print(f"pytest -s -v {__file__} --rerun-analysis  (ìºì‹œ ë¬´ì‹œ)")
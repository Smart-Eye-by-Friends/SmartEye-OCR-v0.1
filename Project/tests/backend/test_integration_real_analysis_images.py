# test_integration_real_analysis.py

import sys
import os
import cv2
import pytest
import pytest_asyncio  # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì§€ì›
from pathlib import Path
from typing import List, Dict, Optional
from loguru import logger
import time
from dotenv import load_dotenv  # .env íŒŒì¼ ë¡œë“œìš©
import difflib

# --- í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì • ë° ëª¨ë“ˆ ì„í¬íŠ¸ ---
project_root = Path(__file__).resolve().parent.parent.parent # Project/ ê²½ë¡œ
sys.path.insert(0, str(project_root)) # <--- ì´ ì¤„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.

# ì‹¤ì œ ë¶„ì„ ì„œë¹„ìŠ¤
from backend.app.services.analysis_service import AnalysisService
# ì •ë ¬ ì„œë¹„ìŠ¤ (âœ¨ Adaptive Strategy)
from backend.app.services.sorter_strategies import sort_layout_elements_adaptive, LayoutProfiler
from backend.app.services.formatter import TextFormatter
from backend.app.services.formatter_utils import clean_output
# DB ì €ì¥ ì„œë¹„ìŠ¤ (Mock DB v2.1 ì‚¬ìš©) ë° Mock DB ìƒíƒœ
from backend.app.services.db_saver import (
    save_sorted_elements_to_mock_db,
    print_mock_db_summary,
    mock_question_groups,
    mock_question_elements
)

from backend.app.services.batch_analysis import (
    initialize_mock_db_for_test as initialize_db_saver_mock, # ì—¬ê¸°ì„œ ì„í¬íŠ¸í•˜ê³  ë³„ì¹­ ì‚¬ìš©
)

# Mock ëª¨ë¸ (ë°ì´í„° êµ¬ì¡°ìš©)
from backend.app.services.mock_models import MockElement, MockTextContent

# í…ŒìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹° (ìºì‹± ë° ê²°ê³¼ ì €ì¥)
try:
    # --- ğŸ‘‡ ìˆ˜ì •: CACHE_DIR ì„í¬íŠ¸ ì œê±° ğŸ‘‡ ---
    from tests.backend.test_utils import (
        save_intermediate_results,
        load_intermediate_results,
        save_visual_artifacts,
        save_formatted_text,
    )
except ImportError:
    logger.error("test_utils.py ì„í¬íŠ¸ ì‹¤íŒ¨. Project/tests/backend/ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    # ëŒ€ì²´ í•¨ìˆ˜ ì •ì˜ (í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ìœ ë„)
    def save_intermediate_results(*args, **kwargs): raise ImportError("save_intermediate_results not found")
    def load_intermediate_results(*args, **kwargs): raise ImportError("load_intermediate_results not found")
    def save_visual_artifacts(*args, **kwargs): raise ImportError("save_visual_artifacts not found")
    def save_formatted_text(*args, **kwargs): raise ImportError("save_formatted_text not found")
    # --- ğŸ‘† CACHE_DIR ì •ì˜ë„ ì—¬ê¸°ì„œ ì œê±° ğŸ‘† ---

# --- ğŸ‘‡ ìˆ˜ì •: .env ë¡œë“œ ë° OPENAI_API_KEY ì •ì˜ ğŸ‘‡ ---
# .env íŒŒì¼ ë¡œë“œ (Project ë£¨íŠ¸ì—ì„œ)
dotenv_path = project_root / ".env"
load_dotenv(dotenv_path)

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.warning("âš ï¸ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    logger.warning(f"   .env íŒŒì¼ ê²½ë¡œ: {dotenv_path}")
    logger.warning("   AI ì„¤ëª… ìƒì„±ì´ ê±´ë„ˆë›°ì–´ì§‘ë‹ˆë‹¤.")
else:
    logger.info(f"âœ… .env íŒŒì¼ì—ì„œ OPENAI_API_KEY ë¡œë“œ ì™„ë£Œ (í‚¤ ê¸¸ì´: {len(OPENAI_API_KEY)}ì)")

# CACHE_DIR ì •ì˜ (test_utils.py ëŒ€ì‹  ì—¬ê¸°ì—)
CACHE_DIR = project_root / "tests" / ".cache"
# --- ğŸ‘† ìˆ˜ì • ë ğŸ‘† ---

# --- í…ŒìŠ¤íŠ¸ ì„¤ì • ---
TEST_IMAGE_FILES = [
    project_root / "tests" / "test_images" / "ìˆ ìˆ˜í•™1-1_í˜ì´ì§€_014.jpg",
    project_root / "tests" / "test_images" / "ìˆ ìˆ˜í•™1-1_í˜ì´ì§€_016.jpg",
    project_root / "tests" / "test_images" / "ìˆ ìˆ˜í•™1-1_í˜ì´ì§€_023.jpg"
    # í•„ìš”ì— ë”°ë¼ ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€ (Path ê°ì²´ ì‚¬ìš©)
]

# TEST_IMAGE_FILES = [
#     project_root / "tests" / "test_images" / "2025 Korean History-1_1 1.png",
#     project_root / "tests" / "test_images" / "2025 Korean History-1_2 1.png",
#     project_root / "tests" / "test_images" / "2025 Korean History-1_3 1.png",
#     project_root / "tests" / "test_images" / "2025 Korean History-1_4 1.png"
#     # í•„ìš”ì— ë”°ë¼ ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€ (Path ê°ì²´ ì‚¬ìš©)
# ]

OUTPUT_SUBDIR = "real_analysis_test" # ê²°ê³¼ ì €ì¥ìš© í•˜ìœ„ í´ë”
BASE_OUTPUT_DIR = project_root / "tests" / "test_pipeline_outputs"
FINAL_OUTPUT_DIR = BASE_OUTPUT_DIR / OUTPUT_SUBDIR
DOC_TYPE_NAME = "question_based" # ë˜ëŠ” "reading_order"
FORMATTED_GOLDEN_DIR = project_root / "tests" / "test_outputs" / "formatted_text"
FORMATTED_OUTPUT_DIR = FINAL_OUTPUT_DIR / "formatted_text"
# --------------------

# --- Pytest ì„¤ì • ---
# conftest.pyì˜ --rerun-analysis ì˜µì…˜ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ pytest ì‹¤í–‰ í•„ìš”
# pytest -s -v tests/backend/test_integration_real_analysis_images.py
# pytest -s -v tests/backend/test_integration_real_analysis_images.py --rerun-analysis

@pytest.fixture(scope="module")
def analysis_service_instance():
    """
    í…ŒìŠ¤íŠ¸ ì „ì²´ì—ì„œ ì‚¬ìš©í•  AnalysisService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

    [Lazy Loading íŒ¨í„´ í™œìš©]
    - auto_load=True: ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œ ëª¨ë¸ì„ ì¦‰ì‹œ ë¡œë“œ
    - ë‹¤ì¤‘ í˜ì´ì§€ ë¶„ì„ ì‹œì—ë„ ëª¨ë¸ì€ í•œ ë²ˆë§Œ ë¡œë“œë¨ (ìµœì í™”ë¨)

    [í•˜ìœ„ í˜¸í™˜ ë°©ì‹]
    ê¸°ì¡´ì²˜ëŸ¼ ìˆ˜ë™ ë¡œë“œë„ ê°€ëŠ¥:
    service = AnalysisService()
    model_path = service.download_model("SmartEyeSsen")
    service.load_model(model_path)
    """
    try:
        # Lazy Loading íŒ¨í„´: auto_load=Trueë¡œ ìë™ ëª¨ë¸ ë¡œë“œ
        service = AnalysisService(model_choice="SmartEyeSsen", auto_load=True)
        return service
    except Exception as e:
        pytest.fail(f"AnalysisService ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


def _format_and_assert(
    *,
    sorted_elements: List[MockElement],
    ocr_results: Optional[List[MockTextContent]],
    ai_descriptions: Optional[Dict[str, str]],
    page_tag: str,
    request: pytest.FixtureRequest,
    test_type: str,
    ocr_map_override: Optional[Dict[int, str]] = None,  # âœ… ìƒˆ íŒŒë¼ë¯¸í„°
    ai_map_override: Optional[Dict[int, str]] = None,   # âœ… ìƒˆ íŒŒë¼ë¯¸í„°
) -> str:
    """í¬ë§·íŒ… ê²°ê³¼ë¥¼ ìƒì„±í•˜ê³  ê³¨ë“ ê³¼ ë¹„êµí•œë‹¤.
    
    Args:
        sorted_elements: ì •ë ¬ëœ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸ (ì´ë¯¸ ì˜¤í”„ì…‹ ì ìš©ë¨)
        ocr_results: OCR ê²°ê³¼ (ë ˆê±°ì‹œ, ocr_map_override ìš°ì„ )
        ai_descriptions: AI ì„¤ëª… (ë ˆê±°ì‹œ, ai_map_override ìš°ì„ )
        page_tag: í˜ì´ì§€ íƒœê·¸
        request: pytest request fixture
        test_type: í…ŒìŠ¤íŠ¸ íƒ€ì… ("images" ë“±)
        ocr_map_override: ì´ë¯¸ ì˜¤í”„ì…‹ ì ìš©ëœ OCR ë§¤í•‘ (ìš°ì„  ì‚¬ìš©)
        ai_map_override: ì´ë¯¸ ì˜¤í”„ì…‹ ì ìš©ëœ AI ë§¤í•‘ (ìš°ì„  ì‚¬ìš©)
    """
    doc_type_id = 1 if DOC_TYPE_NAME == "question_based" else 2
    formatter = TextFormatter(doc_type_id=doc_type_id)

    # âœ… ì˜¤ë²„ë¼ì´ë“œ ë§¤í•‘ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš© (ë ˆê±°ì‹œ í˜¸í™˜)
    if ocr_map_override is not None:
        ocr_dict = ocr_map_override
        logger.debug(f"[{page_tag}] OCR ë§¤í•‘: ì˜¤ë²„ë¼ì´ë“œ ì‚¬ìš©")
    else:
        # ê¸°ì¡´ ë°©ì‹ (í˜¸í™˜ì„±)
        ocr_dict = {
            res.element_id: res.ocr_text
            for res in (ocr_results or [])
            if getattr(res, "element_id", None) is not None
        }
        logger.debug(f"[{page_tag}] OCR ë§¤í•‘: ë ˆê±°ì‹œ ë°©ì‹")

    if ai_map_override is not None:
        ai_dict = ai_map_override
        logger.debug(f"[{page_tag}] AI ë§¤í•‘: ì˜¤ë²„ë¼ì´ë“œ ì‚¬ìš©")
    else:
        # ê¸°ì¡´ ë°©ì‹ (str â†’ int ë³€í™˜)
        ai_dict: Dict[int, str] = {}
        for key, value in (ai_descriptions or {}).items():
            try:
                ai_dict[int(key)] = value
            except (TypeError, ValueError):
                logger.debug(f"AI ì„¤ëª… í‚¤ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ ì‹¤íŒ¨: key={key}")
        logger.debug(f"[{page_tag}] AI ë§¤í•‘: ë ˆê±°ì‹œ ë°©ì‹")

    # âœ… ë””ë²„ê¹…: ë§¤í•‘ ìƒíƒœ í™•ì¸
    logger.debug(f"[{page_tag}] í¬ë§·íŒ… ì…ë ¥:")
    logger.debug(f"   - sorted_elements: {len(sorted_elements)}ê°œ")
    logger.debug(f"   - ocr_dict: {len(ocr_dict)}ê°œ")
    logger.debug(f"   - ai_dict: {len(ai_dict)}ê°œ")
    if sorted_elements:
        logger.debug(f"   - ì²« element_id: {sorted_elements[0].element_id}")
        logger.debug(f"   - OCR í‚¤ ìƒ˜í”Œ: {list(ocr_dict.keys())[:3]}")
        logger.debug(f"   - AI í‚¤ ìƒ˜í”Œ: {list(ai_dict.keys())[:3]}")

    formatted_text = formatter.format_page(sorted_elements, ocr_dict, ai_descriptions=ai_dict)
    cleaned_text = clean_output(formatted_text)
    
    if not cleaned_text:
        logger.error(f"âŒ í¬ë§·íŒ… ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤: {page_tag}")
        logger.error(f"   ìƒì„¸ ì •ë³´ëŠ” ìœ„ì˜ ë””ë²„ê·¸ ë¡œê·¸ ì°¸ì¡°")
    
    assert cleaned_text, f"í¬ë§·íŒ… ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤: {page_tag}"

    save_formatted_text(FORMATTED_OUTPUT_DIR, f"{page_tag}.txt", cleaned_text)

    golden_dir = FORMATTED_GOLDEN_DIR / test_type
    golden_path = golden_dir / f"{page_tag}.txt"
    update_golden = request.config.getoption("--update-formatted-golden")

    if update_golden:
        golden_dir.mkdir(parents=True, exist_ok=True)
        golden_path.write_text(cleaned_text, encoding="utf-8")
        logger.info(f"ğŸ“ í¬ë§·íŒ… ê³¨ë“  ê°±ì‹ : {golden_path}")
        return cleaned_text

    if not golden_path.exists():
        golden_dir.mkdir(parents=True, exist_ok=True)
        golden_path.write_text(cleaned_text, encoding="utf-8")
        pytest.fail(
            f"í¬ë§·íŒ… ê³¨ë“  íŒŒì¼ì´ ì—†ì–´ ìƒˆë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ê²€í†  í›„ --update-formatted-golden ì˜µì…˜ìœ¼ë¡œ ìŠ¹ì¸í•˜ì„¸ìš”: {golden_path}"
        )

    expected_text = clean_output(golden_path.read_text(encoding="utf-8"))
    if cleaned_text != expected_text:
        diff = "\n".join(
            difflib.unified_diff(
                expected_text.splitlines(),
                cleaned_text.splitlines(),
                fromfile="expected",
                tofile="actual",
                lineterm=""
            )
        )
        logger.error(f"âš ï¸ í¬ë§·íŒ… ê³¨ë“  ë¶ˆì¼ì¹˜ ({page_tag})\n{diff}")
        pytest.fail(f"í¬ë§·íŒ… ì¶œë ¥ì´ ê³¨ë“ ê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {page_tag}")

    logger.info(f"   -> í¬ë§·íŒ… ê³¨ë“  ì¼ì¹˜ í™•ì¸ ({page_tag})")
    return cleaned_text

# --- í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ---
@pytest.mark.asyncio  # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ë°ì½”ë ˆì´í„°
async def test_real_analysis_multi_page(request, analysis_service_instance: AnalysisService):
    """
    ë‹¤ì¤‘ ì´ë¯¸ì§€ì— ëŒ€í•´ ì‹¤ì œ ë¶„ì„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³  ê²°ê³¼ë¥¼ ìºì‹±í•˜ë©°,
    ì •ë ¬ ê²°ê³¼ë§Œ Mock DBì— ì €ì¥í•˜ëŠ” í†µí•© í…ŒìŠ¤íŠ¸.

    [ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „]
    - AI ì„¤ëª… ìƒì„± ì‹œ call_openai_api_async() ì‚¬ìš©
    - ì²˜ë¦¬ ì‹œê°„ ì•½ 70% ë‹¨ì¶• (6ì´ˆ â†’ 1.8ì´ˆ)
    """
    logger.info("ğŸš€ ì‹¤ì œ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ (ë‹¤ì¤‘ ì´ë¯¸ì§€, ìºì‹± ì‚¬ìš©)...")
    start_time = time.time()
    rerun_analysis = request.config.getoption("--rerun-analysis") # conftest.py ì˜µì…˜ ì½ê¸°
    if rerun_analysis:
        logger.warning("   -> --rerun-analysis ì˜µì…˜ í™œì„±í™”: ëª¨ë“  ë¶„ì„ ë‹¨ê³„ë¥¼ ê°•ì œ ì¬ì‹¤í–‰í•©ë‹ˆë‹¤.")

    # --- 1. ì¶œë ¥ í´ë” ë° Mock DB ì´ˆê¸°í™” ---
    os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)
    logger.info(f"   -> ê²°ê³¼ ì €ì¥ í´ë”: {FINAL_OUTPUT_DIR}")
    initialize_db_saver_mock() # db_saverì˜ Mock DBë§Œ ì´ˆê¸°í™”
    logger.info("   -> Mock DB(v2.1) ì´ˆê¸°í™” ì™„ë£Œ.")

    # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    service = analysis_service_instance

    processed_pages = 0
    failed_pages = 0

    # --- 2. ì´ë¯¸ì§€ë³„ ë¶„ì„ ë° ì •ë ¬ ë£¨í”„ ---
    for i, img_path in enumerate(TEST_IMAGE_FILES):
        page_num = i + 1
        img_filename = img_path.name
        logger.info(f"\n--- ğŸ“„ í˜ì´ì§€ {page_num}/{len(TEST_IMAGE_FILES)} ì²˜ë¦¬ ì‹œì‘: {img_filename} ---")

        if not img_path.exists():
            logger.error(f"   -> ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {img_path}")
            failed_pages += 1
            continue

        try:
            # --- ì´ë¯¸ì§€ ë¡œë“œ ---
            image = cv2.imread(str(img_path))
            if image is None:
                logger.error(f"   -> ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
                failed_pages += 1
                continue
            page_height, page_width = image.shape[:2]
            logger.info(f"   -> ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ ({page_width}x{page_height})")

            # --- ì¤‘ê°„ ê²°ê³¼ ë¡œë“œ ë˜ëŠ” ì‹¤ì œ ë¶„ì„ ì‹¤í–‰ (ìºì‹± ë¡œì§) ---
            layout_elements: Optional[List[MockElement]] = None
            ocr_results: Optional[List[MockTextContent]] = None
            ai_descriptions: Optional[Dict[str, str]] = None # str í‚¤ ì‚¬ìš©

            if not rerun_analysis:
                logger.debug("   -> ìºì‹œëœ ì¤‘ê°„ ê²°ê³¼ ë¡œë“œ ì‹œë„...")
                layout_elements = load_intermediate_results(CACHE_DIR, img_filename, "layout_elements")
                ocr_results = load_intermediate_results(CACHE_DIR, img_filename, "ocr_results")
                ai_descriptions = load_intermediate_results(CACHE_DIR, img_filename, "ai_descriptions")

            # ë ˆì´ì•„ì›ƒ ë¶„ì„
            if not layout_elements:
                logger.info("   -> [1/4] ì‹¤ì œ ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹¤í–‰...")
                layout_elements = service.analyze_layout(image)
                if layout_elements is None: layout_elements = [] # None ëŒ€ì‹  ë¹ˆ ë¦¬ìŠ¤íŠ¸
                save_intermediate_results(CACHE_DIR, img_filename, "layout_elements", layout_elements)
            else:
                logger.info("   -> [1/4] ë ˆì´ì•„ì›ƒ ë¶„ì„: ìºì‹œ ì‚¬ìš©")

            # OCR ì²˜ë¦¬
            if not ocr_results:
                logger.info("   -> [2/4] ì‹¤ì œ OCR ì²˜ë¦¬ ì‹¤í–‰...")
                ocr_results = service.perform_ocr(image, layout_elements or [])
                if ocr_results is None: ocr_results = []
                save_intermediate_results(CACHE_DIR, img_filename, "ocr_results", ocr_results)
            else:
                logger.info("   -> [2/4] OCR ì²˜ë¦¬: ìºì‹œ ì‚¬ìš©")

            # AI ì„¤ëª… ìƒì„± (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ ë²„ì „)
            if ai_descriptions is None: # None ì²´í¬ ì¤‘ìš” (ë¹ˆ dictì¼ ìˆ˜ ìˆìŒ)
                logger.info("   -> [3/4] ì‹¤ì œ AI ì„¤ëª… ìƒì„± ì‹¤í–‰ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬)...")
                # ğŸ‘‡ ë³€ê²½: await ì¶”ê°€ ë° call_openai_api_async ì‚¬ìš©
                ai_desc_dict_int_keys = await service.call_openai_api_async(
                    image=image,
                    layout_elements=layout_elements or [],
                    api_key=OPENAI_API_KEY,
                    max_concurrent_requests=5  # ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ (Rate Limit ëŒ€ì‘)
                )
                # JSON ì €ì¥ì„ ìœ„í•´ int í‚¤ë¥¼ str í‚¤ë¡œ ë³€í™˜
                ai_descriptions = {str(k): v for k, v in ai_desc_dict_int_keys.items()} if ai_desc_dict_int_keys else {}
                save_intermediate_results(CACHE_DIR, img_filename, "ai_descriptions", ai_descriptions)
                logger.info(f"      âœ… ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {len(ai_descriptions)}ê°œ ì„¤ëª… ìƒì„±")
            else:
                logger.info("   -> [3/4] AI ì„¤ëª… ìƒì„±: ìºì‹œ ì‚¬ìš©")

            # --- ì •ë ¬ ì‹¤í–‰ (âœ¨ Adaptive Strategy ìë™ ì„ íƒ) ---
            logger.info("   -> [4/4] ë ˆì´ì•„ì›ƒ ì •ë ¬ ì‹¤í–‰ (Adaptive Strategy)...")

            # ë ˆì´ì•„ì›ƒ í”„ë¡œíŒŒì¼ ë¶„ì„
            profile = LayoutProfiler.analyze(
                elements=layout_elements or [],
                page_width=page_width,
                page_height=page_height
            )
            logger.info(f"      ğŸ“Š ë ˆì´ì•„ì›ƒ í”„ë¡œíŒŒì¼:")
            logger.info(f"         - Global Consistency: {profile.global_consistency_score:.3f}")
            logger.info(f"         - Horizontal Adjacency: {profile.horizontal_adjacency_ratio:.3f}")
            logger.info(f"         - Anchor Count: {profile.anchor_count}")
            logger.info(f"         - Layout Type: {profile.layout_type.name}")
            logger.info(f"         - ğŸ¯ ì¶”ì²œ ì „ëµ: {profile.recommended_strategy.name}")

            # Adaptive Sorter ì‹¤í–‰ (ìë™ ì „ëµ ì„ íƒ)
            sorted_elements = sort_layout_elements_adaptive(
                elements=layout_elements or [],
                document_type=DOC_TYPE_NAME,
                page_width=page_width,
                page_height=page_height,
                force_strategy=None  # ìë™ ì „ëµ ì„ íƒ
            )
            logger.info(f"      âœ… ì •ë ¬ ì™„ë£Œ: {len(sorted_elements)}ê°œ ìš”ì†Œ")

            # --- Mock DB ì €ì¥ (ì •ë ¬ ê²°ê³¼ë§Œ) ---
            # Mock í˜ì´ì§€ ID ìƒì„± (ì‹¤ì œ í˜ì´ì§€ ID ëŒ€ì‹  ìˆœì„œ ì‚¬ìš©)
            mock_page_id = page_num
            logger.info(f"   -> Mock DB(v2.1)ì— ì •ë ¬ ê²°ê³¼ ì €ì¥ (Page ID: {mock_page_id})...")
            
            # âœ… STEP 1: ì˜¤í”„ì…‹ ì ìš© ì „ì— ì›ë³¸ ID ê¸°ë°˜ ë§¤í•‘ ìƒì„±
            logger.debug(f"   -> ì›ë³¸ ID ê¸°ë°˜ ë§¤í•‘ ìƒì„± ì¤‘...")
            ocr_map_original = {
                res.element_id: res.ocr_text 
                for res in ocr_results or [] 
                if hasattr(res, 'element_id')
            }
            
            ai_map_original: Dict[int, str] = {}
            for key, value in (ai_descriptions or {}).items():
                try:
                    ai_map_original[int(key)] = value
                except (TypeError, ValueError):
                    logger.debug(f"AI ì„¤ëª… í‚¤ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ ì‹¤íŒ¨: key={key}")
            
            # âœ… STEP 2: í˜ì´ì§€ë³„ ì˜¤í”„ì…‹ ì •ì˜
            element_id_offset = page_num * 1000
            logger.debug(f"   -> í˜ì´ì§€ {page_num} ì˜¤í”„ì…‹: {element_id_offset}")
            
            # âœ… STEP 3: sorted_elementsì˜ element_idì— ì˜¤í”„ì…‹ ì ìš©
            for elem in sorted_elements:
                elem.element_id = element_id_offset + elem.element_id
            
            # âœ… STEP 4: OCR/AI ë§¤í•‘ë„ ì˜¤í”„ì…‹ ì ìš© (ìƒˆ IDë¡œ ì¬ë§¤í•‘)
            ocr_map_with_offset = {
                element_id_offset + orig_id: text 
                for orig_id, text in ocr_map_original.items()
            }
            
            ai_map_with_offset = {
                element_id_offset + orig_id: desc 
                for orig_id, desc in ai_map_original.items()
            }
            
            logger.debug(f"   -> ì˜¤í”„ì…‹ ì ìš© ì™„ë£Œ: OCR {len(ocr_map_with_offset)}ê°œ, AI {len(ai_map_with_offset)}ê°œ")
            
            # âœ… STEP 5: Mock DB ì €ì¥
            save_stats = save_sorted_elements_to_mock_db(
                page_id=mock_page_id,
                sorted_elements=sorted_elements,
                clear_existing=False
            )
            logger.info(f"      -> DB ì €ì¥ ì™„ë£Œ: {save_stats}")

            # --- ê²°ê³¼ë¬¼ ì €ì¥ ---
            logger.info("   -> ì‹œê°í™” ë° í…ìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥...")
            
            unique_filename = f"page_{page_num}_{img_path.stem}"

            output_paths = save_visual_artifacts(
                output_dir=str(FINAL_OUTPUT_DIR),
                image=image,
                sorted_elements=sorted_elements,
                ocr_map=ocr_map_with_offset,  # âœ… ì˜¤í”„ì…‹ ì ìš©ëœ ë§¤í•‘
                ai_map=ai_map_with_offset,     # âœ… ì˜¤í”„ì…‹ ì ìš©ëœ ë§¤í•‘ (int í‚¤)
                image_filename=unique_filename
            )
            logger.info(f"      -> ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_paths}")

            # --- í¬ë§·íŒ… ë° ê²€ì¦ ---
            page_tag = f"img_{page_num:02d}_{img_path.stem}"
            
            _format_and_assert(
                sorted_elements=sorted_elements,  # ì´ë¯¸ ì˜¤í”„ì…‹ ì ìš©ë¨
                ocr_results=None,  # âš ï¸ ì‚¬ìš© ì•ˆ í•¨ (ì§ì ‘ ë§¤í•‘ ì „ë‹¬)
                ai_descriptions=None,  # âš ï¸ ì‚¬ìš© ì•ˆ í•¨ (ì§ì ‘ ë§¤í•‘ ì „ë‹¬)
                page_tag=page_tag,
                request=request,
                test_type="images",
                # âœ… ìƒˆ íŒŒë¼ë¯¸í„°ë¡œ ì˜¤í”„ì…‹ ì ìš©ëœ ë§¤í•‘ ì „ë‹¬
                ocr_map_override=ocr_map_with_offset,
                ai_map_override=ai_map_with_offset,
            )

            processed_pages += 1

        except Exception as e:
            logger.error(f"   -> í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            failed_pages += 1

    # --- 3. ìµœì¢… ê²°ê³¼ ìš”ì•½ ---
    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info(f"   - ì´ ì‹œë„ í˜ì´ì§€: {len(TEST_IMAGE_FILES)}")
    logger.info(f"   - ì„±ê³µ í˜ì´ì§€: {processed_pages}")
    logger.info(f"   - ì‹¤íŒ¨ í˜ì´ì§€: {failed_pages}")
    logger.info(f"   - ì´ ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f} ì´ˆ")
    logger.info("="*80)

    # Mock DB ìš”ì•½ ì¶œë ¥
    print("\n--- ìµœì¢… Mock DB ìƒíƒœ ìš”ì•½ ---")
    print_mock_db_summary()

    # í…ŒìŠ¤íŠ¸ ì„±ê³µ/ì‹¤íŒ¨ íŒì •
    assert failed_pages == 0, f"{failed_pages}ê°œ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨"
    assert processed_pages == len(TEST_IMAGE_FILES), "ëª¨ë“  í˜ì´ì§€ê°€ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    logger.success("ğŸ‰ ì‹¤ì œ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")

# --- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ) ---
if __name__ == "__main__":
    logger.remove()
    logger.add(sys.stderr, level="INFO")
    # pytestë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥ (fixture, ì˜µì…˜ ë“± í™œìš©)
    # pytest.main(['-s', '-v', __file__])
    print("ì´ í…ŒìŠ¤íŠ¸ëŠ” pytestë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤:")
    print(f"pytest -s -v {__file__}")
    print(f"pytest -s -v {__file__} --rerun-analysis  (ìºì‹œ ë¬´ì‹œ)")

# test_integration_real_analysis.py

import sys
import os
import cv2
import pytest
import pytest_asyncio  # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ ì§€ì›
from pathlib import Path
from typing import List, Dict, Optional
from loguru import logger
import time
from dotenv import load_dotenv  # .env íŒŒì¼ ë¡œë“œìš©
import fitz  # PyMuPDF

# --- í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì • ë° ëª¨ë“ˆ ì„í¬íŠ¸ ---
project_root = Path(__file__).resolve().parent.parent.parent # Project/ ê²½ë¡œ
sys.path.insert(0, str(project_root)) # <--- ì´ ì¤„ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.

# ì„œë¹„ìŠ¤ ì„í¬íŠ¸
from backend.app.services.analysis_service import AnalysisService
from backend.app.services.sorter import sort_layout_elements
from backend.app.services.db_saver import save_sorted_elements_to_mock_db, print_mock_db_summary
from backend.app.services.batch_analysis import initialize_mock_db_for_test as initialize_db_saver_mock
from backend.app.services.pdf_processor import PDFProcessor

# Mock ëª¨ë¸ (ë°ì´í„° êµ¬ì¡°ìš©)
from backend.app.services.mock_models import MockElement, MockTextContent

# í…ŒìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹°
try:
    from tests.backend.test_utils import save_intermediate_results, load_intermediate_results, save_visual_artifacts
except ImportError:
    logger.error("test_utils.py ì„í¬íŠ¸ ì‹¤íŒ¨. Project/tests/backend/ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    def save_intermediate_results(*args, **kwargs): raise ImportError("save_intermediate_results not found")
    def load_intermediate_results(*args, **kwargs): raise ImportError("load_intermediate_results not found")
    def save_visual_artifacts(*args, **kwargs): raise ImportError("save_visual_artifacts not found")

# --- .env ë¡œë“œ ë° API í‚¤ ì„¤ì • ---
dotenv_path = project_root / ".env"
load_dotenv(dotenv_path)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.warning("âš ï¸ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AI ì„¤ëª… ìƒì„±ì´ ê±´ë„ˆë›°ì–´ì§‘ë‹ˆë‹¤.")
else:
    logger.info(f"âœ… .env íŒŒì¼ì—ì„œ OPENAI_API_KEY ë¡œë“œ ì™„ë£Œ.")

# --- í…ŒìŠ¤íŠ¸ ì„¤ì • ---
CACHE_DIR = project_root / "tests" / ".cache"
BASE_OUTPUT_DIR = project_root / "tests" / "test_pipeline_outputs"
OUTPUT_SUBDIR = "real_analysis_test"
FINAL_OUTPUT_DIR = BASE_OUTPUT_DIR / OUTPUT_SUBDIR
DOC_TYPE_NAME = "question_based"

# --- ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ íŒŒì¼ ëª©ë¡ ---
TEST_IMAGE_FILES = [
    project_root / "tests" / "test_images" / "ìˆ ìˆ˜í•™1-1_í˜ì´ì§€_014.jpg",
    project_root / "tests" / "test_images" / "ìˆ ìˆ˜í•™1-1_í˜ì´ì§€_016.jpg",
]

# --- PDF í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ---
# ğŸ‘‡ ì—¬ê¸°ì— í…ŒìŠ¤íŠ¸í•  PDF íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.
# ì˜ˆ: project_root / "tests" / "test_images" / "my_test.pdf"
TEST_PDF_FILE = project_root / "tests" / "test_images" / "ìˆ ìˆ˜í•™ ë‚±ê°œ ë¬¸ì œì§€.pdf" 

# ===================================================================
# Pytest Fixtures
# ===================================================================

@pytest.fixture(scope="module")
def analysis_service_instance():
    """í…ŒìŠ¤íŠ¸ ì „ì²´ì—ì„œ ì‚¬ìš©í•  AnalysisService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    try:
        service = AnalysisService(model_choice="SmartEyeSsen", auto_load=True)
        return service
    except Exception as e:
        pytest.fail(f"AnalysisService ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

@pytest.fixture(scope="module")
def pdf_processor():
    """PDF ì²˜ë¦¬ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    pdf_output_dir = project_root / "tests" / "test_outputs" / "pdf_to_img_for_analysis"
    pdf_output_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"PDF ë³€í™˜ ì´ë¯¸ì§€ ì €ì¥ í´ë”: {pdf_output_dir}")
    return PDFProcessor(upload_directory=str(pdf_output_dir), dpi=150)

# ===================================================================
# í…ŒìŠ¤íŠ¸ í—¬í¼ í•¨ìˆ˜
# ===================================================================

async def run_analysis_on_images(image_paths: List[Path], service: AnalysisService, rerun_analysis: bool, test_type: str):
    """ì§€ì •ëœ ì´ë¯¸ì§€ ëª©ë¡ì— ëŒ€í•´ ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    processed_pages = 0
    failed_pages = 0

    for i, img_path in enumerate(image_paths):
        page_num = i + 1
        img_filename = img_path.name
        logger.info(f"\n--- ğŸ“„ {test_type} í˜ì´ì§€ {page_num}/{len(image_paths)} ì²˜ë¦¬ ì‹œì‘: {img_filename} ---")

        if not img_path.exists():
            logger.error(f"   -> ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {img_path}")
            failed_pages += 1
            continue

        try:
            image = cv2.imread(str(img_path))
            if image is None:
                logger.error(f"   -> ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
                failed_pages += 1
                continue
            page_height, page_width = image.shape[:2]

            # ìºì‹± ë¡œì§
            layout_elements, ocr_results, ai_descriptions = None, None, None
            if not rerun_analysis:
                layout_elements = load_intermediate_results(CACHE_DIR, img_filename, "layout_elements")
                ocr_results = load_intermediate_results(CACHE_DIR, img_filename, "ocr_results")
                ai_descriptions = load_intermediate_results(CACHE_DIR, img_filename, "ai_descriptions")

            # ë¶„ì„ íŒŒì´í”„ë¼ì¸
            if not layout_elements:
                logger.info("   -> [1/4] ì‹¤ì œ ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹¤í–‰...")
                layout_elements = service.analyze_layout(image) or []
                save_intermediate_results(CACHE_DIR, img_filename, "layout_elements", layout_elements)
            else: logger.info("   -> [1/4] ë ˆì´ì•„ì›ƒ ë¶„ì„: ìºì‹œ ì‚¬ìš©")

            if not ocr_results:
                logger.info("   -> [2/4] ì‹¤ì œ OCR ì²˜ë¦¬ ì‹¤í–‰...")
                ocr_results = service.perform_ocr(image, layout_elements) or []
                save_intermediate_results(CACHE_DIR, img_filename, "ocr_results", ocr_results)
            else: logger.info("   -> [2/4] OCR ì²˜ë¦¬: ìºì‹œ ì‚¬ìš©")

            if ai_descriptions is None:
                logger.info("   -> [3/4] ì‹¤ì œ AI ì„¤ëª… ìƒì„± ì‹¤í–‰...")
                ai_desc_dict_int_keys = await service.call_openai_api_async(image, layout_elements, OPENAI_API_KEY)
                ai_descriptions = {str(k): v for k, v in ai_desc_dict_int_keys.items()} if ai_desc_dict_int_keys else {}
                save_intermediate_results(CACHE_DIR, img_filename, "ai_descriptions", ai_descriptions)
            else: logger.info("   -> [3/4] AI ì„¤ëª… ìƒì„±: ìºì‹œ ì‚¬ìš©")

            logger.info("   -> [4/4] ì‹¤ì œ ë ˆì´ì•„ì›ƒ ì •ë ¬ ì‹¤í–‰...")
            sorted_elements = sort_layout_elements(layout_elements, DOC_TYPE_NAME, page_width, page_height)

            # Mock DB ì €ì¥
            save_sorted_elements_to_mock_db(page_num, sorted_elements, clear_existing=False)

            # ê²°ê³¼ë¬¼ ì €ì¥
            ocr_map = {res.element_id: res.ocr_text for res in ocr_results if hasattr(res, 'element_id')}
            save_visual_artifacts(
                output_dir=str(FINAL_OUTPUT_DIR),
                image=image,
                sorted_elements=sorted_elements,
                ocr_map=ocr_map,
                ai_map=ai_descriptions or {},
                image_filename=img_filename
            )
            
            processed_pages += 1

        except Exception as e:
            logger.error(f"   -> í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            failed_pages += 1
    
    return processed_pages, failed_pages

# ===================================================================
# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ===================================================================

@pytest.mark.image_test
@pytest.mark.asyncio
async def test_real_analysis_multi_page(request, analysis_service_instance: AnalysisService):
    """ë‹¤ì¤‘ ì´ë¯¸ì§€ì— ëŒ€í•´ ì‹¤ì œ ë¶„ì„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” í†µí•© í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸš€ ì´ë¯¸ì§€ ê¸°ë°˜ ì‹¤ì œ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    start_time = time.time()
    rerun_analysis = request.config.getoption("--rerun-analysis")

    os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)
    initialize_db_saver_mock()

    processed_pages, failed_pages = await run_analysis_on_images(
        image_paths=TEST_IMAGE_FILES,
        service=analysis_service_instance,
        rerun_analysis=rerun_analysis,
        test_type="ì´ë¯¸ì§€"
    )

    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š ì´ë¯¸ì§€ ë¶„ì„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info(f"   - ì´ ì‹œë„ í˜ì´ì§€: {len(TEST_IMAGE_FILES)}")
    logger.info(f"   - ì„±ê³µ í˜ì´ì§€: {processed_pages}")
    logger.info(f"   - ì‹¤íŒ¨ í˜ì´ì§€: {failed_pages}")
    logger.info(f"   - ì´ ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f} ì´ˆ")
    logger.info("="*80)

    print("\n--- ìµœì¢… Mock DB ìƒíƒœ ìš”ì•½ (ì´ë¯¸ì§€ Test) ---")
    print_mock_db_summary()

    assert failed_pages == 0, f"{failed_pages}ê°œ ì´ë¯¸ì§€ í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨"
    assert processed_pages == len(TEST_IMAGE_FILES), "ëª¨ë“  ì´ë¯¸ì§€ í˜ì´ì§€ê°€ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    logger.success("ğŸ‰ ì´ë¯¸ì§€ ê¸°ë°˜ ì‹¤ì œ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")


@pytest.mark.pdf_test
@pytest.mark.asyncio
async def test_real_analysis_from_pdf(request, analysis_service_instance: AnalysisService, pdf_processor: PDFProcessor):
    """PDF íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„, ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” í†µí•© í…ŒìŠ¤íŠ¸."""
    if not TEST_PDF_FILE:
        pytest.skip("í…ŒìŠ¤íŠ¸í•  PDF íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (TEST_PDF_FILE is None)")

    logger.info("ğŸš€ PDF ê¸°ë°˜ ì‹¤ì œ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    start_time = time.time()
    rerun_analysis = request.config.getoption("--rerun-analysis")

    # --- 1. ì œê³µëœ PDF ë¡œë“œ ë° ì´ë¯¸ì§€ ë³€í™˜ ---
    if not TEST_PDF_FILE.exists():
        pytest.fail(f"í…ŒìŠ¤íŠ¸ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TEST_PDF_FILE}\n" 
                    f"íŒŒì¼ ìƒë‹¨ì˜ TEST_PDF_FILE ë³€ìˆ˜ì— ì˜¬ë°”ë¥¸ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.")

    logger.info(f"   -> í…ŒìŠ¤íŠ¸ PDF ë¡œë“œ: {TEST_PDF_FILE.name}")
    pdf_bytes = TEST_PDF_FILE.read_bytes()
    
    converted_images_info = pdf_processor.convert_pdf_to_images(
        pdf_bytes=pdf_bytes,
        project_id=999, # ì„ì‹œ í”„ë¡œì íŠ¸ ID
        start_page_number=1
    )
    
    pdf_image_files = [Path(pdf_processor.upload_directory) / info['image_path'] for info in converted_images_info]
    logger.info(f"   -> {len(pdf_image_files)} í˜ì´ì§€ PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ ì™„ë£Œ.")

    # --- 2. ë¶„ì„ ì‹¤í–‰ ---
    os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)
    initialize_db_saver_mock()

    processed_pages, failed_pages = await run_analysis_on_images(
        image_paths=pdf_image_files,
        service=analysis_service_instance,
        rerun_analysis=rerun_analysis,
        test_type="PDF"
    )

    # --- 3. ìµœì¢… ê²°ê³¼ ìš”ì•½ ---
    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š PDF ë¶„ì„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info(f"   - ì´ ì‹œë„ í˜ì´ì§€: {len(pdf_image_files)}")
    logger.info(f"   - ì„±ê³µ í˜ì´ì§€: {processed_pages}")
    logger.info(f"   - ì‹¤íŒ¨ í˜ì´ì§€: {failed_pages}")
    logger.info(f"   - ì´ ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f} ì´ˆ")
    logger.info("="*80)

    print("\n--- ìµœì¢… Mock DB ìƒíƒœ ìš”ì•½ (PDF Test) ---")
    print_mock_db_summary()

    assert failed_pages == 0, f"{failed_pages}ê°œ PDF í˜ì´ì§€ ì²˜ë¦¬ ì‹¤íŒ¨"
    assert processed_pages == len(pdf_image_files), "ëª¨ë“  PDF í˜ì´ì§€ê°€ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    logger.success("ğŸ‰ PDF ê¸°ë°˜ ì‹¤ì œ ë¶„ì„ í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")


# --- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ) ---
if __name__ == "__main__":
    logger.remove()
    logger.add(sys.stderr, level="INFO")
    print("ì´ í…ŒìŠ¤íŠ¸ëŠ” pytestë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤:")
    print(f"pytest -s -v {__file__}")
    print("pytestë¡œ íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰í•˜ë ¤ë©´ -k ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”:")
    print(f"  pytest -s -v -k test_real_analysis_multi_page {__file__}")
    print(f"  pytest -s -v -k test_real_analysis_from_pdf {__file__}")